<!DOCTYPE html>
<html lang="en-us">
  <head>
  <meta charset="UTF-8">
  <title>Ahmad Badary</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <link rel="stylesheet" href="/css/normalize.css">
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="/css/cayman.css">
  <link rel="stylesheet" href="/css/style.css">
  <link rel="shortcut icon" href="/main_files/favicon.ico" />
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="/css/customStyle.css">
  <title> » Ahmad Badary</title>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
</head>

  <body>
    <nav class="main-nav">
    <a href="https://ahmedbadary.github.io/" class="main-nav-logo">
        <img src="/main_files/logo.png">
    </a>
    <ul id="menu-main" class="main-nav-items">
        <li id="menu-item-1859" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-home menu-item-1859">
            <a href="/">Home</a>
        </li>
        <li id="menu-item-2869" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-2869">
            <a href="/work">Work</a>
        </li>
        <li id="menu-item-1892" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1892">
            <a href="/projects">Projects</a>
        </li>
        <li id="menu-item-1858" class="menu-item menu-item-type-post_type menu-item-object-page current_page_parent menu-item-1858">
            <a href="/blog">Blog</a>
        </li>
        <li id="menu-item-1862" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1862">
            <a href="/about">About</a>
        </li>
    </ul>
</nav>


<section class="page-header">
  <h1 class="project-name">Concepts</h1>
  <h2 class="project-tagline"></h2>
  <a href="/#" class="btn">Home</a>
  <a href="/work" class="btn">Work-Space</a>
  <a href= / class="btn">Previous</a>
</section>

<!-- <div>
  <ul class="posts">
    
      <li><span>02 Jan 2014</span> &raquo; <a href="/2014/01/02/introducing-Ahmad/">Introducing Ahmad</a></li>
    
  </ul>
</div> -->


    <section class="main-content">
      
      <div class="TOC">
  <h1 id="table-of-contents">Table of Contents</h1>

  <ul class="TOC1">
    <li><a href="#content1">CNNs</a></li>
  </ul>
  <ul class="TOC2">
    <li><a href="#content2">RNNs</a></li>
  </ul>
  <ul class="TOC3">
    <li><a href="#content3">Math</a></li>
  </ul>
  <ul class="TOC4">
    <li><a href="#content4">Statistics and Probability Theory</a></li>
  </ul>
  <ul class="TOC5">
    <li><a href="#content5">Optimization</a></li>
  </ul>
  <ul class="TOC6">
    <li><a href="#content6">Machine Learning</a></li>
  </ul>
  <ul class="TOC7">
    <li><a href="#content7">Computer Vision</a></li>
  </ul>
  <ul class="TOC8">
    <li><a href="#content8">NLP</a></li>
  </ul>
  <ul class="TOC9">
    <li><a href="#content9">Physics</a></li>
  </ul>
  <ul class="TOC10">
    <li><a href="#content10">Algorithms</a></li>
  </ul>
  <ul class="TOC11">
    <li><a href="#content11">Misc.</a></li>
  </ul>
  <ul class="TOC12">
    <li><a href="#content12">Game Theory</a></li>
  </ul>
</div>

<hr />
<hr />

<ul>
  <li><a href="https://arogozhnikov.github.io/2016/04/28/demonstrations-for-ml-courses.html">Interactive ML Demos (Blog)</a></li>
</ul>

<p><button class="showText" value="show" onclick="showTextPopHide(event);">The Scientific Method as an Ongoing Process</button>
<img src="https://cdn.mathpix.com/snip/images/XCvcfM_6eAB3B5pXgL2IZTyO1FkhciXiaVCcQBjsiAc.original.fullsize.png" alt="img" width="100%" hidden="" /></p>

<p><strong style="color: red">PyTorch:</strong><br />
<button class="showText" value="show" onclick="showTextPopHide(event);">Packages</button>
<img src="https://cdn.mathpix.com/snip/images/dq-w7AFpBfdXveRL3uGmnerIGtfIPyeJFRfj2o97XSU.original.fullsize.png" alt="img" width="100%" hidden="" /><br />
CNN Tensor Shape: \([B, C, H, W]\)</p>

<h2 id="notes">Notes</h2>

<ul>
  <li>Statistics-ML Concepts Translations  <br />
  <button class="showText" value="show" onclick="showText_withParent_PopHide(event);">List</button>
    <div hidden=""></div>
    <ul>
      <li>Dependent/Response variable   \(\iff\)   target variable, label</li>
      <li>Independent variable   \(\iff\)   feature, predictor</li>
      <li>Correlation   \(\iff\)   association</li>
      <li>Regression   \(\iff\)   prediction</li>
      <li>Hypothesis testing   \(\iff\)   model evaluation</li>
      <li>P-value   \(\iff\)   model performance metric</li>
      <li>Outliers   \(\iff\)   anomalies</li>
      <li>Normal distribution   \(\iff\)   Gaussian distribution</li>
      <li>Mean   \(\iff\)   average</li>
      <li>Median   \(\iff\)   middle value</li>
      <li>Mode   \(\iff\)   most frequent value</li>
      <li>Standard deviation   \(\iff\)   spread of data around the mean</li>
      <li>Variance   \(\iff\)   measure of dispersion of data from the mean</li>
      <li>Confidence interval   \(\iff\)   range of values within which the true value is likely to fall</li>
      <li>Statistical significance   \(\iff\)   likelihood that a result is not due to chance</li>
      <li>Sample   \(\iff\)   subset of data used for analysis</li>
      <li>Population   \(\iff\)   entire set of data</li>
      <li>Bias   \(\iff\)   systematic error in a model</li>
      <li>Overfitting   \(\iff\)   when a model is too complex and performs poorly on new data</li>
      <li>Underfitting   \(\iff\)   when a model is too simple and does not capture the underlying patterns in the data.</li>
      <li>Random sampling   \(\iff\)   sampling randomly from a population</li>
      <li>Stratified sampling   \(\iff\)   sampling by dividing the population into subgroups and selecting a random sample from each subgroup</li>
      <li>Cluster sampling   \(\iff\)   sampling by dividing the population into clusters and selecting a random sample of clusters</li>
      <li>Multivariate analysis   \(\iff\)   analysis of multiple variables</li>
      <li>Multinomial distribution   \(\iff\)   probability distribution of a discrete random variable with more than two possible outcomes</li>
      <li>Chi-square test   \(\iff\)   test used to determine if two or more groups have the same distribution</li>
      <li>T-test   \(\iff\)   test used to determine if the means of two groups are significantly different from each other</li>
      <li>ANOVA   \(\iff\)   analysis of variance, used to compare the means of multiple groups</li>
      <li>Principle component analysis   \(\iff\)   technique for reducing the dimensionality of data</li>
      <li>Factor analysis   \(\iff\)   technique for identifying underlying factors in a dataset.</li>
    </ul>

    <p>&lt;/div&gt;</p>
  </li>
</ul>

<h2 id="content1">CNNs</h2>

<!-- 1. **:**{: style="color: SteelBlue"}{: .bodyContents1 #bodyContents11}   -->

<!-- 2. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents1 #bodyContents12}  
3. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents1 #bodyContents13}  
4. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents1 #bodyContents14}  
-->

<!-- __Notes:__   -->
<!-- * __Structured Convolutions__:  
    __Why?__  
    Language has structure, would like it to localize features.  
    > e.g. noun-verb pairs very informative, but not captured by normal CNNs  
 -->

<hr />
<hr />

<h2 id="content2">RNNs</h2>

<!-- 1. **RNN Architectures:**{: style="color: SteelBlue"}{: .bodyContents2 #bodyContents21}   -->
<!-- 2. **Different Connections in RNN Architectures:**{: style="color: SteelBlue"}{: .bodyContents2 #bodyContents22}   -->

<ol>
  <li><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents23">Modeling Sequences - Memory as a model property:</strong><br />
 <button class="showText" value="show" onclick="showTextPopHide(event);">Show Content</button>
    <ul hidden="">
      <li>Everything:<br />
  <strong style="color: red">Memoryless Models for Sequences:</strong>
        <ul>
          <li><strong>Autoregressive Models:</strong><br />
  Predict the next term in a sequence from a fixed number of previous terms using <em>“delay taps”</em>.
            <blockquote>
              <p>It tries to predict the next term, <em>basically as a weighted average</em> (if model is linear) of the previous terms.</p>
            </blockquote>

            <p><img src="/main_files/concepts/11.png" alt="img" width="50%" /></p>
          </li>
          <li><strong>Feed-Forward Neural Nets</strong>:<br />
  Generalize Auto-regressive models by using one or more layers of non-linear hidden units e.g. Bengio’s first LM.<br />
  <img src="/main_files/concepts/12.png" alt="img" width="50%" /></li>
        </ul>

        <p id="lst-p"><strong style="color: red">Beyond Memoryless Models:</strong></p>
        <p>If we give our generative models some <em>hidden state</em>, and if we give this hidden state its own internal dynamics, we get a much more interesting kind of model.</p>
        <blockquote>
          <p>The hidden state produces <em>observations</em> that we get to <em>“observe/see”</em></p>
        </blockquote>

        <ul>
          <li>It can <strong>store information</strong> in its <em>hidden state</em> for a long time.</li>
          <li>If the dynamics is noisy and the way it generates outputs from its hidden state is noisy, (by observing the outputs of the model) we can never know its exact hidden state.
            <ul>
              <li>The best we can do is to infer a probability distribution over the space of hidden state vectors.</li>
            </ul>
          </li>
          <li>This <strong>inference</strong> (of the hidden states by observing the outputs of the model) is only <strong>tractable</strong> for <em>TWO</em> types of hidden-state models:
            <ol>
              <li><strong>Linear Dynamical Systems (LDS) (loved by Engineers):</strong>
                <ul>
                  <li>These are generative models. They have a real-valued hidden state that cannot be observed directly.
                    <ul>
                      <li>The hidden state has linear dynamics with Gaussian noise and produces the observations using a linear model with Gaussian noise.</li>
                      <li>There may also be driving inputs.</li>
                    </ul>
                  </li>
                  <li>To predict the next output (so that we can shoot down the missile) we need to infer the hidden state.
                    <ul>
                      <li>A linearly transformed Gaussian is a Gaussian. So the distribution over the hidden state given the data/observations so far is Gaussian (because all the noise in a LDS is Gaussian). It can be computed using <em>“Kalman filtering”</em>.
 <img src="/main_files/concepts/13.png" alt="img" width="35%" /></li>
                    </ul>
                  </li>
                </ul>
              </li>
              <li><strong>Hidden Markov Models (HMMs) (loved by computer scientists):</strong>
                <ul>
                  <li>Hidden Markov Models have a <strong>discrete one-of-N</strong> hidden state distributions (rather than <em>Gaussian</em> distributions). Transitions between states are stochastic and controlled by a transition matrix. The outputs produced by a state are stochastic.
                    <ul>
                      <li>We cannot be sure which state produced a given output (because the outputs produced by a state are stochastic). So the state is “hidden” (behind this <em>“probabilistic veil”</em>).</li>
                      <li>It is easy to represent a probability distribution across N states with N numbers.<br />
  So, even tho we cant know what state it is in for sure, we can easily represent the probability distribution</li>
                    </ul>
                  </li>
                  <li>To predict the next output we need to infer the probability distribution over hidden states.
                    <ul>
                      <li>HMMs have efficient algorithms for inference and learning (dynamic programming).<br />
 <img src="/main_files/concepts/14.png" alt="img" width="35%" /></li>
                    </ul>
                  </li>
                  <li><strong>A Fundamental Limitation of HMMs</strong>:
                    <ul>
                      <li>Consider what happens when a hidden Markov model generates data
                        <ul>
                          <li>At each time step it must select one of its hidden states. So with \(N\) hidden states it can only remember \(\log(N)\) bits about what it generated so far.</li>
                        </ul>
                      </li>
                      <li>Consider the information that the first half of an utterance contains about the second half:
                        <blockquote>
                          <p>This is the amount of info that the HMM needs to convey to the second half of an utterance it produces from the first half (having produced the first half)</p>
                        </blockquote>

                        <ul>
                          <li>The syntax needs to fit (e.g. number and tense agreement)</li>
                          <li>The semantics needs to fit. The intonation needs to fit.</li>
                          <li>The accent, rate, volume, and vocal tract characteristics must all fit.</li>
                        </ul>
                      </li>
                      <li>All these aspects combined could be \(100\) bits of information that the first half of an utterance needs to convey to the second half. Thus, needing about \(2^100\) hidden states to <em>“remember/store”</em> that information.   \(2^100\) is big!</li>
                    </ul>
                  </li>
                </ul>
              </li>
            </ol>
          </li>
        </ul>

        <p id="lst-p"><strong style="color: red">Recurrent Neural Networks (RNNs):</strong></p>
        <ul>
          <li>RNNs are very powerful, because they combine two properties:
            <ul>
              <li>Distributed hidden state that allows them to store a lot of information about the past efficiently.
                <blockquote>
                  <p>i.e. several different units can be active at once (unlike HMMs), so they can remember several different things at once.</p>
                </blockquote>
              </li>
              <li>Non-linear dynamics that allows them to update their hidden state in complicated ways (unlike LDSs).</li>
            </ul>
          </li>
          <li>
            <p>With enough neurons and time, RNNs can compute anything that can be computed by your computer.<br />
  <img src="/main_files/concepts/15.png" alt="img" width="15%" /></p>
          </li>
          <li><a href="https://distill.pub/2019/memorization-in-rnns/">Visualizing memorization in RNNs</a></li>
        </ul>

        <p><strong>Do generative models need to be stochastic?</strong></p>
        <ul>
          <li>
            <p>Linear dynamical systems and HMMs are stochastic models.<br />
  The dynamics and the production of observations from the underlying state both involve <strong>intrinsic noise</strong>.</p>

            <ul>
              <li>But the <strong>posterior probability distribution</strong> over their hidden states given the observed  data so far is a <em><strong>deterministic</strong> function of the data</em>.  <br />
  <br /></li>
            </ul>
          </li>
          <li>
            <p>Recurrent neural networks are deterministic.</p>
            <ul>
              <li>So think of the hidden state of an RNN as the equivalent of the <strong>deterministic probability distribution over hidden states</strong> in a linear dynamical system or hidden Markov model.</li>
            </ul>
          </li>
        </ul>

        <p><strong>What kinds of behavior can RNNs exhibit?</strong></p>
        <ul>
          <li>They can oscillate. Good for motor control? (e.g. walking needs varying <em>stride</em>)</li>
          <li>They can settle to point attractors. Good for retrieving memories?
            <blockquote>
              <p>By having the target point-attractors (to settle in) be the memories you want to retrieve.</p>
            </blockquote>
          </li>
          <li>They can behave chaotically. Bad for information processing?</li>
          <li>RNNs could potentially learn to implement lots of small programs (using different subsets of their hidden state) that each capture a nugget of knowledge and run in parallel, interacting to produce very complicated effects.</li>
          <li>But the computational power of RNNs makes them very hard to train
            <ul>
              <li>For many years we could not exploit the computational power of RNNs despite some heroic efforts (e.g. Tony Robinson’s speech recognizer)</li>
            </ul>
          </li>
        </ul>

        <p id="lst-p"><strong style="color: red">Notes:</strong></p>
        <ul>
          <li><strong>A Content-Addressable Memory</strong>: an item can be accessed by just knowing part of its content.</li>
        </ul>
      </li>
    </ul>

    <p id="lst-p"><strong style="color: red">Notes:</strong></p>
    <ul>
      <li><a href="https://arxiv.org/pdf/1602.03032.pdf">Associative LSTMs (Paper)</a><br />
 <br /></li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents24">Stability - Vanishing and Exploding Gradients:</strong><br />
 <!-- 
     5. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents2 #bodyContents25}
     6. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents2 #bodyContents26}
     7. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents2 #bodyContents27}
     8. **Notes:**{: style="color: SteelBlue"}{: .bodyContents2 #bodyContents28}           
 --></li>
</ol>

<hr />
<hr />

<h2 id="content3">Maths</h2>

<ol>
  <li><strong style="color: SteelBlue" class="bodyContents3" id="bodyContents31">Metrics and Quasi-Metrics:</strong><br />
 <button class="showText" value="show" onclick="showTextPopHide(event);">Show Content</button>
    <ul hidden="">
      <li>content:<br />
  A <strong>Metric (distance function)</strong> \(d\)  is a function that defines a distance between each pair of elements of a set \(X\).<br />
  A Metric induces a <em>topology</em> on a set; BUT, not all topologies can be generated by a metric.<br />
  Mathematically, it is a function:<br />
  \({\displaystyle d:X\times X\to [0,\infty )},\)<br />
  that must satisfy the following properties:
        <ol>
          <li>\({\displaystyle d(x,y)\geq 0}\) \(\:\:\:\:\:\:\:\)   non-negativity or separation axiom</li>
          <li>\({\displaystyle d(x,y)=0\Leftrightarrow x=y}\) \(\:\:\:\:\:\:\:\)  identity of indiscernibles</li>
          <li>\({\displaystyle d(x,y)=d(y,x)}\) \(\:\:\:\:\:\:\:\)  symmetry</li>
          <li>\({\displaystyle d(x,z)\leq d(x,y)+d(y,z)}\) \(\:\:\:\:\:\:\:\)  subadditivity or triangle inequality
            <blockquote>
              <p>The first condition is implied by the others.</p>
            </blockquote>
          </li>
        </ol>

        <p><button class="showText" value="show" onclick="showText_withParent_PopHide(event);">Examples</button><br />
  <img src="/main_files/concepts/10.png" alt="img" width="100%" hidden="" /><br />
  A <strong>Quasi-Metric</strong> is a metric that lacks the <em>symmetry</em> property.<br />
  One can form a Metric function \(d'\)  from a Quasi-metric function \(d\) by taking:<br />
  \(d'(x, y) = ​1⁄2(d(x, y) + d(y, x))\)</p>
      </li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents3" id="bodyContents32">Binary Relations (abstract algebra):</strong><br />
 <button class="showText" value="show" onclick="showTextPopHide(event);">Show Content</button>
    <ul hidden="">
      <li>
        <p>content:<br />
  A <strong>binary relation</strong> on a set \(A\) is a set of ordered pairs of elements of \(A\). In other words, it is a subset of the Cartesian product \(A^2 = A ×A\).  <br />
  The number of binary relations on a set of \(N\) elements is \(= 2^{N^2}\)</p>

        <p id="lst-p"><strong>Examples:</strong></p>
        <ul>
          <li>“is greater than”</li>
          <li>“is equal to”</li>
          <li>A function \(f(x)\)</li>
        </ul>

        <p id="lst-p"><strong>Properties:</strong>  (for a relation \(R\) and set \(X\))</p>
        <ul>
          <li><em>Reflexive:</em> for all \(x\) in \(X\) it holds that \(xRx\)</li>
          <li><em>Symmetric:</em> for all \(x\) and \(y\) in \(X\) it holds that if \(xRy\) then \(yRx\)</li>
          <li><em>Transitive:</em> for all \(x\), \(y\) and \(z\) in \(X\) it holds that if \(xRy\) and \(yRz\) then \(xRz\)<br />
  An <strong>Equivalence Relation</strong> has all of the above properties.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents3" id="bodyContents33">Set Theory:</strong>
    <ul>
      <li><strong>Number of subsets of a set of \(N\) elements</strong> \(= 2^N\)</li>
      <li><strong>Number of pairs (e.g. \((a,b)\)) of a set of \(N\) elements</strong> \(= N^2\)<br />
  e.g. \(\mathbb{R} \times \mathbb{R} = \mathbb{R}^2\)</li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents3" id="bodyContents34">Proof Methods:</strong><br />
 <button class="showText" value="show" onclick="showTextPopHide(event);">Show List</button>
    <ul hidden="">
      <li>Direct Proof</li>
      <li>Mathematical Induction
        <ul>
          <li>Strong Induction</li>
          <li>Infinite Descent</li>
        </ul>
      </li>
      <li>Contradiction</li>
      <li>Contraposition (\((p \implies q) \iff (!q \implies !p)\))</li>
      <li>Construction</li>
      <li>Combinatorial</li>
      <li>Exhaustion</li>
      <li>Non-Constructive proof (existence proofs)</li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents3" id="bodyContents35">Mathematical Concepts - The Map of Mathematics:</strong><br />
 <button class="showText" value="show" onclick="showTextPopHide(event);">Show Text</button>
    <ul hidden="">
      <li><strong>Real Analysis</strong>:<br />
  The Real line begets Real Analysis. It’s the study of real numbers and continuous functions on the reals. You have a concrete object (real numbers) and a concrete distance measure (the absolute value function) which is needed for the notions of convergence and continuity.</li>
      <li><strong>Metric Spaces</strong>:<br />
  Less concrete than Real Analysis. You have a numerical way of explaining proximity by a distance measure, and you have a similar way of explaining convergence and continuity. Functional Analysis lies in the middle of those two.</li>
      <li><strong>Topology</strong>:<br />
  Studies topological spaces, WHERE, everything is up for grabs. The proximity measure is no longer numerical. The proximity “measure” around a point is a poset-like at best. This makes the notions of convergence and continuity more tricky.</li>
      <li><strong>Functional Analysis</strong>:<br />
  Can be thought of as a generalization of Linear Algebra to infinite dimensional vector spaces (e.g. spaces of functions with a given property - e.g. continuity).</li>
      <li><strong>Differential Topology</strong>:<br />
  is the study of smooth manifolds and smooth maps. It is fundamentally using tools from calculus (hence the “differential” part in the name) but the focus is on spaces and maps up to diffeomorphism, which means that you don’t care at all about notions like angles, lengths, curvature, flatness etc. Just like in ordinary (non-differential) topology, a gently curved line, a straight line, and a totally squiggly line are all the same up to diffeomorphism (the squiggly line should have no sharp cusps and corners though, which is how this is different from ordinary topology).
        <ul>
          <li><strong>Pre-Reqs:</strong> include a very good foundation in real analysis, including multivariate differential analysis; linear algebra; and topology.</li>
        </ul>
      </li>
      <li><strong>Differential Geometry</strong>:<br />
  Its the study of precisely those things that differential topology doesn’t care about (i.e. angles, curvature, etc.). Here the principal objects of study are manifolds endowed with the much more rigid structure of a (Riemannian) metric, which lets you discuss geometric properties like lengths, angles and curvature.
        <ul>
          <li><strong>Applications</strong>:<br />
  It ties well with: Lie Groups, General Relativity, Symplectic Geometry (Mechanics), Algebraic Topology.</li>
          <li><strong>Pre-Reqs</strong>: similar to those for Differential Topology: solid multivariate analysis, some topology, and of course linear algebra.</li>
        </ul>
      </li>
      <li><strong>Algebraic Topology</strong>:<br />
  the study of algebraic invariants as a tool for classifying topological objects.
        <blockquote>
          <p>Some of those invariants can actually be developed via differential topology (de Rham cohomology), but most are defined in completely different terms that do not need the space to have any differential structure whatsoever.</p>
        </blockquote>
        <ul>
          <li><strong>Pre-Reqs</strong>: Hard + Touches a lot of math; topology, a good grounding in algebra (abelian groups, rings etc.), know something about categories and functors.</li>
        </ul>
      </li>
      <li><strong>Algebraic Geometry</strong>:<br />
  very different topic. At the most basic level, its the study of <em>algebraic varieties</em> (i.e. sets of solutions to polynomial equations).<br />
  Modern algebraic geometry, however, is much wider than this innocent statement seems to imply. It is notoriously complex and requires a very deep understanding of a wide variety of disciplines and domains.
        <ul>
          <li><strong>Pre-Reqs</strong>: commutative algebra, Galois theory, some number theory (especially algebraic number theory), complex function theory, category theory, and a serving of algebraic topology wouldn’t hurt.<br />
  General topology is sort-of required: algebraic geometry uses the notion of “Zariski topology” but, honestly, this topology is so different from the things most analysts and topologists talk about that basic topology won’t help.</li>
        </ul>
      </li>
    </ul>

    <p><a href="https://www.quora.com/What-are-the-differences-between-differential-topology-differential-geometry-algebraic-topology-and-algebraic-geometry-In-what-order-does-one-usually-go-about-learning-them">Further Reading</a></p>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents3" id="bodyContents36">From Topology to Algebraic Topology:</strong><br />
 <button class="showText" value="show" onclick="showTextPopHide(event);">Analysis</button>
    <ul hidden="">
      <li>Suppose we have a closed loop of rope, i.e., a rope with its ends connected together. Such a closed loop could be a simple ring or it could be knotted up in various different ways:<br />
  <img src="/main_files/concepts/2.png" alt="img" width="100%" /></li>
      <li>Now, whether or not it is knotted does not depend on how thick the rope is, how long the rope is, or how it is positioned in space. As long as we don’t cut the rope, any kind of continuous deformation of the rope, such as moving it around, stretching it, bending it, and so on, does not change an unknotted closed loop into a knotted one. So, if we want to study the possible different ways a closed loop can be knotted, we want to ignore any differences related to all these various kinds of continuous deformations. When we ignore all those properties, what is left are called topological properties. So, while two closed loops of different sizes or shapes are geometrically distinct, they could be topologically identical. They are topologically distinct only if they can not be transformed into each other with any continuous deformation. So, in the context of knot theory, topology is the study of the properties of knottedness, which do not depend on the details of position, shape, size, and so on.</li>
      <li>Now, algebraic topology is a way of studying topological properties by translating them into algebraic properties. In the case of knot theory, this might involve, for example, a map that assigns a unique integer to any given closed loop. Such a map can be very useful if we can show that it will always assign the same integer to two closed loops that can be continuously deformed into each other, i.e., topologically equivalent closed loops are always assigned the same number. (Such a map is called a knot invariant.) For example, if we are given two closed loops and they are mapped to different integers, then this instantly tells us that they are topologically distinct from each other. The converse is not necessarily true, since a map with poor “resolving power” might take many topologically distinct closed loops to the same integer. Algebraic topology in the context of knot theory is the study of these kinds of maps from topological objects such as closed loops to algebraic objects such as integers. These maps give, as it were, algebraic perspectives on the topological objects, and that is what algebraic topology in general is about.</li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents3" id="bodyContents37">Notes:</strong>
    <ul>
      <li><strong>Dot Product Scale/Magnitude</strong>: the scale of the dot product increases as dimensions get larger.<br />
  Assume that the components of \(q\) and \(k\) are independent random variables with mean \(0\) and variance \(1\). Then their dot product, \(q^Tk = \sum_{i=1}^{d_k} q_ik_i\), (where \(d_k = \vert k \vert\) is the dimension of \(k \in \mathbb{R}^{d_k} \iff q \in \mathbb{R}^{d_q}\)) has mean \(0\) and variance \(d_k\).</li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents3" id="bodyContents38">Formulas:</strong><br />
 <button class="showText" value="show" onclick="showTextPopHide(event);">Show Formulas</button>
    <ul hidden="">
      <li><strong>Binomial Theorem</strong>:
        <p>$$(x+y)^{n}=\sum_{k=0}^{n}{n \choose k}x^{n-k}y^{k}=\sum_{k=0}^{n}{n \choose k}x^{k}y^{n-k} \\={n \choose 0}x^{n}y^{0}+{n \choose 1}x^{n-1}y^{1}+{n \choose 2}x^{n-2}y^{2}+\cdots +{n \choose n-1}x^{1}y^{n-1}+{n \choose n}x^{0}y^{n},$$</p>
      </li>
      <li><strong>Binomial Coefficient</strong>:
        <p>$${\binom {n}{k}}={\frac {n!}{k!(n-k)!}} = {n \text{ choose } k} = {n \choose (n-k)}$$</p>
      </li>
      <li><strong>Expansion \(x^n - y^n\)</strong>:
        <p>$$x^n - y^n = (x-y)(x^{n-1} + x^{n-2} y + ... + x y^{n-2} + y^{n-1})$$</p>
      </li>
      <li><strong>Number of subsets of a set of \(N\) elements</strong> \(= 2^N\)
        <ul>
          <li><strong>Number of pairs (e.g. \((a,b)\)) of a set of \(N\) elements</strong> \(= N^2\)</li>
          <li><strong>Number of subsets of size \(k\)</strong> \(= {\binom {n}{k}}\)
            <ul>
              <li>There are at most \(k^N\) ways to partition \(N\) data points into \(k\) clusters - there are \(N\) choose \(k\) clusters, precisely</li>
            </ul>
          </li>
        </ul>
      </li>
      <li><strong>Permutations and Combinations</strong>:
        <ul>
          <li><strong>Permutations of a set of size \(N\)</strong>  \(= N!\)</li>
          <li><a href="https://math.stackexchange.com/questions/2852683/how-many-subsets-of-size-k-from-1-2-n-such-that-if-subset-contains-2-it-doe">Set Inclusion/Exclusion (stackex)</a><br />
  e.g. \(\left|S_{1} \cup S_{2}\right|=\left|S_{1}\right|+\left|S_{2}\right|-\left|S_{1} \cap S_{2}\right|=2\left|S_{1}\right|-\left|S_{1} \cap S_{2}\right|\)</li>
          <li><strong>Number of Subsets of size \(k\) where 1 element \(i\) always appears</strong>: \(\left(\begin{array}{l}n-1 \\ k-1 \end{array}\right)\)<br />
  (e.g. the number of sets that include the element \(1\))
            <ul>
              <li><strong>Intuition</strong>: you have already chosen two elements (\(1\) and \(2\)), now there are \(k-2\) slots left in each subset and \(n-2\) elements left to choose from.</li>
            </ul>
          </li>
          <li><strong>Number of Subsets of size \(k\) where 2 element \(i\) and \(j\) appear together</strong>: \(\left(\begin{array}{l}n-2 \\ k-2 \end{array}\right)\)<br />
  (e.g. the number of sets that include both \(1\) and \(2\))<br />
  <button class="showText" value="show" onclick="showTextPopHide(event);">Diagram</button>
  <img src="https://cdn.mathpix.com/snip/images/726OtLVApY6cM75FeWVsxKTNWwN7I3C3OGioTOea9xU.original.fullsize.png" alt="img" width="70%" hidden="" /></li>
        </ul>
      </li>
      <li><strong>Logarithms</strong>:
        <p>$$\log_x(y) = \dfrac{\ln(y)}{\ln(x)}$$</p>
      </li>
      <li><strong>The length of a vector \(\mathbf{x}\)  along a direction (projection)</strong>:
        <ol>
          <li>Along a unit-length vector \(\hat{\mathbf{w}}\): \(\text{comp}_ {\hat{\mathbf{w}}}(\mathbf{x}) = \hat{\mathbf{w}}^T\mathbf{x}\)</li>
          <li>Along an unnormalized vector \(\mathbf{w}\): \(\text{comp}_ {\mathbf{w}}(\mathbf{x}) = \dfrac{1}{\|\mathbf{w}\|} \mathbf{w}^T\mathbf{x}\)</li>
        </ol>
      </li>
      <li><strong>Summations</strong>:
        <ul>
          <li>
\[\sum_{i=1}^{n} 2^{i}=2^{n+1}-2\]
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents3" id="bodyContents39">Linear Algebra:</strong>     <br />
 <strong style="color: red">Matrices:</strong>
    <ul>
      <li><strong style="color: blue">Symmetric Matrices:</strong>
        <ul>
          <li>can choose its eigenvectors to be <strong>orthonormal</strong></li>
        </ul>
      </li>
      <li><strong style="color: blue">PSD:</strong></li>
      <li><strong style="color: blue">PD:</strong></li>
    </ul>
  </li>
</ol>

<hr />
<hr />

<h2 id="content4">Statistics and Probability Theory</h2>

<ol>
  <li><strong style="color: SteelBlue" class="bodyContents4" id="bodyContents41">ROC Curve:</strong>
    <ul>
      <li>A way to quantify how good a <strong>binary classifier</strong> separates two classes</li>
      <li>True-Positive-Rate / False-Positive-Rate</li>
      <li>Good classifier has a ROC curve that is near the top-left diagonal (hugging it)</li>
      <li>A Bad Classifier has a ROC curve that is close to the diagonal line</li>
      <li>It allows you to set the <strong>classification threshold</strong>
        <ul>
          <li>You can minimize False-positive rate or maximize the True-Positive Rate</li>
        </ul>
      </li>
    </ul>

    <p id="lst-p"><strong style="color: red">Notes:</strong></p>
    <ul>
      <li>ROC curves (&amp; AUC) are useful even if the <strong>predicted probabilities</strong> are not <em><strong>“properly calibrated”</strong></em><br />
 <br /></li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents4" id="bodyContents42">AUC - AUROC:</strong>
    <ul>
      <li>Range \(= 0.5 - 1.0\), from poor to perfect<br />
 <br /></li>
    </ul>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents4" id="bodyContents43">Statistical Efficiency:</strong><br />
 Essentially, a more efficient estimator, experiment, or test needs fewer observations than a less efficient one to achieve a given performance.<br />
 Efficiencies are often defined using the <em>variance</em> or <em>mean square error</em> as the measure of desirability.<br />
 An efficient estimator is also the minimum variance unbiased estimator (MVUE).</p>

    <ul>
      <li>An Efficient Estimator has lower variance than an inefficient one</li>
      <li>The use of an inefficient estimator gives results equivalent to those obtainable from a subset of data; and is therefor, wasteful of data</li>
    </ul>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents4" id="bodyContents44">Errors VS Residuals:</strong><br />
 The <strong>Error</strong> of an observed value is the deviation of the observed value from the (unobservable) <strong><em>true</em></strong> value of a quantity of interest.</p>

    <p>The <strong>Residual</strong> of an observed value is the difference between the observed value and the <em><strong>estimated</strong></em> value of the quantity of interest.</p>

    <ul>
      <li><a href="https://en.wikipedia.org/wiki/Errors_and_residuals#In_univariate_distributions" value="show" onclick="iframePopA(event)"><strong>Example in Univariate Distributions</strong></a>
 <a href="https://en.wikipedia.org/wiki/Errors_and_residuals#In_univariate_distributions"></a>
        <div></div>
      </li>
    </ul>

    <p><!-- 5. **Maximum Likelihood Estimation:**{: style="color: SteelBlue"}{: .bodyContents4 #bodyContents45}   --></p>
  </li>
</ol>

<!-- 6. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents4 #bodyContents46}  
7. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents4 #bodyContents47}  
    :     -->

<p id="lst-p"><strong style="color: SteelBlue" class="bodyContents4" id="bodyContents48">Notes:</strong></p>
<ul>
  <li><strong>Why maximize the natural log of the likelihood?</strong>:
    <ol>
      <li>Numerical Stability: change products to sums</li>
      <li>The logarithm of a member of the family of exponential probability distributions (which includes the ubiquitous normal) is polynomial in the parameters (i.e. max-likelihood reduces to least-squares for normal distributions)<br />
  \(\log\left(\exp\left(-\frac{1}{2}x^2\right)\right) = -\frac{1}{2}x^2\)</li>
      <li>The latter form is both more numerically stable and symbolically easier to differentiate than the former. It increases the dynamic range of the optimization algorithm (allowing it to work with extremely large or small values in the same way).</li>
      <li>The logarithm is a monotonic transformation that preserves the locations of the extrema (in particular, the estimated parameters in max-likelihood are identical for the original and the log-transformed formulation)</li>
    </ol>
  </li>
  <li><a href="http://anotherdatum.com/gumbel-gan.html"><strong>(GANs) Sampling from Discrete Distributions | The Gumbel-Softmax Trick</strong></a></li>
  <li><strong>Covariance Matrix</strong> is the inverse of the <strong>Metric Tensor</strong>
    <ul>
      <li>In <strong>Gaussians</strong>: \(\Sigma^{1/2}\) maps spheres to ellipsoids; eigenvalues are radii; they are also the standard deviations along the eigenvectors</li>
    </ul>
  </li>
  <li><strong>Reason we sometimes prefer Biased Estimators</strong>:<br />
  Mainly, due to the <em><strong>Bias-Variance Decomposition</strong></em>. The <strong>MSE</strong> takes into account both the <em>bias</em> and the <em>variance</em> and sometimes the biased estimator might have a lower variance than the unbiased one, which results in a total <em>decrease</em> in the MSE.</li>
  <li><strong>Cross-Field Terms</strong>:
    <ul>
      <li>Independent Variable \(\iff\)  Covariate \(\iff\)  Feature </li>
      <li>(Collection of) Independent Variables \(\iff\)  Covariates \(\iff\)  Features \(\iff\)  Input </li>
      <li>Dependent Variable \(\iff\)  Response \(\iff\)  Label \(\iff\)  Target \(\iff\)  Output</li>
      <li><a href="https://towardsdatascience.com/the-actual-difference-between-statistics-and-machine-learning-64b49f07ea3">Statistics VS Machine Learning</a></li>
    </ul>
  </li>
  <li><strong>Uncorrelated Features in a Design Matrix</strong>:
    <p>$$\implies X^TX=nI$$</p>
  </li>
  <li><strong>Expectation Maximization (EM) Algorithm</strong>:<br />
  <a href="http://bjlkeng.github.io/posts/the-expectation-maximization-algorithm/">EM-Algo Math</a></li>
</ul>

<hr />
<hr />

<h2 id="content5">Optimization</h2>

<ol>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents5" id="bodyContents51">Sigmoid:</strong><br />
 \(\sigma(-x) = 1 - \sigma(x)\)</p>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents5" id="bodyContents52">Gradient-Based Optimization:</strong><br />
 <strong style="color: red">Notes:</strong>
    <ul>
      <li>Gradients can’t propagate through <strong>argmax</strong></li>
      <li><strong>Derivative for a max function</strong>:<br />
  The derivative is defined (even though its not continuous at the threshold) by setting the value at the threshold/zero to be either the right or the left derivative.<br />
  This is known as the <strong>Sub-Gradient</strong> and that’s why <em>gradient descent</em> still works.</li>
      <li><a href="https://www.youtube.com/watch?v=jYtCiV1aP44&amp;list=PLnZuxOufsXnvftwTB1HL6mel1V32w0ThI&amp;index=12&amp;t=0s"><strong>Subgradient Descent</strong></a></li>
      <li><a href="https://www.youtube.com/embed/K2X0eBd-0lc?list=PLoRl3Ht4JOcdU872GhiYWf6jwrk_SNhz9" value="show" onclick="iframePopA(event)"><strong>Hessian-Free Optimization | Conjugate Gradient Method (Hinton)</strong></a>
 <a href="https://www.youtube.com/embed/K2X0eBd-0lc?list=PLoRl3Ht4JOcdU872GhiYWf6jwrk_SNhz9"></a>
        <div></div>
      </li>
    </ul>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents5" id="bodyContents53">Backpropagation:</strong></p>

    <p><strong>NOTES:</strong></p>
    <ul>
      <li><a href="https://www.mladdict.com/neural-network-simulator">Neural Network Simulator for learning Backprop</a></li>
    </ul>

    <p><button class="showText" value="show" onclick="showText_withParent_PopHide(event);">Show</button></p>
    <ul hidden="">
      <li><strong>Backprop (BPTT specifically here) and concept of Locality</strong>:<br />
  In this context, local in space means that a unit’s weight vector can be updated using only information stored in the connected units and the unit itself such that update complexity of a single unit is linear in the dimensionality of the weight vector. Local in time means that the updates take place continually (on-line) and depend only on the most recent time step rather than on multiple time steps within a given time horizon as in BPTT. Biological neural networks appear to be local with respect to both time and space. <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network#Gradient_descent">wikipedia</a></li>
      <li><strong>Backpropagation with weight constraints</strong>:
        <ul>
          <li>It is easy to modify the backprop algorithm to incorporate linear constraints between the weights.
            <p>$$\begin{array}{l}{\text { To constrain: } w_{1}=w_{2}} \\ {\text { we need : } \Delta w_{1}=\Delta w_{2}}\end{array}$$</p>
            <p>So, we compute the gradients as usual for each \(w_i\) then average them and update both weights (so they’ll continue to satisfy the constraints).</p>
          </li>
        </ul>
      </li>
      <li>Backprop is a <strong>Leaky Abstraction</strong></li>
      <li><strong>Properties of Loss Functions for Backpropagation</strong>:<br />
  The mathematical expression of the loss function must fulfill two conditions in order for it to be possibly used in back propagation.[3] The first is that it can be written as an average \({\textstyle E={\frac {1}{n}}\sum _{x}E_{x}}\) over error functions \({\textstyle E_{x}}\) {\textstyle E_{x}}, for \({\textstyle n}\) individual training examples, \({\textstyle x}\). The reason for this assumption is that the backpropagation algorithm calculates the gradient of the error function for a single training example, which needs to be generalized to the overall error function. The second assumption is that it can be written as a function of the outputs from the neural network.</li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents5" id="bodyContents54">Error Measures - Loss Functions:</strong>
    <ul>
      <li><strong>Cross Entropy</strong>:
        <ul>
          <li><strong>Deriving Binary Cross Entropy</strong>:<br />
  It is the log-likelihood of a Bernoulli probability model.
            <p>$$\begin{array}{c}{L(p)=p^{y}(1-p)^{1-y}} \\ {\log (L(p))=y \log p+(1-y) \log (1-p)}\end{array}$$</p>
          </li>
          <li><strong><a href="https://jamesmccaffrey.wordpress.com/2013/11/05/why-you-should-use-cross-entropy-error-instead-of-classification-error-or-mean-squared-error-for-neural-network-classifier-training/">Cross Entropy &gt; MSE for Classification</a></strong><br />
 <br /></li>
        </ul>
      </li>
    </ul>

    <p id="lst-p"><strong style="color: red">Notes:</strong></p>
    <ul>
      <li><strong>Loss VS Cost Function</strong>:
        <ul>
          <li>Loss is just the Error function from Caltech</li>
          <li>Cost is more general than Loss: usually the sum of all the losses</li>
          <li><strong>Objective function</strong> is even more general, but a Cost might be a type of <strong>Objective Function</strong>
            <ul>
              <li>The <strong>Risk Function</strong> is an objective function is the expected loss</li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="https://www.youtube.com/watch?v=1oi_Mwozj5w&amp;list=PLnZuxOufsXnvftwTB1HL6mel1V32w0ThI&amp;index=8"><strong>Loss Functions for Regression</strong></a></li>
      <li><strong>MSE</strong>:<br />
  The principle of mean square error can be derived from the principle of maximum likelihood (after we set a linear model where errors are normally distributed).</li>
      <li><strong>Hinge Loss and 0-1 Loss</strong>:
        <ul>
          <li>Hinge loss upper bounds 0-1 loss</li>
          <li>It is the tightest <em>convex</em> upper bound on the 0/1 loss</li>
          <li>Minimizing 0-1 loss is NP-hard in the worst-case<br />
  img</li>
        </ul>
      </li>
      <li><strong>Loss functions of common ML models</strong>:
        <ul>
          <li>maximize the posterior probabilities (e.g., naive Bayes)</li>
          <li>maximize a fitness function (genetic programming)</li>
          <li>maximize the total reward/value function (reinforcement learning)</li>
          <li>maximize information gain/minimize child node impurities (CART decision tree classification)</li>
          <li>minimize a mean squared error cost (or loss) function (CART, decision tree regression, linear regression, adaptive linear neurons, …</li>
          <li>maximize log-likelihood or minimize cross-entropy loss (or cost) function</li>
          <li>minimize hinge loss (support vector machine)<br />
 <br /></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents5" id="bodyContents55">Mathematical Properties, Aspects, Considerations:</strong>
    <ul>
      <li><strong>The Composition of Invariant Functions</strong>:<br />
  A function that is <em>invariant</em> to some transformation (e.g. rotation, permutation, etc.) can be composed by averaging over all transformations (rotations \(\rightarrow\) e.g. rotation invariant filters).<br />
  Equivalently, for <em>BoW</em>, we average over all permutations (by averaging the words).<br />
  This causes <em><strong>smearing</strong></em>.</li>
      <li><strong>Smearing in Invariant Functions</strong>:<br />
  In the linear case, a rotational invariant function commutes with all rotations of the elements in \(\mathbb{R}\); Any commutative transformation should yield this; or a combo of commutative transformations; thus smearing.
        <blockquote>
          <p>Implies that one should not use linear functions to aggregate over the set where we want some transformation invariance</p>
        </blockquote>
      </li>
      <li><strong>Permutation Invariance</strong>:
        <ul>
          <li><a href="https://www.inference.vc/deepsets-modeling-permutation-invariance/">DeepSets: Modeling Permutation Invariance</a></li>
        </ul>
      </li>
      <li><strong>The Weight vector of a linear signal is orthogonal to the decision boundary</strong>:<br />
  The weight vector \(\mathbf{w}\) is orthogonal to the separating-plane/decision-boundary, defined by \(\mathbf{w}^T\mathbf{x} + b = 0\), in the \(\mathcal{X}\) space; Reason:<br />
  Since if you take any two points \(\mathbf{x}^\prime\) and \(\mathbf{x}^{\prime \prime}\) on the plane, and create the vector \(\left(\mathbf{x}^{\prime}-\mathbf{x}^{\prime \prime}\right)\)  parallel to the plane by subtracting the two points, then the following equations must hold:
        <p>$$\mathbf{w}^{\top} \mathbf{x}^{\prime}+b=0 \wedge \mathbf{w}^{\top} \mathbf{x}^{\prime \prime}+b=0 \implies \mathbf{w}^{\top}\left(\mathbf{x}^{\prime}-\mathbf{x}^{\prime \prime}\right)=0$$</p>
      </li>
    </ul>

    <p id="lst-p"><strong style="color: red">Identities:</strong></p>
    <ul>
      <li><strong>Math Identities</strong>:
        <p>$$\frac{1}{N} \sum_{n=1}^{N}\left(\mathbf{w}^{\mathrm{T}} \mathbf{x}_{n}-y_{n}\right)^{2} = \frac{1}{N}\|\mathrm{Xw}-\mathrm{y}\|^{2}$$</p>
        <ul>
          <li>\(\dfrac{\partial}{\partial y} \vert{x-y}\vert  = - \text{sign}(x-y)\)<br />
 <br /></li>
        </ul>
      </li>
    </ul>

    <p id="lst-p"><strong style="color: red">Notes:</strong></p>
    <ul>
      <li>The <strong>well-behaved</strong> property from an optimization standpoint, implies that \(f''(x)\) doesn’t change too much or too rapidly, leading to a nearly quadratic function that is easy to optimize by gradient methods.</li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents5" id="bodyContents56">The Method of Lagrange Multipliers:</strong><br />
 The <strong>constrained</strong> optimization problem:
    <p>$$\min_{\mathbf{x}} f(\mathbf{x}) \text { subject to } g(\mathbf{x}) \leq 0$$</p>
    <p>is equivalent to the <strong>unconstrained</strong> optimization problem:</p>
    <p>$$\min_{\mathbf{x}}(f(\mathbf{x})+\lambda g(\mathbf{x}))$$</p>
    <p>where \(\lambda\) is a scalar called the <strong>Lagrange multiplier</strong>.<br />
<br /></p>
  </li>
</ol>

<!-- 7. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents5 #bodyContents57}  

8. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents5 #bodyContents58}  -->

<p><strong>NOTES:</strong></p>
<ul>
  <li><a href="https://medium.com/inveterate-learner/deep-learning-book-chapter-8-optimization-for-training-deep-models-part-i-20ae75984cb2">Ch.8 Dl-book summary</a></li>
  <li><a href="https://jamesmccaffrey.wordpress.com/2013/11/05/why-you-should-use-cross-entropy-error-instead-of-classification-error-or-mean-squared-error-for-neural-network-classifier-training/">Why You Should Use Cross-Entropy Error Instead Of Classification Error Or Mean Squared Error For Neural Network Classifier Training</a></li>
  <li>Points that satisfy all constraints (i.e. the feasible region) always convex and polytope.</li>
  <li><strong><a href="http://ruder.io/optimizing-gradient-descent/index.html#gradientdescentoptimizationalgorithms">Optimization Blog on opt techniques</a></strong></li>
  <li><a href="https://www.youtube.com/watch?v=FDCfw-YqWTE&amp;list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc&amp;index=10&amp;t=0s">WHY NORMALIZE THE INPUTS/DATA/SIGNAL</a></li>
  <li><a href="http://math.oregonstate.edu/~show/old/142_Luenberger.pdf">Optimization by Vector Space Methods (book)</a></li>
  <li><a href="https://web.stanford.edu/~mrosenfe/soc_meth_proj3/matrix_OLS_NYU_notes.pdf"><strong>OLS Derivation and Theory</strong></a></li>
</ul>

<p><br /></p>

<hr />
<hr />

<h2 id="content6">Machine Learning</h2>

<ol>
  <li><strong style="color: SteelBlue" class="bodyContents6" id="bodyContents61">Theory:</strong>
    <ul>
      <li><strong>ML from a Probabilistic Approach</strong>:<br />
  When employing a <em>probabilistic approach</em> to doing <em>“learning”</em> (i.e. choosing the hypothesis), you are trying to find: <strong>What is the most probable hypothesis, given the Data</strong>.</li>
    </ul>

    <p><strong>Why NNs are not enough?</strong><br />
 The gist of it is this: neural nets do <em>pattern recognition</em>, which achieves <em>local generalization</em> (which works great for supervised perception). But many simple problems require some (small) amount of abstract modeling, which modern neural nets can’t learn.</p>

    <p><strong>Is there enough info in the labels to learn good, general features in Classification problems?</strong><br />
 <button class="showText" value="show" onclick="showText_withParent_PopHide(event);">Show Text</button></p>
    <p hidden="">(((If the task is to learn to classify a particular image into one class/category; and the categories lie on the same manifold (i.e. just cats and dogs; or just vehicles etc.) then, the model can learn the patterns that relate to the particular class the image belongs to, BUT MOREOVER, it learns to ignore the rest of the patterns (i.e. background). So, in a way, yes, there is no information in the labels that tells the network to learn what a tree is (so any objects in the background are somewhat blurred to the network, they have no higher-order meaning) so the overall higher-level vision capabilities of the network doesn't necessarily "develop".   <br />
 As for the task of pre-training, we both know that even if you learn the patterns of very specific objects/classes (e.g. cats and dogs) you still need to develop certain visual features (e.g. edge/corner detection) and those featurizers will develop well, regardless of the amount of information. i.e. the lower-level visual capabilities will be developed. (we have evidence that pretraining works really well in Vision).  <br />
 I think the issue here is with Deterministic Noise (i.e. the Bias of the model). The CNN hypothesis just doesn't do things like inverse graphics and whatnot; regardless of the amount of information.  <br />
 Finally, a big problem is when the information is just conflicting, like two objects that should be recognized but we only label it as one of them. That's the Stochastic Noise. Which relates directly to how well we would generalize. This can be attributed to many things as well: E.g. (1) One-hot vectors need to be smoothed to allow the network to get a sense of the actual different objects in the image, AND to not over-fit the particulars of the data (e.g. consider a cat that looks like a tiger and a cat that looks like a dog; labeling it with 0.8 cat is much better to learn the "cattiness" of the image than the noise) (2) Target labels are just limited. There aren't enough categories in the target, which puts a huge limitation for one-shot learning generalization)))</p>

    <p id="lst-p"><strong>Neural Tangent Kernel:</strong></p>
    <ul>
      <li><a href="https://www.youtube.com/watch?v=raT2ECrvbag">Video</a></li>
      <li><a href="https://arxiv.org/pdf/1806.07572.pdf">Neural Tangent Kernel: Convergence and Generalization in Neural Networks (paper)</a></li>
    </ul>

    <p><strong>NTK Theorem:</strong> A properly randomly initialized <span style="color: purple">sufficiently wide</span> deep neural network <span style="color: purple">trained by gradient descent</span> with infinitesimal step size (a.k.a. gradient flow) is <span style="color: purple">equivalent to a kernel regression predictor</span> with a <span style="color: purple">deterministic</span> kernel called neural tangent kernel (NTK).</p>

    <p>Thus, As width (of NN) \(\rightarrow \infty\), trajectory approaches the trajectory of GD for a kernel regression problem, where the (fixed) kernel in question is the so-called Neural Tangent Kernel (NTK). (For convolutional nets the kernel is Convolutional NTK or CNTK.)<br />
 The paper proves that the evolution of an ANN during training can also be described by a kernel.</p>

    <p id="lst-p"><strong style="color: red">Analysis and Discussion:</strong></p>
    <ul>
      <li>Start with: Fully-Connected Network, Any Depth, Lipschitz Non-Linearity</li>
      <li>Gather all <strong>parameters</strong> in the network into one vector \(\theta\): initialized randomly, trained w/ GD</li>
      <li>Since cost is non-convex, the analysis is difficult</li>
      <li>Instead, study the network function \(f_{\theta} : \mathbb{R}^{n_0} \rightarrow \mathbb{R}^{n_L}\) which maps inputs to outputs<br />
  We fully characterize the behavior of \(f_{\theta}\) in the <strong>infinite-width limit</strong> (# of neurons in hidden layer \(\rightarrow \infty\))</li>
      <li><strong>Behavior in the limit of the width:</strong>
        <ul>
          <li>In the limit, the network function has a <strong>Gaussian distribution</strong> at <em><strong>initialization</strong></em><br />
  <button class="showText" value="show" onclick="showTextPopHide(event);">Plot of 20 random initialization of \(f_{\theta}\) on the unit circle</button>
  <img src="https://cdn.mathpix.com/snip/images/dWbTf3G6bbXIF7jMNZMD9wbRv2fwXgGYRvvvLCRyjPM.original.fullsize.png" alt="img" width="55%" hidden="" /></li>
          <li>The effect of GD on a single point \(\boldsymbol{x}_ 0\) at initialization is to move that point and nearby points slightly<br />
  <button class="showText" value="show" onclick="showTextPopHide(event);">graph</button>
  <img src="https://cdn.mathpix.com/snip/images/O3g9y_EIlF4v0KDqkvs3uG3MJC9UG28M0BzkgVseyJY.original.fullsize.png" alt="img" width="55%" hidden="" /></li>
          <li>The difference between the two time-steps results in a <strong>smooth spike</strong> centered at \(\boldsymbol{x}_ 0\)<br />
  <button class="showText" value="show" onclick="showTextPopHide(event);">graph</button>
  <img src="https://cdn.mathpix.com/snip/images/q4Hiw3g9THS93MVV_eBJvWLfmEeNuui81mYfzKf-lzM.original.fullsize.png" alt="img" width="55%" hidden="" /></li>
          <li>The difference is the same for different initializations.<br />
  <button class="showText" value="show" onclick="showTextPopHide(event);">graph</button>
  <img src="https://cdn.mathpix.com/snip/images/wi4MRjf0aCh4hIquTJxG-Bqg8Pztg_sIYDOXDJoEwLw.original.fullsize.png" alt="img" width="55%" hidden="" /></li>
          <li>As we increase the <strong>width</strong> of the network, they differences become even more similar<br />
  <button class="showText" value="show" onclick="showTextPopHide(event);">graph</button>
  <img src="https://cdn.mathpix.com/snip/images/KytLYBbrNPzO76F4dlFYKDf_HcIZ1ZFHbLcIIUxjhd4.original.fullsize.png" alt="img" width="55%" hidden="" /></li>
          <li>The behavior is <strong>linear</strong> i.e. adding another datapoint \(\boldsymbol{x}_ 1\)  results in the two spikes being <strong>added up</strong><br />
  <button class="showText" value="show" onclick="showTextPopHide(event);">graph</button>
  <img src="https://cdn.mathpix.com/snip/images/H4sVN01wI0Tc2GWXUmRwM9tgjoUrJb9MeM-VvvXLLfI.original.fullsize.png" alt="img" width="100%" hidden="" /></li>
        </ul>
      </li>
      <li>This behavior in the limit can be nicely described by a <strong>kernel</strong>.<br />
  The <strong>Neural Tangent Kernel (NTK)</strong>:<br />
  <img src="https://cdn.mathpix.com/snip/images/Rym-odIEPt0sZJuKmvccyeBFasKNM_LZWm060ONv_cI.original.fullsize.png" alt="img" width="30%" class="center-image" />
        <ul>
          <li><strong>Defined</strong>: in terms of the <span style="color: purple">derivatives of the function wrt the parameters \(\theta\)</span></li>
          <li><strong>Describes</strong>: how <span style="color: purple"><em>modifying</em> the <strong>network function \(f_{\theta}\)</strong> at the point \(\boldsymbol{x}\) will <em>influence</em> another point \(\boldsymbol{y}\)</span></li>
        </ul>
      </li>
      <li><strong>Properties</strong>:
        <ul>
          <li><strong>Finite Width</strong>:<br />
  <em><strong>Depends</strong></em> on the <strong>parameters</strong>, thus it is:
            <ul>
              <li><span style="color: purple"><strong>Random</strong> at initialization  </span></li>
              <li><span style="color: purple"><strong>Time-dependent</strong></span>: varies during training</li>
            </ul>
          </li>
          <li><strong>Infinite width limit</strong> :
            <p>$$\theta^{(L)}(x, y) \rightarrow \theta_{\infty}^{(L)}(x, y)  \:\: n_i \rightarrow \infty \forall i \in [1, ..., L-1]$$</p>
            <p id="lst-p"><em><strong>Independent</strong></em> on the <strong>parameters</strong>, thus it is:</p>
            <ul>
              <li><span style="color: purple">Deterministic</span>: converges to a deterministic limit at initialization</li>
              <li><span style="color: purple">Fixed</span>: its rate of change during training \(\rightarrow 0\)</li>
            </ul>

            <p>This explains why the effect of GD was so similar for different initializations.  <br />
  <button class="showText" value="show" onclick="showTextPopHide(event);">graph</button>
  <img src="https://cdn.mathpix.com/snip/images/Pp0Hxm5V_iEZ4U6hbTl5ihRwKKnE7ZpKUaokDEjgls4.original.fullsize.png" alt="img" width="50%" hidden="" /></p>
          </li>
        </ul>
      </li>
      <li>Now we have all the tools to fully describe the behavior of the network function during training:
        <ul>
          <li><strong>Ex. Least-Squares Regression on 3 points</strong>:
            <ul>
              <li>Start w/ <strong>random Gaussian Process</strong></li>
              <li>Follow the <strong>kernel gradient of the cost</strong> wrt <strong>NTK</strong></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><span style="color: purple"><strong>Kernel GD</strong> is simply a <em><strong>generalization</strong></em> of <strong>GD</strong> to</span> <strong style="color: goldenrod">Function Spaces</strong>
        <ul>
          <li>Because the cost is <strong>convex</strong> in function space the function will converge to the minimum if the kernel is <strong>Positive Definite</strong></li>
        </ul>
      </li>
      <li>As width (of NN) \(\rightarrow \infty\), trajectory approaches the trajectory of GD for a kernel regression problem, where the (fixed) kernel in question is the so-called Neural Tangent Kernel (NTK). (For convolutional nets the kernel is Convolutional NTK or CNTK.)</li>
    </ul>

    <p id="lst-p"><strong>Notes:</strong></p>
    <ul>
      <li><strong>Intuition of why DL Works</strong>:<br />
  <strong>Circuit Theory:</strong> There are function you can compute with a “small” L-layer deep NN that shallower networks require exponentially more hidden units to compute. (comes from looking at networks as logic gates).
        <ul>
          <li><strong>Example</strong>:<br />
  Computing \(x_1 \text{XOR} x_2 \text{XOR} ... \text{XOR} x_n\)  takes:
            <ul>
              <li>\(\mathcal{O}(log(n))\) in a tree representation.<br />
  <img src="/main_files/concepts/7.png" alt="img" width="40%" /></li>
              <li>\(\mathcal{O}(2^n)\) in a one-hidden-layer network because you need to exhaustively enumerate all possible \(2^N\) configurations of the input bits that result in the \(\text{XOR}\) being \({1, 0}\). <br />
  <img src="/main_files/concepts/8.png" alt="img" width="40%" /></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><strong><a href="https://github.com/josh-tobin/cs189-su18/blob/master/lecture7.ipynb">Curse of Dimensionality (ipynb)</a></strong></li>
      <li><strong>The Hypothesis space of Neural Networks is Convex</strong>:<br />
  Composition of affine-relu functions; induction.</li>
      <li><strong><a href="https://arxiv.org/pdf/1710.05468.pdf">Generalization in Deep Learning</a></strong></li>
      <li><strong>Catastrophic Forgetting:</strong>
        <ul>
          <li>mitigating catastrophic forgetting [McCloskey and Cohen, 1989, Ratcliff, 1990, Kemker et al., 2017] by penalizing the norm of parameters when training on a new task [Kirkpatrick et al., 2017], the norm of the difference between parameters for previously learned tasks during parameter updates [Hashimoto et al., 2016], incrementally matching modes [Lee et al., 2017], rehearsing on old tasks [Robins, 1995], using adaptive memory buffers [Gepperth and Karaoguz, 2016], finding task-specific paths through networks [Fernando et al., 2017], and packing new tasks into already trained networks [Mallya and Lazebnik, 2017].</li>
          <li><a href="https://arxiv.org/abs/1612.00796">Overcoming catastrophic forgetting in neural networks (paper)</a><br />
 <br /></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents6" id="bodyContents62">The Big Formulations:</strong><br />
 <strong style="color: red">ML Formulation:</strong><br />
 Improve on <strong>TASK T</strong> with respect to <strong>PERFORMANCE METRIC P</strong> based on <strong>EXPERIENCE E</strong>.</p>

    <p><strong style="color: red">Problems in ML:</strong><br />
 <button class="showText" value="show" onclick="showText_withParent_PopHide(event);">Show</button></p>
    <ul hidden="">
      <li>
        <p><strong>T:</strong> Categorize email messages as spam or legitimate 
  <strong>P:</strong> Percentage of email messages correctly classified 
  <strong>E:</strong> Database of emails, some with human-given labels</p>
      </li>
      <li>
        <p><strong>T:</strong> Recognizing hand-written words 
  <strong>P:</strong> Percentage of words correctly classified 
  <strong>E:</strong> Database of human-labeled images of  handwritten words</p>
      </li>
      <li>
        <p><strong>T:</strong> playing checkers 
  <strong>P:</strong> percentage of games won against an arbitrary opponent 
  <strong>E:</strong> Playing practice games against itself</p>
      </li>
      <li><strong>T:</strong> Driving on four-lane highways using vision sensors 
  <strong>P:</strong> Average distance traveled before a human-judged error 
  <strong>E:</strong> A seq of images and steering commands recorded while observing a human driver</li>
      <li><strong>Sequence Labeling</strong>:
        <ul>
          <li><em><strong>Problems</strong></em>:
            <ul>
              <li>Speech Recognition</li>
              <li>OCR</li>
              <li>Semantic Segmentation</li>
            </ul>
          </li>
          <li><em><strong>Approaches</strong></em>:
            <ul>
              <li>CTC - Bi-directional LSTM</li>
              <li>Listen Attend and Spell (LAS)</li>
              <li>HMMs</li>
              <li>CRFs</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<!-- 3. **What is ML?:**{: style="color: SteelBlue"}{: .bodyContents6 #bodyContents63}   -->

<ol>
  <li><strong style="color: SteelBlue" class="bodyContents6" id="bodyContents64">Types of Learning:</strong>
    <ul>
      <li><strong>Multi-Task Learning</strong>: general term for training on multiple tasks
        <ul>
          <li><em>Joint Learning:</em> by choosing mini-batches from two different tasks simultaneously/alternately</li>
          <li><em>Pre-Training:</em> first train on one task, then train on another
            <blockquote>
              <p>widely used for <strong>word embeddings</strong></p>
            </blockquote>
          </li>
        </ul>
      </li>
      <li><strong>Transfer Learning</strong>:<br />
  a type of multi-task learning where we are focused on one task; by learning on another task then applying those models to our main task</li>
      <li><strong>Domain Adaptation</strong>:<br />
  a type of transfer learning, where the output is the same, but we want to handle different inputs/topics/genres</li>
      <li><strong>Zero-Shot Learning</strong>:</li>
    </ul>

    <p id="lst-p"><strong>Notes:</strong></p>
    <ul>
      <li><strong>Relationship between Supervised and Unsupervised Learning</strong>:<br />
  Many ml algorithms can be used to perform both tasks. E.g., the chain rule of probability states that for a vector \(x \in \mathbb{R}^n\), the joint distribution can be decomposed as:<br />
  \(p(\mathbf{x})=\prod_{i=1}^{n} p\left(\mathrm{x}_{i} \vert \mathrm{x}_{1}, \ldots, \mathrm{x}_{i-1}\right)\)<br />
  which implies that we can solve the Unsupervised problem of modeling \(p(x)\) by splitting it into \(n\) supervised learning problems.<br />
  Alternatively, we can solve the supervised learning problem of learning \(p(y \vert x)\) by using traditional unsupervised learning technologies to learn the joint distribution \(p(x, y)\), then inferring:<br />
  \(p(y \vert \mathbf{x})=\frac{p(\mathbf{x}, y)}{\sum_{y} p\left(\mathbf{x}, y^{\prime}\right)}\)</li>
      <li><strong>Intuition on Why Unsupervised Learning works</strong>:
        <ul>
          <li>Goal: Learn Portuguese</li>
          <li>For 1 month you listen to Portuguese on the radio (this is unlabeled data)</li>
          <li>You develop an intuition for the language, phrases, and grammar (a model in your head)</li>
          <li>It is easier to learn now from a tutor because you have a better (higher representation) of the data/language</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents6" id="bodyContents65">Linear Models:</strong><br />
 A <strong>Linear Model</strong> takes an input \(x\) and computes a signal \(s = \sum_{i=0}^d w_ix_i\) that is a <em>linear combination</em> of the input with weights, then apply a scoring function on the signal \(s\).
    <ul>
      <li><strong>Linear Classifier as a Parametric Model</strong>:<br />
  Linear classifiers \(f(x, W)=W x+b\)  are an example of a parametric model that sums up the knowledge of the training data in the parameter: weight-matrix \(W\).</li>
      <li><strong>Scoring Function</strong>:
        <ul>
          <li><em><strong>Linear Classification</strong></em>:<br />
  \(h(x) = sign(s)\)</li>
          <li><em><strong>Linear Regression</strong></em>:<br />
  \(h(x) = s\)</li>
          <li><em><strong>Logistic Regression</strong></em>:<br />
  \(h(x) = \sigma(s)\)</li>
        </ul>
      </li>
    </ul>

    <p id="lst-p"><strong style="color: red">Notes:</strong></p>
    <ul>
      <li><strong>The Weight vector of a linear signal is orthogonal to the decision boundary</strong>:<br />
  The weight vector \(\mathbf{w}\) is orthogonal to the separating-plane/decision-boundary, defined by \(\mathbf{w}^T\mathbf{x} + b = 0\), in the \(\mathcal{X}\) space; Reason:<br />
  Since if you take any two points \(\mathbf{x}^\prime\) and \(\mathbf{x}^{\prime \prime}\) on the plane, and create the vector \(\left(\mathbf{x}^{\prime}-\mathbf{x}^{\prime \prime}\right)\)  parallel to the plane by subtracting the two points, then the following equations must hold:
        <p>$$\mathbf{w}^{\top} \mathbf{x}^{\prime}+b=0 \wedge \mathbf{w}^{\top} \mathbf{x}^{\prime \prime}+b=0 \implies \mathbf{w}^{\top}\left(\mathbf{x}^{\prime}-\mathbf{x}^{\prime \prime}\right)=0$$</p>
      </li>
    </ul>

    <p><!-- 6. **Learning Probabilities with Logistic Regression and Sigmoids:**{: style="color: SteelBlue"}{: .bodyContents6 #bodyContents66}   --></p>

    <p><!-- 7. **Papers:**{: style="color: SteelBlue"}{: .bodyContents6 #bodyContents67}   --></p>

    <p><!-- 8. **Activation Functions:**{: style="color: SteelBlue"}{: .bodyContents6 #bodyContents68}    --></p>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents6" id="bodyContents69">Bias-Variance Decomposition Theory:</strong> <br />
 <strong style="color: red">Bias-Variance for Neural-Networks:</strong>
    <p><img src="/main_files/concepts/9.png" alt="img" width="60%" /><br />
 <strong>Dealing with Bias and Variance for NN:</strong></p>
    <ul>
      <li><strong>High Bias</strong> (\(E_{\text{train}}\)) \(\rightarrow\) (1) Bigger Net (2) Train longer (3) Different NN archit</li>
      <li><strong>High Variance</strong> (\(E_{\text{dev}}\)) \(\rightarrow\) (1) More Data (2) Regularization (3) Different NN archit<br />
 <br /></li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents6" id="bodyContents610">Models:</strong> <br />
<strong style="color: red">Parametric Models:</strong><br />
A <strong>parametric model</strong> is a set of probability distributions indexed by a parameter \(\theta \in \Theta\). We denote this as:
    <p>$$\{p(y ; \theta) \vert \theta \in \Theta\},$$</p>
    <p>where \(\theta\) is the <strong>parameter</strong> and \(\Theta\) is the <strong>Parameter-Space</strong>.<br />
<br /></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents6" id="bodyContents611">Output Units/Functions:</strong> <br />
<button class="showText" value="show" onclick="showTextPopHide(event);">Output Units: Linear and Sigmoid units</button>
<img src="/main_files/concepts/10.jpg" alt="img" hidden="" /></p>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents6" id="bodyContents612">Model Varieties - Regression and Classification:</strong><br />
<strong>Generalized Regression</strong> also known as <strong style="color: red">Conditional Distribution Estimation:</strong>
    <ul>
      <li>Given \(x\), predict probability distribution \(p(y\vert x)\)</li>
      <li>How do we represent the probability distribution?
        <ul>
          <li>We’ll consider parametric families of distributions
            <ul>
              <li>distribution represented by parameter vector</li>
            </ul>
          </li>
          <li>Examples:
            <ul>
              <li>Generalized Linear Models (GLM)
                <ul>
                  <li>Logistic regression (Bernoulli distribution)</li>
                  <li>Probit regression (Bernoulli distribution)</li>
                  <li>Poisson regression (Poisson distribution)</li>
                  <li>Linear regression (Normal distribution, fixed variance)</li>
                </ul>
              </li>
              <li>Generalized Additive Models (GAM)</li>
              <li>Gradient Boosting Machines (GBM) / AnyBoost</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>

    <p id="lst-p"><strong style="color: red">Probabilistic Binary Classifiers:</strong></p>
    <ul>
      <li>Setting: \(X=\mathrm{R}^{d}, y=\{0,1\}\)</li>
      <li>For each \(x\), need to predict a distribution on \(y=\{0,1\}\)</li>
      <li>To define a distribution supported on \(\{0,1\}\), it is sufficient to specify the <strong>Bernoulli parameter</strong> \(\theta=p(y=1 \vert x)\)</li>
      <li>We can refer to this distribution as \(\text{Bernoulli}(\theta)\)</li>
    </ul>

    <p id="lst-p"><strong style="color: red">Linear Probabilistic Classifiers:</strong></p>
    <ul>
      <li>Setting: \(X=\mathrm{R}^{d}, y=\{0,1\}\)</li>
      <li>Want prediction function to map each \(x \in \mathrm{R}^{d}\) to the right \(\theta \in[0,1]\)</li>
      <li>We first extract information from \(x \in \mathrm{R}^{d}\) and summarize in a single number
        <ul>
          <li>That number is analogous to the <strong>Score</strong> in <em>classification</em></li>
        </ul>
      </li>
      <li>For a <strong>linear method/model</strong>, this extraction is done with a <strong>linear function</strong>;
        <p>$$\underbrace{x}_{\in \mathbb{R}^{D}} \mapsto \underbrace{w^{T} x}_{\in \mathrm{R}}$$</p>
      </li>
      <li>As usual, \(x \mapsto w^{T} x\) will include <strong>affine functions</strong> if we include a constant features in \(x\)</li>
      <li>\(w^Tx\) is called the <strong>linear predictor</strong></li>
      <li>Still need to map this to \([0, 1]\); we do so by <strong>Transfer/Response/Inverse-Link function</strong>; usually the <em><strong>logistic function (Sigmoid)</strong></em>
        <blockquote>
          <p>Its a function to map the linear predictor in \(\mathbb{R}\) to \([0,1]\):<br />
      \(\underbrace{x}_ {\in \mathbf{R}^{D}} \mapsto \underbrace{w^{T}}_{\in R} \mapsto \underbrace{f\left(w^{T} x\right)}_{\in[0,1]}=\theta = p(y=1 \vert x)\)</p>
        </blockquote>
      </li>
    </ul>

    <p><strong>Learning:</strong><br />
The hypothesis space/set:</p>
    <p>$$\mathcal{H}=\left\{x \mapsto f\left(w^{T} x\right) \vert w \in \mathbb{R}^{d}\right\}$$</p>
    <p>where the <strong>only <em>“parameter”</em></strong> in this model is \(w \in \mathbb{R}^d\). <br />
We can choose \(w\) using <strong>maximum likelihood:</strong><br />
<strong>Likelihood Scoring | Bernoulli Regression:</strong></p>
    <ul>
      <li>Suppose we have data \(\mathcal{D}=\left\{\left(x_{1}, y_{1}\right), \ldots,\left(x_{n}, y_{n}\right)\right\}\)</li>
      <li>The model likelihood for \(\mathcal{D}\):
        <p>$$\begin{aligned} p_{w}(\mathcal{D}) &amp;=\prod_{i=1}^{n} p_{w}\left(y_{i} \vert x_{i}\right)[\text { by independence }] \\ &amp;=\prod_{i=1}^{n}\left[f\left(w^{T} x_{i}\right)\right]^{y_{i}}\left[1-f\left(w^{T} x_{i}\right)\right]^{1-y_{i}} \end{aligned}$$</p>
        <ul>
          <li>This probability of each data-point \(p_w(y_i\|x_i)\) can be summed in the equation \(\left[f\left(w^{T} x_{i}\right)\right]^{y_{i}}\left[1-f\left(w^{T} x_{i}\right)\right]^{1-y_{i}}\) which capture both cases \(p_w(y_i = 1) = f\left(w^{T} x_{i}\right)\) and \(p_w(y_i = 0) = 1 - f\left(w^{T} x_{i}\right)\)</li>
        </ul>
      </li>
      <li>The <strong>log likelihood</strong>:
        <p>$$\log p_{w}(\mathcal{D})=\sum_{i=1}^{n} y_{i} \log f\left(w^{T} x_{i}\right)+\left(1-y_{i}\right) \log \left[1-f\left(w^{T} x_{i}\right)\right]$$</p>
      </li>
      <li>Equivalently, minimize the objective function:
        <p>$$J(w)=-\left[\sum_{i=1}^{n} y_{i} \log f\left(w^{T} x_{i}\right)+\left(1-y_{i}\right) \log \left[1-f\left(w^{T} x_{i}\right)\right]\right]$$</p>
      </li>
    </ul>

    <p id="lst-p"><strong style="color: red">Gaussian Linear Regression/Conditional Gaussian Regression:</strong></p>
    <ul>
      <li><a href="https://www.youtube.com/embed/JrFj0xpGd2Q?start=1965" value="show" onclick="iframePopA(event)"><strong>Gaussian Linear Regression</strong></a>
<a href="https://www.youtube.com/embed/JrFj0xpGd2Q?start=1965"></a>
        <div></div>
      </li>
    </ul>

    <p id="lst-p"><strong style="color: red">Generalized Regression as Statistical Learning:</strong></p>
    <ul>
      <li><a href="https://www.youtube.com/embed/JrFj0xpGd2Q?start=2609" value="show" onclick="iframePopA(event)"><strong>Generalized Regression as Statistical Learning</strong></a>
<a href="https://www.youtube.com/embed/JrFj0xpGd2Q?start=2609"></a>
        <div></div>
      </li>
    </ul>

    <p id="lst-p"><strong style="color: red">Generalized Linear Models:</strong></p>
    <ul>
      <li><a href="https://www.youtube.com/embed/nLKOQfKLUks?list=PLA89DCFA6ADACE599" value="show" onclick="iframePopA(event)"><strong>Generalized Linear Models (Andrew NG)</strong></a>
<a href="https://www.youtube.com/embed/nLKOQfKLUks?list=PLA89DCFA6ADACE599"></a>
        <div></div>
      </li>
      <li><a href="http://bjlkeng.github.io/posts/a-probabilistic-view-of-regression/">GLM Probabilistic Development</a><br />
<br /></li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents6" id="bodyContents613">Bayesian Conditional Probabilistic Models:</strong>
    <ul>
      <li><a href="https://www.youtube.com/embed/Mo4p2B37LwY" value="show" onclick="iframePopA(event)"><strong>Bayesian Conditional Probabilistic Models</strong></a>
<a href="https://www.youtube.com/embed/Mo4p2B37LwY"></a>
        <div></div>
        <p><br /></p>
      </li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents6" id="bodyContents615">Recommendation Systems:</strong>
    <ul>
      <li><button class="showText" value="show" onclick="showTextPopHide(event);">Recommendation Systems</button>
<img src="/main_files/concepts/9.jpg" alt="img" hidden="" /></li>
      <li><a href="https://blog.echen.me/2011/10/24/winning-the-netflix-prize-a-summary/">Winning the Netflix Prize: A Summary (blog!)</a></li>
      <li><a href="https://blog.echen.me/2014/10/07/moving-beyond-ctr-better-recommendations-through-human-evaluation/">Moving Beyond CTR: Better Recommendations Through Human Evaluation (blog)</a><br />
<br /></li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents6" id="bodyContents616">Regularization:</strong>
    <ul>
      <li><strong>Overfitting and Regularization</strong>:<br />
  To address over-fitting:
        <ul>
          <li>Increase size of training dataset</li>
          <li>Reduce number of features</li>
          <li>Do Regularization:
            <ul>
              <li>Keep all the features but reduce the magnitude/values of the weights/parameters</li>
              <li>Works well when we have a lot of features, each of which contributes a bit to predicting \(y\)</li>
            </ul>
          </li>
        </ul>
      </li>
      <li><strong>Regularization Theory</strong>:
        <ul>
          <li><a href="https://www.youtube.com/watch?v=DCvXYD6xQYw">link1</a></li>
        </ul>
      </li>
      <li><strong>Theoretical Justification for Regularization</strong>:<br />
  A theoretical justification for regularization is that it attempts to impose Occam’s razor on the solution.<br />
  From a Bayesian point of view, many regularization techniques correspond to imposing certain prior distributions on model parameters.</li>
      <li><strong>Tikhonov Regularization</strong>: is essentially a trade-off between fitting the data and reducing a norm of the solution.</li>
    </ul>

    <p id="lst-p"><strong style="color: red">Data Regularization:</strong></p>
    <ul>
      <li>The <strong>Design Matrix</strong> contains sample points in each <em><strong>row</strong></em></li>
      <li><strong>Feature Scaling/Mean Normalization (of data)</strong>:
        <ul>
          <li>Define the mean \(\mu_j\) of each feature of the datapoints \(x^{(i)}\):</li>
        </ul>
        <p>$$\mu_{j}=\frac{1}{m} \sum_{i=1}^{m} x_{j}^{(i)}$$</p>
        <ul>
          <li>Replace each \(x_j^{(i)}\) with \(x_j - \mu_j\)</li>
        </ul>
      </li>
      <li><strong>Centering</strong>:  subtracting \(\mu\) from each row of \(X\)</li>
      <li><strong>Sphering</strong>:  applying the transform \(X' = X \Sigma^{-1/2}\)</li>
      <li><strong>Whitening</strong>:  Centering + Sphering (also known as <em><strong>Decorrelating feature space</strong></em>)</li>
    </ul>

    <p><button class="showText" value="show" onclick="showTextPopHide(event);">Why Normalize the Data/Signal?</button>
<img src="https://cdn.mathpix.com/snip/images/8aNuJetgTgCtv4pvqaI0dr96pDyUmfuX_d1aLK1lmaw.original.fullsize.png" alt="img" width="80%" hidden="" /></p>

    <p><a href="https://hadrienj.github.io/posts/Preprocessing-for-deep-learning/">Pre-processing for Deep Learning (data regularization)</a></p>

    <p><a href="https://github.com/dalmia/Deep-Learning-Book-Chapter-Summaries/blob/master/07%20-%20Regularization%20for%20Deep%20Learning.ipynb">Ch.7 dl-book summary</a><br />
<br /></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents6" id="bodyContents617">Aggregation - Ensemble Methods:</strong></p>

    <ul>
      <li><strong>Boosting</strong>: create different hypothesis \(h_i\)s sequentially + make each new hypothesis <strong>decorrelated</strong> with previous hypothesis.
        <ul>
          <li>Assumes that this will be combined/ensembled</li>
          <li>Ensures that each new model/hypothesis will give a different/independent output</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents6" id="bodyContents618">Kernels:</strong>
    <ul>
      <li><strong>Kernels</strong>:
        <ul>
          <li><strong>Polynomial Kernel of degree, exactly, \(d\)</strong>:
            <p>$$K(\mathbf{u}, \mathbf{v})=(\mathbf{u} \cdot \mathbf{v})^{d}$$</p>
          </li>
          <li><strong>Polynomial Kernel of degree, up to, \(d\)</strong>:
            <p>$$K(\mathbf{u}, \mathbf{v})=(\mathbf{u} \cdot \mathbf{v}+1)^{d}$$</p>
          </li>
          <li><strong>Gaussian Kernel</strong>:
            <p>$$K(\vec{u}, \vec{v})=\exp \left(-\frac{\|\vec{u}-\vec{v}\|_ {2}^{2}}{2 \sigma^{2}}\right)$$</p>
          </li>
          <li><strong>Sigmoid Kernel</strong>:
            <p>$$K(\mathbf{u}, \mathbf{v})=\tanh (\eta \mathbf{u} \cdot \mathbf{v}+\nu)$$</p>
          </li>
        </ul>
      </li>
      <li><strong>Local Kernels</strong>: a kernel where \(k(u, v)\) is large when \(u=v\) and decreases as \(u\) and \(v\) grow further apart from each other.<br />
  A local kernel can be thought of as a <strong>similarity function</strong> that performs <strong>template matching</strong>, by measuring how closely a test example \(x\) resembles each training example \(x^{(i)}\).</li>
      <li>
        <p>The kernel trick can NOT be applied to any learning algorithm</p>
      </li>
      <li><a href="http://mccormickml.com/2014/02/26/kernel-regression/">Kernel Regression Introduction</a></li>
    </ul>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents6" id="bodyContents621">Curse of Dimensionality:</strong><br />
<strong>The Curse of Dimensionality</strong>, in general, refers to various phenomena, that arise when analyzing and organizing data in high-dimensional spaces, that do not occur in low-dimensional settings such as the three-dimensional physical space of everyday experience.</p>

    <p><strong style="color: red">Common Theme:</strong><br />
When the dimensionality increases, the <em>volume of the space increases so fast</em> that the available <em>data become sparse</em>. This <strong>sparsity</strong> is problematic for any method that requires <strong>statistical significance</strong>. In order to obtain a statistically sound and reliable result, the <em>amount of data needed</em> to support the result often <em>grows exponentially with the dimensionality</em>. Also, organizing and searching data often relies on detecting areas where objects form groups with similar properties (<em>clustering</em>); in high dimensional data, however, all objects appear to be sparse and dissimilar in many ways, which prevents common data organization strategies from being efficient.</p>

    <p><strong style="color: red">Sampling:</strong><br />
The sampling density is proportional to \(N^{1/p}\), where \(p\) is the dimension of the input space and \(N\) is the sample size. Thus, if \(N_1 = 100\) represents a dense sample for a single input problem, then \(N_{10} = 100^{10}\) is the sample size required for the same sampling density with \(10\) inputs. Thus in high dimensions all feasible training samples sparsely populate the input space.</p>

    <p><a href="https://marckhoury.github.io/counterintuitive-properties-of-high-dimensional-space/">Story on Geometry in high-dimensional spaces</a></p>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents6" id="bodyContents60">Notes:</strong>
    <ul>
      <li><strong>Complexity</strong>:
        <ul>
          <li><strong>Caching the activations of a NN</strong>:<br />
  We need to cache the activation vectors of a NN after each layer \(Z^{[l]}\) because they are required in the backward computation.</li>
        </ul>
      </li>
      <li><strong>Initializations</strong>:
        <ul>
          <li><strong>Initializing NN</strong>:
            <ul>
              <li>Don’t initialize the weights to Zero. The symmetry of hidden units results in a similar computation for each hidden unit, making all the rows of the weight matrix to be equal (by induction).</li>
              <li>It’s OK to initialize the bias term to zero.</li>
              <li>Since a neuron takes the sum of \(N\) inputsXweights, if \(N\) is large, you want smaller \(w_i\)s. You want to initialize with a <strong>variance</strong> \(\propto \dfrac{1}{n}\) (i.e. multiply by \(\dfrac{1}{\sqrt{n}}\); \(n\) is the number of weights in <em><strong>previous layer</strong></em>).<br />
  This doesnt solve but reduces vanishing/exploding gradient problem because \(z\) would take a similar distribution.
                <ul>
                  <li><strong>Xavier Initialization:</strong> assumes \(\tanh\) activation; ^ uses logic above; samples from normal distribution and multiplies by \(\dfrac{1}{\sqrt{n}}\).</li>
                  <li>If <strong>ReLU</strong> activation, it turns out to be better to make variance \(\propto \dfrac{2}{n}\) instead.</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li><strong>Training</strong>:
        <ul>
          <li><a href="http://karpathy.github.io/2019/04/25/recipe/">A Recipe for Training Neural Networks</a></li>
          <li><a href="http://rishy.github.io/ml/2017/01/05/how-to-train-your-dnn/">Tips for Training Deep Networks</a></li>
          <li><a href="http://www.chioka.in/why-train-a-model-generatively-and-discriminatively/">Why Train a Model BOTH Generatively and Discriminatively</a></li>
        </ul>
      </li>
      <li><strong>Feature Importance</strong>:
        <ul>
          <li>In linear models, feature importance can be calculated by the scale of the coefficients</li>
          <li>In tree-based methods (such as random forest), important features are likely to appear closer to the root of the tree. We can get a feature’s importance for random forest by computing the averaging depth at which it appears across all trees in the forest</li>
        </ul>
      </li>
      <li><strong>Probabilistic Calibration</strong>:
        <ul>
          <li><a href="https://scikit-learn.org/stable/modules/calibration.html">Plot and Explanation</a></li>
          <li><a href="http://alondaks.com/2017/12/31/the-importance-of-calibrating-your-deep-model/">Blog on How to do it</a></li>
        </ul>
      </li>
      <li><strong>Complexity in ML</strong>:
        <ul>
          <li><strong>Definitions of the complexity of an object (\(h\))</strong>:
            <ul>
              <li><strong>Minimum Description Length (MDL)</strong>: the number of bits for specifying an object.</li>
              <li><strong>Order of a Polynomial</strong></li>
            </ul>
          </li>
          <li><strong>Definitions of the complexity of a class of objects (\(\mathcal{H}\))</strong>:
            <ul>
              <li><strong>Entropy</strong></li>
              <li><strong>VC-dim</strong></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><strong>Gaussian Discriminant Analysis</strong>:
        <ul>
          <li>models \(P(Y=y \vert X)\) as a logistic function.</li>
          <li>is a generative model.</li>
          <li>can be used to classify points without ever computing an exponential</li>
          <li><strong>decision boundary shapes:</strong>
            <ul>
              <li>Hyperplane</li>
              <li>Nonlinear quadric surface (quadric = the isosurface of a quadratic function)</li>
              <li>The empty set (the classifier always returns the same class)</li>
            </ul>
          </li>
          <li><a href="https://web.stanford.edu/~hastie/Papers/ESLII.pdf#page=146">Logistic Regression vs LDA? (ESL)</a></li>
        </ul>
      </li>
      <li><strong>Geometry of Gaussian Distributions</strong>:
        <ul>
          <li>Multivariate Normal Distribution:
            <ul>
              <li>Isotropic:
                <ul>
                  <li>I.E. Isosurfaces are spheres</li>
                  <li>Covariance Matrix \(\Sigma = \sigma^2 I\)<br />
  where \(\sigma^2\) is the variance of any one feature.</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>The <strong>Bias Parameter</strong>:
        <ul>
          <li><a href="https://stackoverflow.com/questions/2480650/role-of-bias-in-neural-networks">Role of Bias in a NN</a></li>
        </ul>
      </li>
      <li><strong>When is does an ML problem become a <em>Research Problem</em></strong>:<br />
  A problem that you are trying to solve using ML becomes a <strong>research problem</strong> as opposed to those solved by <strong>applied practitioners</strong> when the only way to learn the problem is to <span style="color: purple">improve the <strong>learning algorithm</strong> itself</span>. This happens in two situations:
        <ol>
          <li>You can fit the <strong>training data</strong> well but cannot improve <strong>generalization error</strong>:<br />
 This happens when: It is not feasible to gather more data</li>
          <li>You cannot fit the <strong>training data</strong> well even when you increase the capacity of your models as much as you <em>“feasibly”</em> can</li>
        </ol>
      </li>
      <li><button class="showText" value="show" onclick="showTextPopHide(event);">Designing Human-Centered AI</button>
  <img src="https://cdn.mathpix.com/snip/images/QMFDyvhLtOO4V5sJ5UXNzc5ykwllgkghEmpqncZ0P4Y.original.fullsize.png" alt="img" width="100%" hidden="" /></li>
      <li><strong>Bayesian Deep Learning</strong>:<br />
  <button class="showText" value="show" onclick="showTextPopHide(event);">List of Topics</button>
        <ul hidden="">
          <li>Uncertainty in deep learning,</li>
          <li>Applications of Bayesian deep learning,</li>
          <li>Probabilistic deep models (such as extensions and application of Bayesian neural networks),</li>
          <li>Deep probabilistic models (such as hierarchical Bayesian models and their applications),</li>
          <li>Generative deep models (such as variational autoencoders),</li>
          <li>Information theory in deep learning,</li>
          <li>Deep ensemble uncertainty,</li>
          <li>NTK and Bayesian modelling,</li>
          <li>Connections between NNs and GPs,</li>
          <li>Incorporating explicit prior knowledge in deep learning (such as posterior regularisation with logic rules),</li>
          <li>Approximate inference for Bayesian deep learning (such as variational Bayes / expectation propagation / etc. in Bayesian neural networks),</li>
          <li>Scalable MCMC inference in Bayesian deep models,</li>
          <li>Deep recognition models for variational inference (amortised inference),</li>
          <li>Bayesian deep reinforcement learning,</li>
          <li>Deep learning with small data,</li>
          <li>Deep learning in Bayesian modelling,</li>
          <li>Probabilistic semi-supervised learning techniques,</li>
          <li>Active learning and Bayesian optimisation for experimental design,</li>
          <li>Kernel methods in Bayesian deep learning,</li>
          <li>Implicit inference,</li>
          <li>Applying non-parametric methods, one-shot learning, and Bayesian deep learning in general.</li>
        </ul>
      </li>
      <li><strong>Learning Problems</strong>:
        <ul>
          <li>Counting/Arithmetic</li>
          <li>Copying</li>
          <li>Identity Mapping</li>
          <li>Pointing (Copying?)</li>
          <li></li>
        </ul>
      </li>
      <li><strong>Learning Features</strong>:
        <ul>
          <li>Higher-Order/k-Order Interactions</li>
          <li>Global Dependencies</li>
          <li>Local Dependencies</li>
          <li>Self-Similarity</li>
          <li>Non-Locality (<a href="https://arxiv.org/pdf/1711.07971.pdf">Non-local Neural Networks (paper!)</a>)</li>
          <li>Long-Range Dependencies</li>
          <li>Memory: Long-Term, Short-Term (working memory)
            <ul>
              <li>Associative Retrieval</li>
            </ul>
          </li>
          <li>Mathematical (Symbolic?) Manipulation: Arithmetic?: Counting</li>
        </ul>
      </li>
      <li><strong>Input Representations</strong>:
        <ul>
          <li>Localist Representations</li>
          <li>Point Attractors
 <br /></li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<hr />
<hr />

<h2 id="content7">Computer Vision</h2>

<!-- 

1. **Edge Detection Filters:**{: style="color: SteelBlue"}{: .bodyContents7 #bodyContents71}  
    * __Sobel Filter:__  
        <p>$$\begin{array}{|c|c|c|}\hline 1 & {0} & {-1} \\ \hline 2 & {0} & {-2} \\ \hline 1 & {0} & {-1} \\ \hline\end{array}$$</p>  
    * __Schorr Filter__:  
        <p>$$\begin{array}{|c|c|c|}\hline 3 & {0} & {-3} \\ \hline 10 & {0} & {-10} \\ \hline 3 & {0} & {-3} \\ \hline\end{array}$$</p>  
            

2. **Aliasing:**{: style="color: SteelBlue"}{: .bodyContents7 #bodyContents72}  
    Aliasing is an effect that causes different signals to become indistinguishable (or aliases of one another) when sampled. It also refers to the distortion or artifact that results when the signal reconstructed from samples is different from the original continuous signal.  

    Aliasing can occur in signals sampled in time, for instance digital audio, and is referred to as __temporal aliasing__. Aliasing can also occur in spatially sampled signals, for instance moiré patterns in digital images. Aliasing in spatially sampled signals is called __spatial aliasing__.  
        -->

<!-- 3. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents7 #bodyContents73}  
4. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents7 #bodyContents74}  
  -->

<hr />
<hr />

<h2 id="content8">NLP</h2>

<p><a href="https://sites.tufts.edu/models/files/2019/04/Norvig.pdf">The Norvig-Chomsky Debate</a><br />
<a href="https://nlpoverview.com">Modern Deep Learning Techniques Applied to Natural Language Processing (Amazing Resource)</a><br />
<a href="https://tryolabs.com/blog/2017/12/12/deep-learning-for-nlp-advancements-and-trends-in-2017/?utm_campaign=Revue%20newsletter&amp;utm_medium=Newsletter&amp;utm_source=The%20Wild%20Week%20in%20AI">Deep Learning for NLP: Advancements &amp; Trends</a></p>

<ol>
  <li><strong style="color: SteelBlue" class="bodyContents8" id="bodyContents81">Language Modeling:</strong><br />
 <strong style="color: red">Towards Better Language Modeling (Lec.9 highlight, 38m):</strong>
    <p>To improve a <em>Language Model</em>:</p>
    <ol>
      <li><strong>Better Inputs</strong>: 
 Word \(\rightarrow\) Subword \(\rightarrow\) Char<br />
 <button class="showText" value="show" onclick="showTextPopHide(event);">Slide</button>
 <img src="/main_files/concepts/2.png" alt="img" width="100%" hidden="" /><br />
 <em>Subword Language Modeling , Mikolov et al. 2012</em><br />
 <em>Character-Aware Neural Language Model , Kim et al. 2015</em>.</li>
      <li><strong>Better Regularization/Preprocessing</strong>:<br />
 Similar to computer vision, we can do both Regularization and Preprocessing on the data to increase its relevance to the true distribution.<br />
 Preprocessing acts as a <em><strong>data augmentation</strong></em> technique. This allows us to achieve a <strong>Smoother</strong> distribution, since we are removing more common words and re-enforcing rarer words.<br />
 <em>Zoneout, Kruger et al. 2016</em><br />
 <em>Data Noising as Smoothing, Xie et al. 2016</em>
        <ul>
          <li><em><strong>Regularization</strong></em>:
            <ul>
              <li>Use Dropout (Zaremba, et al. 2014).</li>
              <li>Use Stochastic FeedForward depth (Huang et al. 2016)</li>
              <li>Use Norm Stabilization (Memisevic 2015)
  …</li>
            </ul>
          </li>
          <li><em><strong>Preprocessing</strong></em>:
            <ul>
              <li>Randomly replacing words in a sentence with other words</li>
              <li>Use bigram statistics to generate <em>Kneser-Ney</em> inspired replacement (Xie et al. 2016).</li>
              <li>Replace a word with <strong>fixed</strong> drop rate</li>
              <li>Replace a word with <strong>adaptive</strong> drop rate, by how rare two words appear together (i.e. “Humpty Dumpty”), and replace by a unigram draw over vocab</li>
              <li>Replace a word with <strong>adaptive</strong> drop rate, and draw word from a <strong>proposal distribution</strong> (i.e. “New York”)</li>
            </ul>
          </li>
        </ul>
      </li>
      <li><strong>Better Model</strong> (+ all above)</li>
    </ol>

    <p id="lst-p"><strong style="color: red">Recurrent Neural Networks as Language Models:</strong></p>
    <ul>
      <li><button class="showText" value="show" onclick="showTextPopHide(event);">RNN-LM</button>
 <img src="/main_files/concepts/7.jpg" alt="img" hidden="" /></li>
    </ul>

    <p id="lst-p"><strong style="color: red">Notes:</strong></p>
    <ul>
      <li><strong>The ML-Estimate of \(p(w_i \vert w_{i-1})\)</strong> \(= \dfrac{c(w_{i-1}\:, w_i)}{\sum_{w_i} c(w_{i-1}\:, w_i)}\)<br />
 <br /></li>
    </ul>

    <p><!-- 2. **:**{: style="color: SteelBlue"}{: .bodyContents8 #bodyContents82}   --></p>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents8" id="bodyContents83">Neural Text Generation:</strong>
    <ul>
      <li><strong>Traditionally</strong>:
        <ul>
          <li>Often Auto-regressive language models (ie. seq2seq)</li>
          <li>These models generate text by sampling words sequentially, with each word conditioned on the previous word</li>
          <li>Benchmarked on validation perplexity even though this is not a direct measure of the quality of the generated text</li>
          <li>The models are typically trained via <strong>maximum likelihood</strong> and <strong>teacher forcing</strong>
            <blockquote>
              <p>These methods are well-suited to optimizing perplexity but can result in poor sample quality since generating text requires conditioning on sequences of words that may have never been observed at training time</p>
            </blockquote>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents8" id="bodyContents84">NLP &amp; DL (R. Sorcher):</strong>
    <ul>
      <li><button class="showText" value="show" onclick="showTextPopHide(event);">Common DL-NLP Tasks/Problems in NLP w/ DL</button>
 <img src="/main_files/concepts/1_1.jpg" alt="img" hidden="" /></li>
      <li><button class="showText" value="show" onclick="showTextPopHide(event);">Problems in NLP w/ DL contd</button>
 <img src="/main_files/concepts/2.jpg" alt="img" hidden="" /></li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents8" id="bodyContents85">Text Classification:</strong><br />
 <strong style="color: red">Word-Window Classification:</strong>
    <ul>
      <li><button class="showText" value="show" onclick="showTextPopHide(event);">Classification Setup</button>
 <img src="/main_files/concepts/3.jpg" alt="img" hidden="" /></li>
      <li><button class="showText" value="show" onclick="showTextPopHide(event);">Cross-Entropy and Softmax</button>
 <img src="/main_files/concepts/3_1.jpg" alt="img" hidden="" /></li>
      <li><button class="showText" value="show" onclick="showTextPopHide(event);">Classification over a full dataset</button>
 <img src="/main_files/concepts/4.jpg" alt="img" hidden="" /></li>
      <li><button class="showText" value="show" onclick="showTextPopHide(event);">General ML vs DL Optimization</button>
 <img src="/main_files/concepts/4_1.jpg" alt="img" hidden="" /></li>
      <li><button class="showText" value="show" onclick="showTextPopHide(event);">Window Classification</button>
 <img src="/main_files/concepts/5.jpg" alt="img" hidden="" /></li>
      <li><button class="showText" value="show" onclick="showTextPopHide(event);">Softmax limitations and considerations</button>
 <img src="/main_files/concepts/6.jpg" alt="img" hidden="" /></li>
      <li><button class="showText" value="show" onclick="showTextPopHide(event);">The Max-Margin Loss</button>
 <img src="/main_files/concepts/6_1.jpg" alt="img" hidden="" /></li>
    </ul>

    <p id="lst-p"><strong style="color: red">CNN Text Classification:</strong></p>
    <ul>
      <li><button class="showText" value="show" onclick="showTextPopHide(event);">The Problem Set-up and the Pooling Layer</button>
 <img src="/main_files/concepts/8.jpg" alt="img" hidden="" /></li>
      <li>
        <p><button class="showText" value="show" onclick="showTextPopHide(event);">Classification and Tips for Learning</button>
 <img src="/main_files/concepts/8_1.jpg" alt="img" hidden="" /></p>
      </li>
      <li><a href="http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp">CNN Text Classification</a></li>
      <li><a href="https://blog.goodaudience.com/introduction-to-1d-convolutional-neural-networks-in-keras-for-time-sequences-3a7ff801a2cf">1d CNNs for Time-Sequences</a></li>
      <li><a href="http://mccormickml.com/2016/11/04/interpreting-lsi-document-similarity/">LSI document similarity</a></li>
      <li><a href="http://mccormickml.com/2016/03/25/lsa-for-text-classification-tutorial/">Latent Semantic Analysis (LSA) for Text Classification Tutorial</a></li>
      <li><a href="https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/">A Comprehensive Guide to Understand and Implement Text Classification in Python (All Models for Txt Cls. - very useful)</a></li>
    </ul>

    <p><!-- 6. **:**{: style="color: SteelBlue"}{: .bodyContents8 #bodyContents86}   --></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents8" id="bodyContents87">Coreference Resolution:</strong><br />
 <strong>Coreference Resolution:</strong> Identify all mentions that refer to the same real world entity.</p>

    <p id="lst-p"><strong style="color: red">Applications:</strong></p>
    <ul>
      <li><strong>Full text understanding</strong>:
        <ul>
          <li>information extraction, question answering, summarization, …</li>
          <li>“He was born in 1961” (Who?)</li>
        </ul>
      </li>
      <li><strong>Machine Translation</strong>:
        <ul>
          <li>languages have different features for gender, number, dropped pronouns, etc.</li>
        </ul>
      </li>
      <li><strong>Dialogue Systems</strong>:<br />
  “Book tickets to see <span style="color: red">James Bond</span>”<br />
  “<span style="color: red">Spectre</span> is playing near you at 2:00 and <span style="color: blue">3:00</span> today. <span style="color: orange">How many tickets</span> would you like?”<br />
  “<span style="color: orange">Two</span> tickets for the showing at <span style="color: blue">three</span>”</li>
    </ul>

    <p id="lst-p"><strong style="color: red">An approach for Coref-Res in 2 steps:</strong></p>
    <ol>
      <li><strong>Detect the Mentions</strong> (easy)<br />
 “Book tickets to see <span style="color: gray">James Bond</span>”<br />
 “<span style="color: gray">Spectre</span> is playing near you at 2:00 and <span style="color: gray">3:00</span> today. <span style="color: gray">How many tickets</span> would you like?”<br />
 “<span style="color: gray">Two</span> tickets for the showing at <span style="color: gray">three</span>”</li>
      <li><strong>Cluster the Mentions</strong> (hard)<br />
 “Book tickets to see <span style="color: red">James Bond</span>”<br />
 “<span style="color: red">Spectre</span> is playing near you at 2:00 and <span style="color: blue">3:00</span> today. <span style="color: orange">How many tickets</span> would you like?”<br />
 “<span style="color: orange">Two</span> tickets for the showing at <span style="color: blue">three</span>”</li>
    </ol>

    <p><strong style="color: red">Mention Detection:</strong><br />
 <strong>Mention:</strong> span of text referring to some entity.</p>

    <p id="lst-p"><strong>Types of Mention:</strong></p>
    <ol>
      <li><strong>Pronouns</strong><br />
 “I”, “your”, “it”, “she”, “him”</li>
      <li><strong>Named Entities</strong><br />
 People, places, etc.</li>
      <li><strong>Noun Phrases</strong><br />
 “a dog”, “the big fluffy cat stuck in the tree”</li>
    </ol>

    <p id="lst-p"><strong>Detection:</strong><br />
 Use other NLP systems for the detection task:</p>
    <ol>
      <li>Pronouns: <strong>POS-Tagger</strong></li>
      <li>Named Entities: <strong>NER</strong></li>
      <li>Noun Phrases: <strong>(Constituency) Parser</strong></li>
    </ol>

    <p><strong>Problem with Detection - Extra/bad mentions:</strong><br />
 Notice that the systems above will overmatch on possible mentions that don’t have a concrete entity that they refer to: e.g. [It] is sunny, [Every student], [No student], [The best donut in the world], [100 miles].</p>

    <p id="lst-p"><strong>Dealing with bad mentions:</strong></p>
    <ul>
      <li>Train a classifier to filter out spurious mentions</li>
      <li>(more commonly) keep all mentions as “candidate mentions”
        <ul>
          <li>After your coreference system is done running discard all singleton mentions (i.e., ones that have not been marked as coreference with anything else)</li>
        </ul>
      </li>
    </ul>

    <p><a href="https://www.youtube.com/watch?v=i19m4GzBhfc&amp;list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&amp;index=17&amp;t=1320s">Continue Lecture (CS224N)</a> 
 <br /></p>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents8" id="bodyContents88">Word Embeddings:</strong><br />
 <strong style="color: red">Word Vectors:</strong>
    <ul>
      <li><button class="showText" value="show" onclick="showTextPopHide(event);">Learning Word Vectors and Word2Vec</button>
 <img src="/main_files/concepts/11.jpg" alt="img" hidden="" /></li>
      <li><button class="showText" value="show" onclick="showTextPopHide(event);">Word Vectors and Polysemy</button>
 <img src="/main_files/concepts/11_1.jpg" alt="img" hidden="" /></li>
    </ul>

    <p id="lst-p"><strong style="color: red">Notes:</strong></p>
    <ul>
      <li><strong>Categorization</strong> is a method for Evaluating w2v Embeddings by creating categorize by clustering, then measuring the purity of the clusters</li>
    </ul>
  </li>
</ol>

<p id="lst-p"><strong style="color: red">Notes:</strong></p>
<ul>
  <li><a href="http://www.cs.toronto.edu/~ilya/pubs/">Ilya Sutskever Pubs/Vids</a></li>
  <li>Can all NLP tasks be cast as QA problems?!</li>
  <li><a href="https://arxiv.org/pdf/1703.09902.pdf">Survey of the State of the Art in Natural Language Generation</a></li>
</ul>

<!-- 
***
***

## Physics
{: #content9} 
-->

<!-- 
1. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents9 #bodyContents91}  
2. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents9 #bodyContents92}  
3. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents9 #bodyContents93}  
-->

<hr />
<hr />

<!-- ## Algorithms
{: #content10}

1. **DFS:**{: style="color: SteelBlue"}{: .bodyContents10 #bodyContents101}  
    __Applications__:  
    * Finding (strongly or not) connected components.
    * Topological sorting.
    * Finding the bridges of a graph.
    * Generating words in order to plot the limit set of a group.
    * Finding strongly connected components.
    * Planarity testing.
    * Solving puzzles with only one solution, such as mazes. (DFS can be adapted to find all solutions to a maze by only including nodes on the current path in the visited set.)
    * Maze generation may use a randomized depth-first search.
    * Finding biconnectivity in graphs.  

    __Code:__  
    ```python
    # RECURSIVE
    def dfs(n, visit, graph, s):
        # print('n: ', n);print('visit: ', visit);print('graph: ', graph);print('s: ', s)# print("HERE: ", len(visit), len(graph))
        visit[s] = 1
        print(s)
        for v in graph[s]:
            if not visit[v]:
                dfs(n, visit, graph, v)
    ```   

    ```python
    # Pseudo-Code
    procedure DFS-iterative(G,v):
        let S be a stack
        S.push(v)
        while S is not empty
            v = S.pop()
            if v is not labeled as discovered:
                label v as discovered
                for all edges from v to w in G.adjacentEdges(v) do 
                    S.push(w)
    ```
        

2. **Complexity of common Data-Structures:**{: style="color: SteelBlue"}{: .bodyContents10 #bodyContents102}  
    :   ![img](/main_files/concepts/bigo.png){: width="100%"}  

3. **Data-Structures:**{: style="color: SteelBlue"}{: .bodyContents10 #bodyContents103}  
    * __Stack__:  
        * __Implementations__:  
            (1) Arrays  $$\:\:$$ (2) Linked-Lists  
        

4. **Maps and Networks - The Four Color Problem:**{: style="color: SteelBlue"}{: .bodyContents10 #bodyContents104}  
* All maps can be colored with only 4 colors
* All maps are networks (__planar graphs__) but not all networks (non-planar) are maps

5. **Recurrence (complexity):**{: style="color: SteelBlue"}{: .bodyContents10 #bodyContents105}  
    * __Master Theorem__:  
    Given the Recurrence:  
    $$T(n) = aT(n/b) + cn^k,\:\: T(1) = c$$,  
    where a, b, c, and k are all constants. solves to:  
    $$T(n) \in \Theta(n^k)$$ if $$a < b^k$$  
    $$T(n) \in \Theta(n^k \log{n})$$ if $$a = b^k$$  
    $$T(n) \in \Theta(n^{\log_b(a)})$$ if $$a > b^k$$  
    * <button>General Master Theorem</button>{: .showText value="show"
     onclick="showTextPopHide(event);"}
    ![img](/main_files/concepts/general_master_thm.jpg){: hidden=""}  
    * __Recursion Out-of-form__:  
    $$T(n) = T(n − 1) + c^n$$, where $$c$$ is a constant; solves to:  
    Expands to: $$T(n) = \sum_{i=0}^n c^i$$  
    Where the solution is $$\Theta(1), \Theta(n), or \Theta(c^n)$$, depending on if $$c < 1, c = 1, or c > 1$$  
    * __The height of the binary recursion tree__:  
    Given $$T(n) = aT(n^{1/k}) + f(n)$$, the height $$h$$ is the solution to:  
    $$n^{1/{k^h}} = 2$$  
    * __Solution from Recursion Tree__:  
    The solution of a recursion is defined as:  
    1. The number of nodes in the tree: $$= 2^{h+1}-1$$, where $$h$$ is the height of the tree  
    2. Multiplied by the amount of work done at every node: $$f(n)$$     

6. **Proofs for Algorithms:**{: style="color: SteelBlue"}{: .bodyContents10 #bodyContents106}  
    * __Strong Induction:__ e.g. dijkstras

7. **Data Structures:**{: style="color: SteelBlue"}{: .bodyContents10 #bodyContents107}  
    * __Array__  
    * __Stack (LIFO)__  
    * __Queue (FIFO)__  
    * __(min/max) Heap__  
    * __Hash Table__  
    * __Binary Tree__  
    * __(single/double) Linked List__  


    * __Array__:  
    * __Stack__:  
        * __Operations O(1)__:  
            1. Push
            2. Pop
            3. Top
            4. IsEmpty
        * __Implementations__:  
            1. (cyclic) Array: w/ modular indices
            2. (doubly) Linked List
    * __Queue__:  
        * __Operations O(1)__:  
            1. Enqueue
            2. Dequeue
            3. Front
            4. IsEmpty
        * __Implementations__:  
            1. (cyclic) Array: w/ modular indices
            2. (doubly) Linked List
    * __(min/max) Heap__:  
    * __Hash Table__:  
        * __Implementations__:  
            1. Array of Linked Lists (access=O(1))
            2. Balanced BST (access=O(log(n)))
    * __Binary Tree__:  
    * __(single/double) Linked List__:  

    

    8. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents10 #bodyContents108}  
    :

0. **Notes:**{: style="color: SteelBlue"}{: .bodyContents10 #bodyContents100}  
    * __Matrices Trick:__ matrices ($$A,\  B$$) can be put in a larger matrix (to create one big matrix) for efficient computation/multiplication:  
        $$\begin{bmatrix}
            A & 0 \\
            0 & B \\
        \end{bmatrix}$$  
    * [Computable Functions and Turing Machines](https://marckhoury.github.io/on-computable-functions/)   

***
***
 -->

<!-- ## Misc.
{: #content11}

1. **Philosophy:**{: style="color: SteelBlue"}{: .bodyContents11 #bodyContents111}  
    __Occam's Razor:__  Suppose there exist two explanations for an occurrence. In this case the one that requires the least speculation is usually better.  
    Another way of saying it is that the more assumptions you have to make, the more unlikely an explanation.  
    > It is neither _precise_ nor _self evident_.    -->

<!-- 2. **Misc:**{: style="color: SteelBlue"}{: .bodyContents11 #bodyContents112}  
3. **Misc:**{: style="color: SteelBlue"}{: .bodyContents11 #bodyContents113}   -->

<p id="lst-p"><strong style="color: red">Resources:</strong></p>
<ul>
  <li><a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html">Reinforcement Learning Course Lectures UCL</a></li>
  <li><a href="https://people.eecs.berkeley.edu/~pabbeel/cs287-fa15/">Advanced Robotics Lecture CS287 Berk</a></li>
  <li><a href="https://fullstackdeeplearning.com/march2019">Full-Stack DL (productionization of DL) Bootcamp Peter Abbeel</a></li>
  <li><a href="https://sites.google.com/view/berkeley-cs294-158-sp19/home">Deep Unsupervised Learning CS294 Berk</a></li>
  <li><a href="https://sites.google.com/view/deep-rl-bootcamp/lectures">Deep RL WS1</a></li>
  <li><a href="https://sites.google.com/view/deep-rl-workshop-nips-2018/home">Deep RL WS2</a></li>
  <li><a href="http://rail.eecs.berkeley.edu/deeprlcourse/">Deep RL Lec CS294 Berk</a></li>
  <li><a href="https://en.d2l.ai/d2l-en.pdf">DeepLearning Book (dive into dl) Berkeley</a>
    <ul>
      <li><a href="https://www.d2l.ai/">d2l course website</a></li>
    </ul>
  </li>
  <li><a href="https://www.youtube.com/watch?v=Mdp9uC3gXUU">Mathematics of DL</a></li>
  <li><a href="https://jhui.github.io/2017/01/05/Deep-learning-linear-algebra/">Deep Learning Linear Algebra</a></li>
  <li><a href="https://www.inference.vc/untitled/">Intro to Causal Inference (do-Calculus)</a></li>
  <li><a href="https://www.technologyreview.com/s/602344/the-extraordinary-link-between-deep-neural-networks-and-the-nature-of-the-universe/">DL and Physics</a></li>
  <li><a href="https://ee227c.github.io/">EE227C: Convex Optimization and Approximation</a></li>
  <li><a href="https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf">Boyd Cvx-Opt</a></li>
  <li><a href="http://www.stat.cmu.edu/~ryantibs/convexopt/">Tibshirani Cvx-Opt</a></li>
  <li><a href="https://docs.google.com/document/d/1w_fcJKNyXUMhMS328w7qiOr-P1dSOHALuBnOjEbiZYA/edit">Efficient DL</a></li>
  <li><a href="https://sailinglab.github.io/pgm-spring-2019/">Probabilistic Graphical Models CS-708 (CMU!)</a></li>
  <li><a href="https://berkeley-deep-learning.github.io">Deep learning courses at UC Berkeley!</a></li>
  <li><a href="https://bcourses.berkeley.edu/courses/1478831/pages/cs182-slash-282a-designing-visualizing-and-understanding-deep-neural-networks-spring-2019">CS182/282A Designing, Visualizing and Understanding Deep Neural Networks Spring 2019</a></li>
  <li><a href="https://quantum.country/qcvc">Quantum Computing Learning Resource (Blog!)</a></li>
</ul>


      <footer class="site-footer">
    <!--   <span class="site-footer-owner"><a href="http://localhost:8889">Ahmad Badary</a> is maintained by <a href="https://ahmedbadary.github.io/">Ahmad Badary</a>.</span> -->
    
<!--  -->
    <div class="wrapper">
        <div class="footer-col-wrapper">
            <div class="footer-col footer-col-1">
            <span class="site-footer-owner"><a href="http://localhost:8889">Site</a> maintained by <a href="https://ahmedbadary.github.io/">Ahmad Badary</a>.</span>
    <span class="site-footer-credits">
        <p>
            &copy; 2017. All rights reserved.
        </p> 
    </span>
            </div>
            <div class="footer-col footer-col-2">
            <div><p>         </p></div>
            </div>
            <div class="footer-col footer-col-3">
                <ul class="social-media-list">
                    
                      <li>
                        <a href="https://github.com/AhmedBadary">
                          <i class="fa fa-github"></i> GitHub
                        </a>
                      </li>
                    
                    
                      <li>
                        <a href="https://linkedin.com/in/ahmad-badary-656098121/">
                          <i class="fa fa-linkedin"></i> LinkedIn
                        </a>
                      </li>
                    
                    
                      <li>
                        <a href="https://www.facebook.com/ahmed.thabet.94">
                          <i class="fa fa-facebook"></i> Facebook
                        </a>
                      </li>
                    
                </ul>
            </div>
        </div>
    </div>
<!--  -->
</footer>


    </section>

  </body>

<!-- Table of Content Script -->
<script type="text/javascript">
var bodyContents = $(".bodyContents1");
$("<ol>").addClass("TOC1ul").appendTo(".TOC1");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC1ul");
     });
// 
var bodyContents = $(".bodyContents2");
$("<ol>").addClass("TOC2ul").appendTo(".TOC2");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC2ul");
     });
// 
var bodyContents = $(".bodyContents3");
$("<ol>").addClass("TOC3ul").appendTo(".TOC3");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC3ul");
     });
//
var bodyContents = $(".bodyContents4");
$("<ol>").addClass("TOC4ul").appendTo(".TOC4");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC4ul");
     });
//
var bodyContents = $(".bodyContents5");
$("<ol>").addClass("TOC5ul").appendTo(".TOC5");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC5ul");
     });
//
var bodyContents = $(".bodyContents6");
$("<ol>").addClass("TOC6ul").appendTo(".TOC6");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC6ul");
     });
//
var bodyContents = $(".bodyContents7");
$("<ol>").addClass("TOC7ul").appendTo(".TOC7");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC7ul");
     });
//
var bodyContents = $(".bodyContents8");
$("<ol>").addClass("TOC8ul").appendTo(".TOC8");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC8ul");
     });
//
var bodyContents = $(".bodyContents9");
$("<ol>").addClass("TOC9ul").appendTo(".TOC9");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC9ul");
     });

</script>

<!-- VIDEO BUTTONS SCRIPT -->
<script type="text/javascript">
  function iframePopInject(event) {
    var $button = $(event.target);
    // console.log($button.parent().next());
    if ($button.attr('value') == 'show') {
        $button.attr('value', 'hide');
        $figure = $("<div>").addClass("video_container");
        $iframe = $("<iframe>").appendTo($figure);
        $iframe.attr("src", $button.attr("src"));
        // $iframe.attr("frameborder", "0");
        $iframe.attr("allowfullscreen", "true");
        $iframe.css("padding", "4px 6px");
        $button.next().css("display", "block");
        $figure.appendTo($button.next());
        $button.text("Hide Video")
    } else {
        $button.attr('value', 'show');
        $button.next().html("");
        $button.text("Show Video")
    }
}
</script>

<!-- BUTTON TRY -->
<script type="text/javascript">
  function iframePopA(event) {
    event.preventDefault();
    var $a = $(event.target).parent();
    console.log($a);
    if ($a.attr('value') == 'show') {
        $a.attr('value', 'hide');
        $figure = $("<div>");
        $iframe = $("<iframe>").addClass("popup_website_container").appendTo($figure);
        $iframe.attr("src", $a.attr("href"));
        $iframe.attr("frameborder", "1");
        $iframe.attr("allowfullscreen", "true");
        $iframe.css("padding", "4px 6px");
        $a.next().css("display", "block");
        $figure.appendTo($a.next().next());
        // $a.text("Hide Content")
        $('html, body').animate({
            scrollTop: $a.offset().top
        }, 1000);
    } else {
        $a.attr('value', 'show');
        $a.next().next().html("");
        // $a.text("Show Content")
    }

    $a.next().css("display", "inline");
}
</script>


<!-- TEXT BUTTON SCRIPT - INJECT -->
<script type="text/javascript">
  function showTextPopInject(event) {
    var $button = $(event.target);
    var txt = $button.attr("input");
    console.log(txt);
    if ($button.attr('value') == 'show') {
        $button.attr('value', 'hide');
        $p = $("<p>");
        $p.html(txt);
        $button.next().css("display", "block");
        $p.appendTo($button.next());
        $button.text("Hide Content")
    } else {
        $button.attr('value', 'show');
        $button.next().html("");
        $button.text("Show Content")
    }

}
</script>

<!-- TEXT BUTTON SCRIPT - HIDDEN / HIDE / SHOW / HIDE/SHOW -->
<script type="text/javascript">
  function showTextPopHide(event) {
    var $button = $(event.target);
    // var txt = $button.attr("input");
    var txt = $button.text();
    if ($button.attr('value') == 'show') {
        $button.attr('value', 'hide');
        $button.next().removeAttr("hidden");
        $button.text(txt + " - Hide Content");
    } else {
        $button.attr('value', 'show');
        $button.next().attr("hidden", "");
        $button.text(txt.replace(" - Hide Content",""));
    }
}
</script>

<!-- TEXT BUTTON SCRIPT - HIDDEN / HIDE / SHOW / HIDE/SHOW -->
<script type="text/javascript">
  function showText_withParent_PopHide(event) {
    var $button = $(event.target);
    var $parent = $button.parent();
    var txt = $button.text();
    if ($button.attr('value') == 'show') {
        $button.attr('value', 'hide');
        $parent.next().removeAttr("hidden");
        $button.text(txt + " - Hide Content");
    } else {
        $button.attr('value', 'show');
        $parent.next().attr("hidden", "");
        $button.text(txt.replace(" - Hide Content",""));
    }
}
</script>

<!-- Print / Printing / printme -->
<!-- <script type="text/javascript">
i = 0

for (var i = 1; i < 6; i++) {
    var bodyContents = $(".bodyContents" + i);
    $("<p>").addClass("TOC1ul")  .appendTo(".TOC1");
    bodyContents.each(function(index, element) {
        var paragraph = $(element);
        $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC1ul");
         });
} 
</script>
 -->
 
</html>

