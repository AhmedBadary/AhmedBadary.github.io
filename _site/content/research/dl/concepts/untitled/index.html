<!DOCTYPE html>
<html lang="en-us">
  <head>
  <meta charset="UTF-8">
  <title>Ahmad Badary</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <link rel="stylesheet" href="/css/normalize.css">
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="/css/cayman.css">
  <link rel="stylesheet" href="/css/style.css">
  <link rel="shortcut icon" href="/main_files/favicon.ico" />
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="/css/customStyle.css">
  <title> » Ahmad Badary</title>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
</head>

  <body>
    <nav class="main-nav">
    <a href="https://ahmedbadary.github.io/" class="main-nav-logo">
        <img src="/main_files/logo.png">
    </a>
    <ul id="menu-main" class="main-nav-items">
        <li id="menu-item-1859" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-home menu-item-1859">
            <a href="/">Home</a>
        </li>
        <li id="menu-item-2869" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-2869">
            <a href="/work">Work</a>
        </li>
        <li id="menu-item-1892" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1892">
            <a href="/projects">Projects</a>
        </li>
        <li id="menu-item-1858" class="menu-item menu-item-type-post_type menu-item-object-page current_page_parent menu-item-1858">
            <a href="/blog">Blog</a>
        </li>
        <li id="menu-item-1862" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1862">
            <a href="/about">About</a>
        </li>
    </ul>
</nav>


<section class="page-header">
  <h1 class="project-name">The Learning Problem</h1>
  <h2 class="project-tagline"></h2>
  <a href="https://github.com/AhmedBadary/" class="btn">GitHub</a>
  <a href="https://www.linkedin.com/in/ahmad-badary-656098121/" class="btn">LinkedIn</a>
  <a href=https://www.facebook.com/ahmed.thabet.94 class="btn">Facebook</a>
</section>

<!-- <div>
  <ul class="posts">
    
      <li><span>02 Jan 2014</span> &raquo; <a href="/2014/01/02/introducing-Ahmad/">Introducing Ahmad</a></li>
    
  </ul>
</div> -->


    <section class="main-content">
      
      <!-- <div class="page">
  <h1 class="page-title">The Learning Problem</h1>
  <h2 id="the-learning-problem">The Learning Problem</h2>

<p><span style="color: goldenrod"><strong>Learning</strong></span>:<br />
A computer program is said to learn from <em><strong>experience</strong></em> \(E\) with respect to some class of <em><strong>tasks</strong></em> \(T\) and <em><strong>performance measure</strong></em> \(P\), if its performance at tasks in \(T\), as measured by \(P\), improves with experience \(E\).</p>

<ol>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents11">The Basic Premise/Goal of Learning:</strong><br />
 “Using a set of observations to uncover an underlying process”<br />
 Rephrased mathematically, the <strong>Goal of Learning</strong> is: <br />
 Use the Data to find a hypothesis \(g \in \mathcal{H}\), from the hypothesis set \(\mathcal{H}=\{h\}\), that <em>approximates</em> \(f\) well.</p>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents12">When to do Learning:</strong><br />
 When:
    <ol>
      <li>A pattern Exists</li>
      <li>We cannot pin the pattern down mathematically</li>
      <li>We have Data</li>
    </ol>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents13">Components of the Problem (Learning):</strong>
    <ul>
      <li><strong>Input</strong>: \(\vec{x}\)</li>
      <li><strong>Output</strong>: \(y\)</li>
      <li><strong>Data</strong>:  \({(\vec{x}_ 1, y_ 1), (\vec{x}_ 2, y_ 2), ..., (\vec{x}_ N, y_ N)}\)</li>
      <li><strong>Target Function</strong>: \(f : \mathcal{X} \rightarrow \mathcal{Y}\)  (Unknown/Unobserved)</li>
      <li><strong>Hypothesis</strong>: \(g : \mathcal{X} \rightarrow \mathcal{Y}\)</li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents15">Components of the Solution:</strong>
    <ul>
      <li><strong>The Learning Model</strong>:
        <ul>
          <li><strong>The Hypothesis Set</strong>:  \(\mathcal{H}=\{h\},  g \in \mathcal{H}\)
            <blockquote>
              <p>E.g. Perceptron, SVM, FNNs, etc.</p>
            </blockquote>
          </li>
          <li><strong>The Learning Algorithm</strong>: picks \(g \approx f\) from a hypothesis set \(\mathcal{H}\)
            <blockquote>
              <p>E.g. Backprop, Quadratic Programming, etc.</p>
            </blockquote>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents18">The Learning Diagram:</strong><br />
 <img src="/main_files/dl/theory/caltech/3.png" alt="img" width="70%" /></p>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents17">Types of Learning:</strong>
    <ul>
      <li><strong>Supervised Learning</strong>: the task of learning a function that maps an input to an output based on example input-output pairs.<br />
  <img src="/main_files/dl/theory/caltech/4.png" alt="img" width="70%" /></li>
      <li><strong>Unsupervised Learning</strong>: the task of making inferences, by learning a better representation, from some datapoints that do not have any labels associated with them.<br />
  <img src="/main_files/dl/theory/caltech/5.png" alt="img" width="70%" />
        <blockquote>
          <p>Unsupervised Learning is another name for <a href="https://en.wikipedia.org/wiki/Hebbian_theory">Hebbian Learning</a></p>
        </blockquote>
      </li>
      <li><strong>Reinforcement Leaning</strong>: the task of learning how software agents ought to take actions in an environment so as to maximize some notion of cumulative reward.<br />
  <img src="/main_files/dl/theory/caltech/6.png" alt="img" width="70%" /></li>
    </ul>
  </li>
</ol>

<h2 id="the-feasibility-of-learning">The Feasibility of Learning</h2>

<div class="borderexample" style="padding: 0;">
  <p>The Goal of this Section is to answer the question: <br />
<span style="color: purple"><strong>“Can we make any statements/inferences outside of the sample data that we have?”</strong></span></p>
</div>

<ol>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents21">The Problem of Learning:</strong><br />
 Learning a truly <strong>Unknown</strong> function is <strong>Impossible</strong>, since outside of the observed values, the function could assume <em>any value</em> it wants.</p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents22">Learning is Feasible:</strong><br />
 The statement we made that is equivalent to <strong>Learning is Feasible</strong> is the following:<br />
 We establish a <strong>theoretical guarantee</strong> that when you <span style="color: purple"><strong>do well in-sample</strong></span> \(\implies\) you <span style="color: purple"><strong>do well out-of-sample (<em>“Generalization”</em>)</strong> </span>.</p>

    <p><strong>Learning Feasibility</strong>:<br />
 When learning we only deal with In-Sample Errors \(E_{\text{in}}(\mathbf{w})\); we never handle the out-sample error explicitly; we take the theoretical guarantee that when you do well in-sample \(\implies\) you do well out-sample (Generalization).</p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents23">Achieving Learning:</strong><br />
 <strong>Generalization VS Learning:</strong><br />
 We know that <em>Learning is Feasible</em>.</p>
    <ul>
      <li><strong>Generalization</strong>:<br />
  It is likely that the following condition holds:
        <p>$$\: E_{\text {out }}(g) \approx E_{\text {in }}(g)  \tag{3.1}$$</p>
        <p>This is equivalent to “good” <strong>Generalization</strong>.</p>
      </li>
      <li><strong>Learning</strong>:<br />
  Learning corresponds to the condition that \(g \approx f\), which in-turn corresponds to the condition:
        <p>$$E_{\text {out }}(g) \approx 0  \tag{3.2}$$</p>
      </li>
    </ul>

    <p id="lst-p"><strong style="color: red">How to achieve Learning:</strong>  <br />
 We achieve \(E_{\text {out }}(g) \approx 0\) through:</p>
    <ol>
      <li>\(E_{\mathrm{out}}(g) \approx E_{\mathrm{in}}(g)\)<br />
 A <strong>theoretical</strong> result achieved through Hoeffding <strong style="color: red">PROBABILITY THEORY</strong>  .</li>
      <li>\(E_{\mathrm{in}}(g) \approx 0\)<br />
 A <strong>Practical</strong> result of minimizing the In-Sample Error Function (ERM) <strong style="color: red">Optimization</strong>  .</li>
    </ol>

    <p id="lst-p">Learning is, thus, reduced to the 2 following questions:</p>
    <ol>
      <li>Can we make sure that \(E_{\text {out }}(g)\) is close enough to \(E_{\text {in }}(g)\)? (theoretical)</li>
      <li>Can we make \(E_{\text {in}}(g)\) small enough? (practical)</li>
    </ol>
  </li>
</ol>

</div> -->

<h2 id="the-learning-problem">The Learning Problem</h2>

<p><span style="color: goldenrod"><strong>Learning</strong></span>:<br />
A computer program is said to learn from <em><strong>experience</strong></em> \(E\) with respect to some class of <em><strong>tasks</strong></em> \(T\) and <em><strong>performance measure</strong></em> \(P\), if its performance at tasks in \(T\), as measured by \(P\), improves with experience \(E\).</p>

<ol>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents11">The Basic Premise/Goal of Learning:</strong><br />
 “Using a set of observations to uncover an underlying process”<br />
 Rephrased mathematically, the <strong>Goal of Learning</strong> is: <br />
 Use the Data to find a hypothesis \(g \in \mathcal{H}\), from the hypothesis set \(\mathcal{H}=\{h\}\), that <em>approximates</em> \(f\) well.</p>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents12">When to do Learning:</strong><br />
 When:
    <ol>
      <li>A pattern Exists</li>
      <li>We cannot pin the pattern down mathematically</li>
      <li>We have Data</li>
    </ol>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents13">Components of the Problem (Learning):</strong>
    <ul>
      <li><strong>Input</strong>: \(\vec{x}\)</li>
      <li><strong>Output</strong>: \(y\)</li>
      <li><strong>Data</strong>:  \({(\vec{x}_ 1, y_ 1), (\vec{x}_ 2, y_ 2), ..., (\vec{x}_ N, y_ N)}\)</li>
      <li><strong>Target Function</strong>: \(f : \mathcal{X} \rightarrow \mathcal{Y}\)  (Unknown/Unobserved)</li>
      <li><strong>Hypothesis</strong>: \(g : \mathcal{X} \rightarrow \mathcal{Y}\)</li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents15">Components of the Solution:</strong>
    <ul>
      <li><strong>The Learning Model</strong>:
        <ul>
          <li><strong>The Hypothesis Set</strong>:  \(\mathcal{H}=\{h\},  g \in \mathcal{H}\)
            <blockquote>
              <p>E.g. Perceptron, SVM, FNNs, etc.</p>
            </blockquote>
          </li>
          <li><strong>The Learning Algorithm</strong>: picks \(g \approx f\) from a hypothesis set \(\mathcal{H}\)
            <blockquote>
              <p>E.g. Backprop, Quadratic Programming, etc.</p>
            </blockquote>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents18">The Learning Diagram:</strong><br />
 <img src="/main_files/dl/theory/caltech/3.png" alt="img" width="70%" /></p>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents17">Types of Learning:</strong>
    <ul>
      <li><strong>Supervised Learning</strong>: the task of learning a function that maps an input to an output based on example input-output pairs.<br />
  <img src="/main_files/dl/theory/caltech/4.png" alt="img" width="70%" /></li>
      <li><strong>Unsupervised Learning</strong>: the task of making inferences, by learning a better representation, from some datapoints that do not have any labels associated with them.<br />
  <img src="/main_files/dl/theory/caltech/5.png" alt="img" width="70%" />
        <blockquote>
          <p>Unsupervised Learning is another name for <a href="https://en.wikipedia.org/wiki/Hebbian_theory">Hebbian Learning</a></p>
        </blockquote>
      </li>
      <li><strong>Reinforcement Leaning</strong>: the task of learning how software agents ought to take actions in an environment so as to maximize some notion of cumulative reward.<br />
  <img src="/main_files/dl/theory/caltech/6.png" alt="img" width="70%" /></li>
    </ul>
  </li>
</ol>

<h2 id="the-feasibility-of-learning">The Feasibility of Learning</h2>

<div class="borderexample" style="padding: 0;">
  <p>The Goal of this Section is to answer the question: <br />
<span style="color: purple"><strong>“Can we make any statements/inferences outside of the sample data that we have?”</strong></span></p>
</div>

<ol>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents21">The Problem of Learning:</strong><br />
 Learning a truly <strong>Unknown</strong> function is <strong>Impossible</strong>, since outside of the observed values, the function could assume <em>any value</em> it wants.</p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents22">Learning is Feasible:</strong><br />
 The statement we made that is equivalent to <strong>Learning is Feasible</strong> is the following:<br />
 We establish a <strong>theoretical guarantee</strong> that when you <span style="color: purple"><strong>do well in-sample</strong></span> \(\implies\) you <span style="color: purple"><strong>do well out-of-sample (<em>“Generalization”</em>)</strong> </span>.</p>

    <p><strong>Learning Feasibility</strong>:<br />
 When learning we only deal with In-Sample Errors \(E_{\text{in}}(\mathbf{w})\); we never handle the out-sample error explicitly; we take the theoretical guarantee that when you do well in-sample \(\implies\) you do well out-sample (Generalization).</p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents23">Achieving Learning:</strong><br />
 <strong>Generalization VS Learning:</strong><br />
 We know that <em>Learning is Feasible</em>.</p>
    <ul>
      <li><strong>Generalization</strong>:<br />
  It is likely that the following condition holds:
        <p>$$\: E_{\text {out }}(g) \approx E_{\text {in }}(g)  \tag{3.1}$$</p>
        <p>This is equivalent to “good” <strong>Generalization</strong>.</p>
      </li>
      <li><strong>Learning</strong>:<br />
  Learning corresponds to the condition that \(g \approx f\), which in-turn corresponds to the condition:
        <p>$$E_{\text {out }}(g) \approx 0  \tag{3.2}$$</p>
      </li>
    </ul>

    <p id="lst-p"><strong style="color: red">How to achieve Learning:</strong>  <br />
 We achieve \(E_{\text {out }}(g) \approx 0\) through:</p>
    <ol>
      <li>\(E_{\mathrm{out}}(g) \approx E_{\mathrm{in}}(g)\)<br />
 A <strong>theoretical</strong> result achieved through Hoeffding <strong style="color: red">PROBABILITY THEORY</strong>  .</li>
      <li>\(E_{\mathrm{in}}(g) \approx 0\)<br />
 A <strong>Practical</strong> result of minimizing the In-Sample Error Function (ERM) <strong style="color: red">Optimization</strong>  .</li>
    </ol>

    <p id="lst-p">Learning is, thus, reduced to the 2 following questions:</p>
    <ol>
      <li>Can we make sure that \(E_{\text {out }}(g)\) is close enough to \(E_{\text {in }}(g)\)? (theoretical)</li>
      <li>Can we make \(E_{\text {in}}(g)\) small enough? (practical)</li>
    </ol>
  </li>
</ol>


      <footer class="site-footer">
    <!--   <span class="site-footer-owner"><a href="http://localhost:8880">Ahmad Badary</a> is maintained by <a href="http://ahmedbadary.ml">Ahmad Badary</a>.</span> -->
    
<!--  -->
    <div class="wrapper">
        <div class="footer-col-wrapper">
            <div class="footer-col footer-col-1">
            <span class="site-footer-owner"><a href="http://localhost:8880">Site</a> maintained by <a href="http://ahmedbadary.ml">Ahmad Badary</a>.</span>
    <span class="site-footer-credits">
        <p>
            &copy; 2017. All rights reserved.
        </p> 
    </span>
            </div>
            <div class="footer-col footer-col-2">
            <div><p>         </p></div>
            </div>
            <div class="footer-col footer-col-3">
                <ul class="social-media-list">
                    
                      <li>
                        <a href="https://github.com/AhmedBadary">
                          <i class="fa fa-github"></i> GitHub
                        </a>
                      </li>
                    
                    
                      <li>
                        <a href="https://linkedin.com/in/ahmad-badary-656098121/">
                          <i class="fa fa-linkedin"></i> LinkedIn
                        </a>
                      </li>
                    
                    
                      <li>
                        <a href="https://www.facebook.com/ahmed.thabet.94">
                          <i class="fa fa-facebook"></i> Facebook
                        </a>
                      </li>
                    
                </ul>
            </div>
        </div>
    </div>
<!--  -->
</footer>


    </section>

  </body>
</html>
