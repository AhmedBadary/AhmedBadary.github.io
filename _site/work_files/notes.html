<!DOCTYPE html>
<html lang="en-us">
  <head>
  <meta charset="UTF-8">
  <title>Ahmad Badary</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <link rel="stylesheet" href="/css/normalize.css">
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="/css/cayman.css">
  <link rel="stylesheet" href="/css/style.css">
  <link rel="shortcut icon" href="/main_files/favicon.ico" />
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="/css/customStyle.css">
  <title> » Ahmad Badary</title>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
</head>

  <body>
    <nav class="main-nav">
    <a href="https://ahmedbadary.github.io/" class="main-nav-logo">
        <img src="/main_files/logo.png">
    </a>
    <ul id="menu-main" class="main-nav-items">
        <li id="menu-item-1859" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-home menu-item-1859">
            <a href="/">Home</a>
        </li>
        <li id="menu-item-2869" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-2869">
            <a href="/work">Work</a>
        </li>
        <li id="menu-item-1892" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1892">
            <a href="/projects">Projects</a>
        </li>
        <li id="menu-item-1858" class="menu-item menu-item-type-post_type menu-item-object-page current_page_parent menu-item-1858">
            <a href="/blog">Blog</a>
        </li>
        <li id="menu-item-1862" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1862">
            <a href="/about">About</a>
        </li>
    </ul>
</nav>


<section class="page-header">
  <h1 class="project-name">Notes</h1>
  <h2 class="project-tagline"></h2>
  <a href="/#" class="btn">Home</a>
  <a href="/work" class="btn">Work-Space</a>
  <a href= /work_files/research/dl/theory.html class="btn">Previous</a>
</section>

<!-- <div>
  <ul class="posts">
    
      <li><span>02 Jan 2014</span> &raquo; <a href="/2014/01/02/introducing-Ahmad/">Introducing Ahmad</a></li>
    
  </ul>
</div> -->


    <section class="main-content">
      
      <div class="TOC">
  <h1 id="table-of-contents">Table of Contents</h1>

  <ul class="TOC1">
    <li><a href="#content1">FIRST</a></li>
  </ul>
  <ul class="TOC2">
    <li><a href="#content2">SECOND</a></li>
  </ul>
  <!--     * [Feature Importance](#content3)
  {: .TOC3}
  * [FOURTH](#content4)
  {: .TOC4}
  * [FIFTH](#content5)
  {: .TOC5}
  * [SIXTH](#content6)
  {: .TOC6} -->
</div>

<hr />
<hr />

<h2 id="content1">Data Drift/Shift</h2>

<ol>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents11">Linear Algebra:</strong></p>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents12">General Data Distribution Shifts:</strong>
    <ul>
      <li><strong>Feature change</strong>, such as when new features are added, older features are removed, or the set of all possible values of a feature changes:
  months to years</li>
      <li>
        <table>
          <tbody>
            <tr>
              <td><strong>Label schema change</strong> is when the set of possible values for Y change. With label shift, P(Y) changes but P(X</td>
              <td>Y) remains the same. With label schema change, both P(Y) and P(X</td>
              <td>Y) change.</td>
            </tr>
          </tbody>
        </table>
        <ul>
          <li><em><strong>CREDIT:</strong></em> * With regression tasks, label schema change could happen because of changes in the possible range of label values. Imagine you’re building a model to predict someone’s credit score. Originally, you used a credit score system that ranged from 300 to 850, but you switched to a new system that ranges from 250 to 900.</li>
        </ul>
      </li>
      <li></li>
    </ul>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents13">Linear Algebra:</strong></p>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents14">Handling Data Distribution Shifts:</strong>
    <ol>
      <li>DETECTION</li>
      <li>HANDLING</li>
    </ol>

    <ul>
      <li><strong style="color: blue">DETECTION:</strong>
        <ul>
          <li>monitor your model’s accuracy-related metrics30 in production to see whether they have changed.
            <ul>
              <li>
                <table>
                  <tbody>
                    <tr>
                      <td>When ground truth labels are unavailable or too delayed to be useful, we can monitor other distributions of interest instead. The distributions of interest are the input distribution P(X), the label distribution P(Y), and the conditional distributions P(X</td>
                      <td>Y) and P(Y</td>
                      <td>X).</td>
                    </tr>
                  </tbody>
                </table>
              </li>
              <li>In research, there have been efforts to understand and detect label shifts without labels from the target distribution. One such effort is Black Box Shift Estimation by Lipton et al., 2018.</li>
            </ul>
          </li>
          <li><strong style="color: blue">Statistical Methods:</strong>
            <ul>
              <li>a simple method many companies use to detect whether the two distributions are the same is to compare their statistics like mean, median, variance, quantiles, skewness, kurtosis, etc. (bad)
                <ul>
                  <li>If those metrics differ significantly, the inference distribution might have shifted from the training distribution. However, if those metrics are similar, there’s no guarantee that there’s no shift.</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<h2 id="content2">Encoding</h2>

<ol>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents21">Linear Algebra:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents22">Linear Algebra:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents23">Linear Algebra:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents24">Linear Algebra:</strong></p>
  </li>
</ol>

<h2 id="content3">Feature Importance</h2>

<ol>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents3" id="bodyContents31">Linear Algebra:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents3" id="bodyContents32">Linear Algebra:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents3" id="bodyContents33">Linear Algebra:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents3" id="bodyContents34">Linear Algebra:</strong></p>
  </li>
</ol>

<h2 id="content4">Feature Selection</h2>

<ol>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents4" id="bodyContents41">Linear Algebra:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents4" id="bodyContents42">Linear Algebra:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents4" id="bodyContents43">Linear Algebra:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents4" id="bodyContents44">Linear Algebra:</strong></p>
  </li>
</ol>

<h2 id="content5">Data Preprocessing and Normalization</h2>

<ol>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents5" id="bodyContents51">Linear Algebra:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents5" id="bodyContents52">Linear Algebra:</strong></p>

    <p id="lst-p"><strong style="color: red">Data Regularization:</strong></p>
    <ul>
      <li>The <strong>Design Matrix</strong> contains sample points in each <em><strong>row</strong></em></li>
      <li><strong>Feature Scaling/Mean Normalization (of data)</strong>:
        <ul>
          <li>Define the mean \(\mu_j\) of each feature of the datapoints \(x^{(i)}\):</li>
        </ul>
        <p>$$\mu_{j}=\frac{1}{m} \sum_{i=1}^{m} x_{j}^{(i)}$$</p>
        <ul>
          <li>Replace each \(x_j^{(i)}\) with \(x_j - \mu_j\)</li>
        </ul>
      </li>
      <li><strong>Centering</strong>:  subtracting \(\mu\) from each row of \(X\)</li>
      <li><strong>Sphering</strong>:  applying the transform \(X' = X \Sigma^{-1/2}\)</li>
      <li><strong>Whitening</strong>:  Centering + Sphering (also known as <em><strong>Decorrelating feature space</strong></em>)</li>
    </ul>

    <p><strong>Why Normalize the Data/Signal?</strong><br />
 <img src="https://cdn.mathpix.com/snip/images/8aNuJetgTgCtv4pvqaI0dr96pDyUmfuX_d1aLK1lmaw.original.fullsize.png" alt="img" width="40%" /></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents5" id="bodyContents53">Linear Algebra:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents5" id="bodyContents54">CODE:</strong></p>
    <ul>
      <li><a href="https://hadrienj.github.io/posts/Preprocessing-for-deep-learning/">Preprocessing for deep learning: from covariance matrix to image whitening (Blog)</a>
        <ul>
          <li><a href="https://github.com/hadrienj/Preprocessing-for-deep-learning">NOTEBOOK</a></li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<h2 id="content6">Validation &amp; Evaluation - ROC, AUC, Reject Inference + Off-policy Evaluation</h2>

<ol>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents6" id="bodyContents61">Linear Algebra:</strong></p>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents6" id="bodyContents62">ROC:</strong>
    <ul>
      <li>A way to quantify how good a <strong>binary classifier</strong> separates two classes</li>
      <li>True-Positive-Rate / False-Positive-Rate</li>
      <li>Good classifier has a ROC curve that is near the top-left diagonal (hugging it)</li>
      <li>A Bad Classifier has a ROC curve that is close to the diagonal line</li>
      <li>It allows you to set the <strong>classification threshold</strong>
        <ul>
          <li>You can minimize False-positive rate or maximize the True-Positive Rate</li>
        </ul>
      </li>
    </ul>

    <p id="lst-p"><strong style="color: red">Notes:</strong></p>
    <ul>
      <li>ROC curve is monotone increasing from 0 to 1 and is invariant to any monotone transformation of test results.</li>
      <li>ROC curves (&amp; AUC) are useful even if the <strong>predicted probabilities</strong> are not <em><strong>“properly calibrated”</strong></em></li>
      <li>ROC curves are not affected by monotonically increasing functions</li>
      <li><a href="https://builtin.com/data-science/roc-curves-auc">Scale and Threshold Invariance (Blog)</a></li>
      <li>Accuracy is neither a threshold-invariant metric nor a scale-invariant metric.</li>
      <li>
        <p>When to use <strong>PRECISION</strong>: when data is <em><strong>imbalanced</strong></em> E.G. when the number of <em><strong>negative</strong></em> examples is <strong>larger</strong> than <em><strong>positive</strong></em>.<br />
  Precision does not include <strong>TN (True Negatives)</strong> so NOT AFFECTED.<br />
  In PRACTICE, e.g. studying <em><strong>RARE Disease</strong></em>.<br />
 <br /></p>
      </li>
      <li>ROC Curve only cares about the <em><strong>ordering</strong></em> of the scores, not the values.</li>
      <li>
        <p><strong>Probability Calibration</strong> and ROC: The calibration doesn’t change the order of the scores, it just scales them to make a better match, and the ROC score only cares about the ordering of the scores.</p>
      </li>
      <li>
        <p><a href="https://kiwidamien.github.io/what-is-a-roc-curve-a-visualization-with-credit-scores.html">ROC and Credit Score Example (Blog)</a></p>
      </li>
      <li><strong>AUC</strong>: The AUC is also the probability that a randomly selected positive example has a higher score than a randomly selected negative example.</li>
    </ul>

    <p><button class="showText" value="show" onclick="showTextPopHide(event);">AUC Reliability (Equal AUC - different models)</button>
 <img src="https://cdn.mathpix.com/snip/images/GAyvZvN61xzDjklTeVepqrYYuWrXXfPnEHkNwM80p6k.original.fullsize.png" alt="img" width="100%" hidden="" /></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents6" id="bodyContents63">AUC:</strong><br />
 AUC provides an aggregate measure of performance across all possible classification thresholds. One way of interpreting AUC is as the probability that the model ranks a random positive example more highly than a random negative example.</p>

    <ul>
      <li>
        <p>Range \(= 0.5 - 1.0\), from poor to perfect</p>
      </li>
      <li><strong style="color: blue">Pros:</strong>
        <ul>
          <li>AUC is <em><strong>scale-invariant</strong></em>: It measures how well predictions are ranked, rather than their absolute values.</li>
          <li>AUC is <em><strong>classification-threshold-invariant</strong></em>: It measures the quality of the model’s predictions irrespective of what classification threshold is chosen.</li>
        </ul>

        <blockquote>
          <p>These properties make AUC pretty valuable for evaluating binary classifiers as it provides us with a way to compare them without caring about the classification threshold.</p>
        </blockquote>
      </li>
      <li>
        <p><strong style="color: red">Cons</strong> <br />
  However, both these reasons come with caveats, which may limit the usefulness of AUC in certain use cases:</p>

        <ul>
          <li>
            <p>Scale invariance is not always desirable. For example, sometimes we really do need well calibrated probability outputs, and AUC won’t tell us about that.</p>
          </li>
          <li>
            <p>Classification-threshold invariance is not always desirable. In cases where there are wide disparities in the cost of false negatives vs. false positives, it may be critical to minimize one type of classification error. For example, when doing email spam detection, you likely want to prioritize minimizing false positives (even if that results in a significant increase of false negatives). AUC isn’t a useful metric for this type of optimization.</p>
          </li>
        </ul>
      </li>
    </ul>

    <p id="lst-p"><strong style="color: red">Notes:</strong></p>
    <ul>
      <li><strong>Partial AUC</strong> can be used when only a portion of the entire ROC curve needs to be considered.<br />
 <br /></li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents6" id="bodyContents64">Reject Inference and Off-policy Evaluation:</strong>
    <ul>
      <li>
        <p><strong>Reject inference</strong> is a method for performing off-policy evaluation, which is a way to estimate the performance of a policy (a decision-making strategy) based on data generated by a different policy. In reject inference, the idea is to use importance sampling to weight the data in such a way that the samples generated by the behavior policy (the one that generated the data) are down-weighted, while the samples generated by the target policy (the one we want to evaluate) are up-weighted. This allows us to focus on the samples that are most relevant to the policy we are trying to evaluate, which can improve the accuracy of our estimates.</p>
      </li>
      <li>
        <p><strong>Off-policy evaluation</strong> is useful in situations where it is not possible or practical to directly evaluate the performance of a policy. For example, in a real-world setting, it may not be possible to directly evaluate a new policy because it could be risky or expensive to implement. In such cases, off-policy evaluation can help us estimate the performance of the policy using data generated by a different, perhaps safer or more easily implemented, policy.</p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents6" id="bodyContents65">Validation:</strong></p>

    <ol>
      <li>
        <p>Validate a model with given constraints (see above).</p>

        <p>Spoke to the recruiter who was super nice and transparent. Scheduled a technical screening afterwards. The question was to validate a model only knowing the true values and predicted values. The interviewer wanted to incorporate the business value of the model. I found this to be interesting and odd as how can the business value validate any model. As we walked through the problem, the interviewer did not care about traditional statistical error measures and techniques in model validation. The interviewer wanted to incorporate the business cases (i.e. <strong style="color: goldenrod">total loss in revenue and gains</strong>) to validate the model. To me, it felt more business intelligence rather than traditional statistics/machine learning model validation. I am uncertain if data scientists at Affirm are just BI with Python skills.</p>
      </li>
    </ol>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents6" id="bodyContents66">Evaluation:</strong>
    <ul>
      <li><strong style="color: blue">Precision vs Recall Tradeoff:</strong>
        <ul>
          <li>
            <p><strong>Recall</strong> is more important where Overlooked Cases (False Negatives) are more costly than False Alarms (False Positive). The focus in these problems is finding the positive cases.</p>
          </li>
          <li>
            <p><strong>Precision</strong> is more important where False Alarms (False Positives) are more costly than Overlooked Cases (False Negatives). The focus in these problems is in weeding out the negative cases.</p>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<h2 id="content7">Regularization</h2>

<ol>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents7" id="bodyContents71">Regularization:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents7" id="bodyContents72">Norms:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents7" id="bodyContents73">AUC:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents7" id="bodyContents74">Linear Algebra:</strong></p>
  </li>
</ol>

<h2 id="content8">Interpretability</h2>

<ol>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents8" id="bodyContents81">Regularization:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents8" id="bodyContents82">Norms:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents8" id="bodyContents83">AUC:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents8" id="bodyContents84">Linear Algebra:</strong></p>
  </li>
</ol>

<h2 id="content9">Decision Trees, Random Forests, XGB, and Gradient Boosting</h2>

<ol>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents9" id="bodyContents91">Regularization:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents9" id="bodyContents92">Norms:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents9" id="bodyContents93">AUC:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents9" id="bodyContents94">Boosting:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents9" id="bodyContents95">Boosting:</strong></p>
    <ul>
      <li><strong>Boosting</strong>: create different hypothesis \(h_i\)s sequentially + make each new hypothesis <strong>decorrelated</strong> with previous hypothesis.
        <ul>
          <li>Assumes that this will be combined/ensembled</li>
          <li>Ensures that each new model/hypothesis will give a different/independent output</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<h2 id="content10"><a href="/work_files/calibration">Uncertainty and Probabilistic Calibration</a></h2>

<ul>
  <li><a href="/work_files/calibration">CALIBRATION (website)</a></li>
</ul>

<ol>
  <li><strong style="color: SteelBlue" class="bodyContents10" id="bodyContents101">Uncertainty:</strong>
    <ul>
      <li><strong style="color: red">Aleatoric vs Epistemic:</strong><br />
  Aleatoric uncertainty and epistemic uncertainty are two types of uncertainty that can arise in statistical modeling and machine learning. Aleatoric uncertainty is a type of uncertainty that arises from randomness or inherent noise in the data. It is inherent to the system being studied and cannot be reduced through additional data or better modeling. On the other hand, epistemic uncertainty is a type of uncertainty that arises from incomplete or imperfect knowledge about the system being studied. It can be reduced through additional data or better modeling.</li>
    </ul>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents10" id="bodyContents102">Model Uncertainty, Softmax, and Dropout:</strong> <br />
 <strong style="color: red">Interpreting Softmax Output Probabilities:</strong><br />
 Softmax outputs only measure <a href="https://en.wikipedia.org/wiki/Uncertainty_quantification#Aleatoric_and_epistemic_uncertainty"><strong>Aleatoric Uncertainty</strong></a>.<br />
 In the same way that in regression, a NN with two outputs, one representing mean and one variance, that parameterise a Gaussian, can capture aleatoric uncertainty, even though the model is deterministic.<br />
 Bayesian NNs (dropout included), aim to capture epistemic (aka model) uncertainty.</p>

    <p><strong style="color: red">Dropout for Measuring Model (epistemic) Uncertainty:</strong><br />
 Dropout can give us principled uncertainty estimates.<br />
 Principled in the sense that the uncertainty estimates basically approximate those of our <a href="/work_files/research/dl/archits/nns#bodyContents13">Gaussian process</a>.</p>

    <p id="lst-p"><strong>Theoretical Motivation:</strong> dropout neural networks are identical to <span style="color: purple">variational inference in Gaussian processes</span>.<br />
 <strong>Interpretations of Dropout:</strong></p>
    <ul>
      <li>Dropout is just a diagonal noise matrix with the diagonal elements set to either 0 or 1.</li>
      <li><a href="http://mlg.eng.cam.ac.uk/yarin/blog_3d801aa532c1ce.html">What My Deep Model Doesn’t Know (Blog! - Yarin Gal)</a><br />
 <br /></li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents10" id="bodyContents103">Calibration in Deep Networks:</strong>
    <ul>
      <li><a href="http://alondaks.com/2017/12/31/the-importance-of-calibrating-your-deep-model/">READ THIS (Blog!)</a></li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents10" id="bodyContents104">Linear Algebra:</strong></li>
</ol>

<h2 id="content11">Extra: Bandit, bootstrapping, and prediction interval estimation, Linear Models in Credit</h2>

<ol>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents11" id="bodyContents111">Bandit:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents11" id="bodyContents112">bootstrapping:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents11" id="bodyContents113">prediction interval estimation:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents11" id="bodyContents114">Linear Models in Credit Analysis:</strong><br />
 <img src="https://cdn.mathpix.com/snip/images/fa_yKNL9BXfeHhGkOvnXhNmgSYR8TF0B-hCfZn-0whc.original.fullsize.png" alt="img" width="40%" />  s</p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents11" id="bodyContents115">Errors vs Residuals:</strong><br />
 The <strong>Error</strong> of an observed value is the deviation of the observed value from the (unobservable) <strong><em>true</em></strong> value of a quantity of interest.</p>

    <p>The <strong>Residual</strong> of an observed value is the difference between the observed value and the <em><strong>estimated</strong></em> value of the quantity of interest.</p>
  </li>
</ol>

<h2 id="content12">Notes from Affirm Blog</h2>

<ol>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents12" id="bodyContents121">Bandit:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents12" id="bodyContents122">bootstrapping:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents12" id="bodyContents123">prediction interval estimation:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents12" id="bodyContents124">Linear Models in Credit Analysis:</strong><br />
 <img src="https://cdn.mathpix.com/snip/images/fa_yKNL9BXfeHhGkOvnXhNmgSYR8TF0B-hCfZn-0whc.original.fullsize.png" alt="img" width="40%" />  s</p>
  </li>
</ol>


      <footer class="site-footer">
    <!--   <span class="site-footer-owner"><a href="http://localhost:8889">Ahmad Badary</a> is maintained by <a href="https://ahmedbadary.github.io/">Ahmad Badary</a>.</span> -->
    
<!--  -->
    <div class="wrapper">
        <div class="footer-col-wrapper">
            <div class="footer-col footer-col-1">
            <span class="site-footer-owner"><a href="http://localhost:8889">Site</a> maintained by <a href="https://ahmedbadary.github.io/">Ahmad Badary</a>.</span>
    <span class="site-footer-credits">
        <p>
            &copy; 2017. All rights reserved.
        </p> 
    </span>
            </div>
            <div class="footer-col footer-col-2">
            <div><p>         </p></div>
            </div>
            <div class="footer-col footer-col-3">
                <ul class="social-media-list">
                    
                      <li>
                        <a href="https://github.com/AhmedBadary">
                          <i class="fa fa-github"></i> GitHub
                        </a>
                      </li>
                    
                    
                      <li>
                        <a href="https://linkedin.com/in/ahmad-badary-656098121/">
                          <i class="fa fa-linkedin"></i> LinkedIn
                        </a>
                      </li>
                    
                    
                      <li>
                        <a href="https://www.facebook.com/ahmed.thabet.94">
                          <i class="fa fa-facebook"></i> Facebook
                        </a>
                      </li>
                    
                </ul>
            </div>
        </div>
    </div>
<!--  -->
</footer>


    </section>

  </body>

<!-- Table of Content Script -->
<script type="text/javascript">
var bodyContents = $(".bodyContents1");
$("<ol>").addClass("TOC1ul").appendTo(".TOC1");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC1ul");
     });
// 
var bodyContents = $(".bodyContents2");
$("<ol>").addClass("TOC2ul").appendTo(".TOC2");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC2ul");
     });
// 
var bodyContents = $(".bodyContents3");
$("<ol>").addClass("TOC3ul").appendTo(".TOC3");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC3ul");
     });
//
var bodyContents = $(".bodyContents4");
$("<ol>").addClass("TOC4ul").appendTo(".TOC4");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC4ul");
     });
//
var bodyContents = $(".bodyContents5");
$("<ol>").addClass("TOC5ul").appendTo(".TOC5");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC5ul");
     });
//
var bodyContents = $(".bodyContents6");
$("<ol>").addClass("TOC6ul").appendTo(".TOC6");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC6ul");
     });
//
var bodyContents = $(".bodyContents7");
$("<ol>").addClass("TOC7ul").appendTo(".TOC7");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC7ul");
     });
//
var bodyContents = $(".bodyContents8");
$("<ol>").addClass("TOC8ul").appendTo(".TOC8");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC8ul");
     });
//
var bodyContents = $(".bodyContents9");
$("<ol>").addClass("TOC9ul").appendTo(".TOC9");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC9ul");
     });

</script>

<!-- VIDEO BUTTONS SCRIPT -->
<script type="text/javascript">
  function iframePopInject(event) {
    var $button = $(event.target);
    // console.log($button.parent().next());
    if ($button.attr('value') == 'show') {
        $button.attr('value', 'hide');
        $figure = $("<div>").addClass("video_container");
        $iframe = $("<iframe>").appendTo($figure);
        $iframe.attr("src", $button.attr("src"));
        // $iframe.attr("frameborder", "0");
        $iframe.attr("allowfullscreen", "true");
        $iframe.css("padding", "4px 6px");
        $button.next().css("display", "block");
        $figure.appendTo($button.next());
        $button.text("Hide Video")
    } else {
        $button.attr('value', 'show');
        $button.next().html("");
        $button.text("Show Video")
    }
}
</script>

<!-- BUTTON TRY -->
<script type="text/javascript">
  function iframePopA(event) {
    event.preventDefault();
    var $a = $(event.target).parent();
    console.log($a);
    if ($a.attr('value') == 'show') {
        $a.attr('value', 'hide');
        $figure = $("<div>");
        $iframe = $("<iframe>").addClass("popup_website_container").appendTo($figure);
        $iframe.attr("src", $a.attr("href"));
        $iframe.attr("frameborder", "1");
        $iframe.attr("allowfullscreen", "true");
        $iframe.css("padding", "4px 6px");
        $a.next().css("display", "block");
        $figure.appendTo($a.next().next());
        // $a.text("Hide Content")
        $('html, body').animate({
            scrollTop: $a.offset().top
        }, 1000);
    } else {
        $a.attr('value', 'show');
        $a.next().next().html("");
        // $a.text("Show Content")
    }

    $a.next().css("display", "inline");
}
</script>


<!-- TEXT BUTTON SCRIPT - INJECT -->
<script type="text/javascript">
  function showTextPopInject(event) {
    var $button = $(event.target);
    var txt = $button.attr("input");
    console.log(txt);
    if ($button.attr('value') == 'show') {
        $button.attr('value', 'hide');
        $p = $("<p>");
        $p.html(txt);
        $button.next().css("display", "block");
        $p.appendTo($button.next());
        $button.text("Hide Content")
    } else {
        $button.attr('value', 'show');
        $button.next().html("");
        $button.text("Show Content")
    }

}
</script>

<!-- TEXT BUTTON SCRIPT - HIDDEN / HIDE / SHOW / HIDE/SHOW -->
<script type="text/javascript">
  function showTextPopHide(event) {
    var $button = $(event.target);
    // var txt = $button.attr("input");
    var txt = $button.text();
    if ($button.attr('value') == 'show') {
        $button.attr('value', 'hide');
        $button.next().removeAttr("hidden");
        $button.text(txt + " - Hide Content");
    } else {
        $button.attr('value', 'show');
        $button.next().attr("hidden", "");
        $button.text(txt.replace(" - Hide Content",""));
    }
}
</script>

<!-- TEXT BUTTON SCRIPT - HIDDEN / HIDE / SHOW / HIDE/SHOW -->
<script type="text/javascript">
  function showText_withParent_PopHide(event) {
    var $button = $(event.target);
    var $parent = $button.parent();
    var txt = $button.text();
    if ($button.attr('value') == 'show') {
        $button.attr('value', 'hide');
        $parent.next().removeAttr("hidden");
        $button.text(txt + " - Hide Content");
    } else {
        $button.attr('value', 'show');
        $parent.next().attr("hidden", "");
        $button.text(txt.replace(" - Hide Content",""));
    }
}
</script>

<!-- Print / Printing / printme -->
<!-- <script type="text/javascript">
i = 0

for (var i = 1; i < 6; i++) {
    var bodyContents = $(".bodyContents" + i);
    $("<p>").addClass("TOC1ul")  .appendTo(".TOC1");
    bodyContents.each(function(index, element) {
        var paragraph = $(element);
        $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC1ul");
         });
} 
</script>
 -->
 
</html>

