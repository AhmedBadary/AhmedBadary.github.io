<!DOCTYPE html>
<html lang="en-us">
  <head>
  <meta charset="UTF-8">
  <title>Ahmad Badary</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <link rel="stylesheet" href="/css/normalize.css">
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="/css/cayman.css">
  <link rel="stylesheet" href="/css/style.css">
  <link rel="shortcut icon" href="/main_files/favicon.ico" />
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="/css/customStyle.css">
  <title> » Ahmad Badary</title>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
</head>

  <body>
    <nav class="main-nav">
    <a href="https://ahmedbadary.github.io/" class="main-nav-logo">
        <img src="/main_files/logo.png">
    </a>
    <ul id="menu-main" class="main-nav-items">
        <li id="menu-item-1859" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-home menu-item-1859">
            <a href="/">Home</a>
        </li>
        <li id="menu-item-2869" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-2869">
            <a href="/work">Work</a>
        </li>
        <li id="menu-item-1892" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1892">
            <a href="/projects">Projects</a>
        </li>
        <li id="menu-item-1858" class="menu-item menu-item-type-post_type menu-item-object-page current_page_parent menu-item-1858">
            <a href="/blog">Blog</a>
        </li>
        <li id="menu-item-1862" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1862">
            <a href="/about">About</a>
        </li>
    </ul>
</nav>


<section class="page-header">
  <h1 class="project-name">The Naive Bayes Classifier</h1>
  <h2 class="project-tagline"></h2>
  <a href="/#" class="btn">Home</a>
  <a href="/work" class="btn">Work-Space</a>
  <a href= /work_files/research/ml.html class="btn">Previous</a>
</section>

<!-- <div>
  <ul class="posts">
    
      <li><span>02 Jan 2014</span> &raquo; <a href="/2014/01/02/introducing-Ahmad/">Introducing Ahmad</a></li>
    
  </ul>
</div> -->


    <section class="main-content">
      
      <div class="TOC">
  <h1 id="table-of-contents">Table of Contents</h1>

  <ul class="TOC1">
    <li><a href="#content1">Introduction and the Naive Bayes Classifier</a></li>
  </ul>
  <p><!-- * [SECOND](#content2)
  {: .TOC2} --></p>
</div>

<hr />
<hr />

<p><a href="http://www.cs.columbia.edu/~mcollins/em.pdf">Full Treatment of Naive Bayes Classification</a><br />
<a href="https://www.cs.helsinki.fi/u/jkivinen/opetus/iml/2013/Bayes.pdf">Bayes Classifier and Bayes Error (paper)</a><br />
<a href="https://stats.stackexchange.com/questions/296014/why-is-the-naive-bayes-classifier-optimal-for-0-1-loss?noredirect=1&amp;lq=1">Bayes Classifier and Bayes Error (question)</a><br />
<a href="https://www.youtube.com/watch?v=1nOb0vwWkAE">Naive Bayes CS188 (+Probabilistic Calibration)</a></p>

<p><button class="showText" value="show" onclick="showTextPopHide(event);">Naive Bayes Mind-Map</button>
<img src="/main_files/misc/naive_bayes_mindmap.png" alt="img" width="100%" hidden="" /></p>

<blockquote>
  <p>A Naive Bayes classifier that figured out that you liked pickles and ice cream would probably naively recommend you a pickle ice cream.</p>
</blockquote>

<h2 id="content1">Introduction and the Naive Bayes Classifier</h2>

<ol>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents10">Naive Bayes:</strong><br />
 <strong>Naive Bayes</strong> is a simple technique for <em><strong>constructing classifiers</strong></em>.</p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents11">Naive Bayes Classifiers:</strong><br />
 <strong>Naive Bayes Classifiers</strong> are a family of simple probabilistic classifiers based on applying <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem"><em>Bayes’ Theorem</em></a> with strong (naive) independence assumptions between the features.</p>

    <p id="lst-p"><strong style="color: red">The Assumptions:</strong></p>
    <ol>
      <li><strong>Naive Independence</strong>: the feature probabilities are indpendenet given a class \(c\).</li>
      <li><strong>Bag-of-Words</strong>: we assume that the position of the words does <em>not</em> matter.<br />
 <br /></li>
    </ol>

    <p id="lst-p"><strong style="color: red">Notes:</strong></p>
    <ul>
      <li>Not a <strong>Bayesian Method</strong>: the name only references the use of Bayes’ theorem in the classifier’s decision rule</li>
      <li>The <strong>Naive Bayes Classifier</strong> is a <em><strong>Bayes Classifier</strong></em> (i.e. minimizes the prob of misclassification)</li>
      <li><strong>As a Parametric Model (analysis)</strong>:<br />
  <button class="showText" value="show" onclick="showTextPopHide(event);">Analysis</button>
        <ul hidden="">
          <li>A Bayes classifier basically picks the label \(y\) that has the maximum probability, given that testing data-point \(x\):<br />
  \(y^{* }=\operatorname{argmax}_ {y} P(y)=\operatorname{argmax}_ {y} \frac{P(x \mid y) P(y)}{P(x)}\)<br />
  If you assume the features of \(x\) are conditionally independent given the label, you get the Naive Bayes classifier.<br />
  So, classification depends a lot on \(P(x \mid y)\). The parametric way to classify would be to decide a model (Gaussian, Bernoulli, etc.) for the features of \(x\), and typically the models are different for different classes \(y\). The parameters here are the parameters of your model (mean and covariance for Gaussian, individual feature probabilities for Bernoulli, etc.) and the training problem becomes a parameter estimation problem.</li>
        </ul>
        <p><br /></p>
      </li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents12">The Probabilistic Model (Naive Bayes Probability/Statistical Model):</strong><br />
 Abstractly, naive Bayes is a <strong>conditional probability model</strong>:<br />
 given a problem instance to be classified, represented by a vector \({\displaystyle \: \mathbf{x} =(x_{1},\dots ,x_{n})}\) representing some \(n\) features (independent variables), it assigns to this instance probabilities
    <p>$${\displaystyle p(C_{k}\mid x_{1},\dots ,x_{n}) = p(C_{k}\mid \mathbf {x})}$$</p>
    <p>for each of the \(k\) possible classes \(C_k\).</p>

    <p>Using <strong>Bayes’ Theorem</strong> we <em>decompose the conditional probability</em> as:</p>
    <p>$${\displaystyle p(C_{k}\mid \mathbf {x} )={\frac {p(C_{k})\ p(\mathbf {x} \mid C_{k})}{p(\mathbf {x} )}}\,}$$</p>

    <p>Notice that the <em><strong>numerator</strong></em> is equivalent to the <em><strong>joint probability distribution</strong></em>:</p>
    <p>$$p\left(C_{k}\right) p\left(\mathbf{x} | C_{k}\right) = p\left(C_{k}, x_{1}, \ldots, x_{n}\right)$$</p>

    <p>Using the <strong>Chain-Rule</strong> for repeated application of the conditional probability, the <em>joint probability</em> model can be rewritten as:</p>
    <p>$$p(C_{k},x_{1},\dots ,x_{n})\, = p(x_{1}\mid x_{2},\dots ,x_{n},C_{k})p(x_{2}\mid x_{3},\dots ,x_{n},C_{k})\dots p(x_{n-1}\mid x_{n},C_{k})p(x_{n}\mid C_{k})p(C_{k})$$</p>

    <p>Using the <strong>Naive Conditional Independence</strong> assumptions:</p>
    <p>$$p\left(x_{i} | x_{i+1}, \ldots, x_{n}, C_{k}\right)=p\left(x_{i} | C_{k}\right)$$</p>
    <p>Thus, we can write the <strong>joint model</strong> as:</p>
    <p>$${\displaystyle {\begin{aligned}p(C_{k}\mid x_{1},\dots ,x_{n})&amp;\varpropto p(C_{k},x_{1},\dots ,x_{n})\\&amp;=p(C_{k})\ p(x_{1}\mid C_{k})\ p(x_{2}\mid C_{k})\ p(x_{3}\mid C_{k})\ \cdots \\&amp;=p(C_{k})\prod _{i=1}^{n}p(x_{i}\mid C_{k})\,,\end{aligned}}}$$</p>

    <p>Finally, the <em><strong>conditional distribution over the class variable \(C\)</strong></em> is:</p>
    <p>$${\displaystyle p(C_{k}\mid x_{1},\dots ,x_{n})={\frac {1}{Z}}p(C_{k})\prod _{i=1}^{n}p(x_{i}\mid C_{k})}$$</p>
    <p>where, \({\displaystyle Z=p(\mathbf {x} )=\sum _{k}p(C_{k})\ p(\mathbf {x} \mid C_{k})}\) is a <strong>constant</strong> scaling factor,<strong>dependent only</strong> on the, <em>known</em>, feature variables \(x_i\)s.<br />
 <br /></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents13">The Classifier:</strong><br />
 We can construct the <strong>classifier</strong> from the <strong>probabilistic model</strong> above.<br />
 The <strong>Naive Bayes Classifier</strong> combines this model with a <strong>decision rule</strong>.</p>

    <p><strong style="color: red">The Decision Rule:</strong><br />
 we commonly use the <a href="https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation"><strong>Maximum A Posteriori (MAP)</strong></a> hypothesis, as the decision rule; i.e. pick the hypothesis that is most probable.</p>

    <p>The Classifier is the <em>function that assigns a class label \(\hat{y} = C_k\)</em> for some \(k\) as follows:</p>
    <p>$${\displaystyle {\hat {y}}={\underset {k\in \{1,\dots ,K\}}{\operatorname {argmax} }}\ p(C_{k})\displaystyle \prod _{i=1}^{n}p(x_{i}\mid C_{k}).}$$</p>

    <p>It, basically, maximizes the probability of the class given an input \(\boldsymbol{x}\).<br />
 <br /></p>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents14">Naive Bayes Estimate VS MAP Estimate:</strong><br />
 <strong>MAP Estimate:</strong>
    <p>$${\displaystyle {\hat {y}_{\text{MAP}}}={\underset {k\in \{1,\dots ,K\}}{\operatorname {argmax} }}\ p(C_{k})\ p(\mathbf {x} \mid C_{k})}$$</p>
    <p><strong>Naive Bayes Estimate:</strong></p>
    <p>$${\displaystyle {\hat {y}_{\text{NB}}}={\underset {k\in \{1,\dots ,K\}}{\operatorname {argmax} }}\ p(C_{k})\displaystyle \prod _{i=1}^{n}p(x_{i}\mid C_{k})}$$</p>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents15">Estimating the Parameters of the Classifier:</strong><br />
 <strong style="color: red">Parameters to be Estimated:</strong>
    <ul>
      <li>The <strong>prior probability of each class</strong>:
        <p>$$p(C_{k})$$</p>
      </li>
      <li>The <strong>conditional probability of each feature (word) given a class</strong>:
        <p>$$p(x_{i}\mid C_{k}) \:\: \forall i \in {1, .., n}$$</p>
      </li>
    </ul>

    <p>We, generally, use <strong>Maximum Likelihood Estimates</strong> for the parameters.</p>

    <p><strong style="color: red">The MLE Estimates for the Parameters:</strong></p>
    <ul>
      <li>\(\hat{P}(C_k) = \dfrac{\text{doc-count}(C=C_k)}{N_\text{doc}}\),<br />
 <br /></li>
      <li>\(\hat{P}(x_i | C_j) = \dfrac{\text{count}(x_i,C_j)}{\sum_{x \in V} \text{count}(x, C_j)}\)<br />
 <br /></li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents16">MLE Derivation of the Parameter Estimates:</strong>
    <ul>
      <li><a href="http://www.cs.cornell.edu/courses/cs5740/2017sp/res/nb-prior.pdf">Derivation</a></li>
      <li><a href="https://math.stackexchange.com/questions/2605546/partial-derivative-of-a-summation">Partial derivative of a summation (stackexchange - helpful hint)</a></li>
    </ul>

    <p>The <strong>Likelihood</strong> of the observed data (TBC)</p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents17">Motivation:</strong><br />
 To estimate the parameters of the “true” MAP estimate, we need a prohibitive number of examples ~ \(\mathcal{O}(\vert x\vert^n \cdot \vert C\vert)\).</p>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents18">Notes:</strong>
    <ul>
      <li>In a naive Bayes classifier we are interested in computing the conditional \(p(y \mid x ; \theta) \propto p(y ; \theta) \prod_{i}^{d} p\left(x_{i} \mid y ; \theta\right)\).<br />
  Is this a parametric or nonparametric model? The model is specified by \(\mathcal{H}=\{p(x, y ; \theta)\}\) where \(\theta\) contains the parameter for the class prior multinomial distribution \(p(y)\) (finite number of parameters), and the class conditional distributions \(p\left(x_{i} \mid y\right)\) for each dimension. The latter can be parametric (such as a multinomial over the vocabulary, or a Gaussian), or nonparametric (such as \(1D\) kernel density estimation). Therefore, naive Bayes can be either parametric or nonparametric, although in practice the former is more common.<br />
  In machine learning we are often interested in a function of the distribution \(T(F)\), for example, the mean. We call \(T\) the statistical functional, viewing \(F\) the distribution itself a function of \(x\). However, we will also abuse the notation and say \(\theta=T(F)\) is a “parameter” even for nonparametric models.</li>
    </ul>
  </li>
</ol>

<hr />

<!-- ## SECOND
{: #content2} -->

<!-- 1. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents2 #bodyContents21}

2. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents2 #bodyContents22}

3. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents2 #bodyContents23}

4. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents2 #bodyContents24}

5. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents2 #bodyContents25}

6. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents2 #bodyContents26}

7. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents2 #bodyContents27}

8. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents2 #bodyContents28} -->


      <footer class="site-footer">
    <!--   <span class="site-footer-owner"><a href="http://localhost:8889">Ahmad Badary</a> is maintained by <a href="https://ahmedbadary.github.io/">Ahmad Badary</a>.</span> -->
    
<!--  -->
    <div class="wrapper">
        <div class="footer-col-wrapper">
            <div class="footer-col footer-col-1">
            <span class="site-footer-owner"><a href="http://localhost:8889">Site</a> maintained by <a href="https://ahmedbadary.github.io/">Ahmad Badary</a>.</span>
    <span class="site-footer-credits">
        <p>
            &copy; 2017. All rights reserved.
        </p> 
    </span>
            </div>
            <div class="footer-col footer-col-2">
            <div><p>         </p></div>
            </div>
            <div class="footer-col footer-col-3">
                <ul class="social-media-list">
                    
                      <li>
                        <a href="https://github.com/AhmedBadary">
                          <i class="fa fa-github"></i> GitHub
                        </a>
                      </li>
                    
                    
                      <li>
                        <a href="https://linkedin.com/in/ahmad-badary-656098121/">
                          <i class="fa fa-linkedin"></i> LinkedIn
                        </a>
                      </li>
                    
                    
                      <li>
                        <a href="https://www.facebook.com/ahmed.thabet.94">
                          <i class="fa fa-facebook"></i> Facebook
                        </a>
                      </li>
                    
                </ul>
            </div>
        </div>
    </div>
<!--  -->
</footer>


    </section>

  </body>

<!-- Table of Content Script -->
<script type="text/javascript">
var bodyContents = $(".bodyContents1");
$("<ol>").addClass("TOC1ul").appendTo(".TOC1");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC1ul");
     });
// 
var bodyContents = $(".bodyContents2");
$("<ol>").addClass("TOC2ul").appendTo(".TOC2");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC2ul");
     });
// 
var bodyContents = $(".bodyContents3");
$("<ol>").addClass("TOC3ul").appendTo(".TOC3");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC3ul");
     });
//
var bodyContents = $(".bodyContents4");
$("<ol>").addClass("TOC4ul").appendTo(".TOC4");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC4ul");
     });
//
var bodyContents = $(".bodyContents5");
$("<ol>").addClass("TOC5ul").appendTo(".TOC5");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC5ul");
     });
//
var bodyContents = $(".bodyContents6");
$("<ol>").addClass("TOC6ul").appendTo(".TOC6");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC6ul");
     });
//
var bodyContents = $(".bodyContents7");
$("<ol>").addClass("TOC7ul").appendTo(".TOC7");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC7ul");
     });
//
var bodyContents = $(".bodyContents8");
$("<ol>").addClass("TOC8ul").appendTo(".TOC8");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC8ul");
     });
//
var bodyContents = $(".bodyContents9");
$("<ol>").addClass("TOC9ul").appendTo(".TOC9");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC9ul");
     });

</script>

<!-- VIDEO BUTTONS SCRIPT -->
<script type="text/javascript">
  function iframePopInject(event) {
    var $button = $(event.target);
    // console.log($button.parent().next());
    if ($button.attr('value') == 'show') {
        $button.attr('value', 'hide');
        $figure = $("<div>").addClass("video_container");
        $iframe = $("<iframe>").appendTo($figure);
        $iframe.attr("src", $button.attr("src"));
        // $iframe.attr("frameborder", "0");
        $iframe.attr("allowfullscreen", "true");
        $iframe.css("padding", "4px 6px");
        $button.next().css("display", "block");
        $figure.appendTo($button.next());
        $button.text("Hide Video")
    } else {
        $button.attr('value', 'show');
        $button.next().html("");
        $button.text("Show Video")
    }
}
</script>

<!-- BUTTON TRY -->
<script type="text/javascript">
  function iframePopA(event) {
    event.preventDefault();
    var $a = $(event.target).parent();
    console.log($a);
    if ($a.attr('value') == 'show') {
        $a.attr('value', 'hide');
        $figure = $("<div>");
        $iframe = $("<iframe>").addClass("popup_website_container").appendTo($figure);
        $iframe.attr("src", $a.attr("href"));
        $iframe.attr("frameborder", "1");
        $iframe.attr("allowfullscreen", "true");
        $iframe.css("padding", "4px 6px");
        $a.next().css("display", "block");
        $figure.appendTo($a.next().next());
        // $a.text("Hide Content")
        $('html, body').animate({
            scrollTop: $a.offset().top
        }, 1000);
    } else {
        $a.attr('value', 'show');
        $a.next().next().html("");
        // $a.text("Show Content")
    }

    $a.next().css("display", "inline");
}
</script>


<!-- TEXT BUTTON SCRIPT - INJECT -->
<script type="text/javascript">
  function showTextPopInject(event) {
    var $button = $(event.target);
    var txt = $button.attr("input");
    console.log(txt);
    if ($button.attr('value') == 'show') {
        $button.attr('value', 'hide');
        $p = $("<p>");
        $p.html(txt);
        $button.next().css("display", "block");
        $p.appendTo($button.next());
        $button.text("Hide Content")
    } else {
        $button.attr('value', 'show');
        $button.next().html("");
        $button.text("Show Content")
    }

}
</script>

<!-- TEXT BUTTON SCRIPT - HIDDEN / HIDE / SHOW / HIDE/SHOW -->
<script type="text/javascript">
  function showTextPopHide(event) {
    var $button = $(event.target);
    // var txt = $button.attr("input");
    var txt = $button.text();
    if ($button.attr('value') == 'show') {
        $button.attr('value', 'hide');
        $button.next().removeAttr("hidden");
        $button.text(txt + " - Hide Content");
    } else {
        $button.attr('value', 'show');
        $button.next().attr("hidden", "");
        $button.text(txt.replace(" - Hide Content",""));
    }
}
</script>

<!-- TEXT BUTTON SCRIPT - HIDDEN / HIDE / SHOW / HIDE/SHOW -->
<script type="text/javascript">
  function showText_withParent_PopHide(event) {
    var $button = $(event.target);
    var $parent = $button.parent();
    var txt = $button.text();
    if ($button.attr('value') == 'show') {
        $button.attr('value', 'hide');
        $parent.next().removeAttr("hidden");
        $button.text(txt + " - Hide Content");
    } else {
        $button.attr('value', 'show');
        $parent.next().attr("hidden", "");
        $button.text(txt.replace(" - Hide Content",""));
    }
}
</script>

<!-- Print / Printing / printme -->
<!-- <script type="text/javascript">
i = 0

for (var i = 1; i < 6; i++) {
    var bodyContents = $(".bodyContents" + i);
    $("<p>").addClass("TOC1ul")  .appendTo(".TOC1");
    bodyContents.each(function(index, element) {
        var paragraph = $(element);
        $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC1ul");
         });
} 
</script>
 -->
 
</html>

