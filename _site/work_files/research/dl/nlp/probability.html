<!DOCTYPE html>
<html lang="en-us">
  <head>
  <meta charset="UTF-8">
  <title>Ahmad Badary</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <link rel="stylesheet" href="/css/normalize.css">
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="/css/cayman.css">
  <link rel="stylesheet" href="/css/style.css">
  <link rel="shortcut icon" href="/main_files/favicon.ico" />
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="/css/customStyle.css">
  <title> » Ahmad Badary</title>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
</head>

  <body>
    <nav class="main-nav">
    <a href="https://ahmedbadary.github.io/" class="main-nav-logo">
        <img src="/main_files/logo.png">
    </a>
    <ul id="menu-main" class="main-nav-items">
        <li id="menu-item-1859" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-home menu-item-1859">
            <a href="/">Home</a>
        </li>
        <li id="menu-item-2869" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-2869">
            <a href="/work">Work</a>
        </li>
        <li id="menu-item-1892" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1892">
            <a href="/projects">Projects</a>
        </li>
        <li id="menu-item-1858" class="menu-item menu-item-type-post_type menu-item-object-page current_page_parent menu-item-1858">
            <a href="/blog">Blog</a>
        </li>
        <li id="menu-item-1862" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1862">
            <a href="/about">About</a>
        </li>
    </ul>
</nav>


<section class="page-header">
  <h1 class="project-name">Probability Theory <br /> Mathematics of Deep Learning</h1>
  <h2 class="project-tagline"></h2>
  <a href="/#" class="btn">Home</a>
  <a href="/work" class="btn">Work-Space</a>
  <a href= /work_files/research/dl/nlp.html class="btn">Previous</a>
</section>

<!-- <div>
  <ul class="posts">
    
      <li><span>02 Jan 2014</span> &raquo; <a href="/2014/01/02/introducing-Ahmad/">Introducing Ahmad</a></li>
    
  </ul>
</div> -->


    <section class="main-content">
      
      <div class="TOC">
  <h1 id="table-of-contents">Table of Contents</h1>

  <ul class="TOC1">
    <li><a href="#content1">Motivation</a></li>
  </ul>
  <ul class="TOC2">
    <li><a href="#content2">Basics</a></li>
  </ul>
  <!--   * [THIRD](#content3)
  {: .TOC3} -->
  <ul class="TOC9">
    <li><a href="#content9">Discrete Distributions</a></li>
  </ul>
  <ul class="TOC10">
    <li><a href="#content10">Notes, Tips, and Tricks</a></li>
  </ul>
</div>

<hr />
<hr />

<h2 id="content1">Motivation</h2>

<ol>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents11">Uncertainty in General Systems and the need for a Probabilistic Framework:</strong></dt>
      <dd>
        <ol>
          <li><strong>Inherent stochasticity in the system being modeled:</strong><br />
 Take Quantum Mechanics, most interpretations of quantum mechanics describe the dynamics of sub-atomic particles as being probabilistic.</li>
          <li><strong>Incomplete observability</strong>:<br />
 Deterministic systems can appear stochastic even when we cannot observe all the variables that drive the behavior of the system.
            <blockquote>
              <p>i.e. Point-of-View determinism (Monty-Hall)</p>
            </blockquote>
          </li>
          <li><strong>Incomplete modeling</strong>:<br />
 Building a system that makes strong assumptions about the problem and discards (observed) information result in uncertainty in the predictions.</li>
        </ol>
      </dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents12">Bayesian Probabilities and Frequentist Probabilities:</strong></dt>
      <dd><strong>Frequentist Probabilities</strong> describe the predicted number of times that a <strong>repeatable</strong> process will result in a given output in an absolute scale.<br />
<strong>Bayesian Probabilities</strong> describe the <em>degree of belief</em> that a certain <strong>non-repeatable</strong> event is going to result in a given output, in an absolute scale.</dd>
      <dd>We assume that <strong>Bayesian Probabilities</strong> behaves in exactly the same way as <strong>Frequentist Probabilities</strong>.<br />
This assumption is derived from a set of <em>“common sense”</em> arguments that end in the logical conclusion that both approaches to probabilities must behave the same way - <a href="https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/ramseyfp/ramsess.pdf">Truth and probability (Ramsey 1926)</a>.</dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents13">Probability as an extension of Logic:</strong></dt>
      <dd>“Probability can be seen as the extension of logic to deal with uncertainty. Logic provides a set of formal rules for determining what propositions are implied to be true or false given the assumption that some other set of propositions is true or false. Probability theory provides a set of formal rules for determining the likelihood of a proposition being true given the likelihood of other propositions.” - deeplearningbook p.54</dd>
    </dl>
  </li>
</ol>

<hr />

<h2 id="content2">Basics</h2>

<ol>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents20">Elements of Probability:</strong></dt>
      <dd>
        <ul>
          <li><strong>Sample Space <script type="math/tex">\Omega</script></strong>: The set of all the outcomes of a stochastic experiment; where each <em>outcome</em> is a complete description of the state of the real world at the end of the experiment.</li>
          <li><strong>Event Space <script type="math/tex">{\mathcal {F}}</script></strong>: A set of <em>events</em>; where each event <script type="math/tex">A \in \mathcal{F}</script> is a subset of the sample space <script type="math/tex">\Omega</script> - it is a collection of possible outcomes of an experiment.</li>
          <li><strong>Probability Measure <script type="math/tex">\operatorname {P}</script></strong>: A function <script type="math/tex">\operatorname {P}: \mathcal{F} \rightarrow \mathbb{R}</script> that satisfies the following properties:
            <ul>
              <li><script type="math/tex">\operatorname {P}(A) \geq 0, \: \forall A \in \mathcal{f}</script>,</li>
              <li><script type="math/tex">\operatorname {P}(\Omega) = 1</script>,</li>
              <li><script type="math/tex">{\displaystyle \operatorname {P}(\bigcup_i A_i) = \sum_i \operatorname {P}(A_i) }</script>, where <script type="math/tex">A_1, A_2, ...</script> are <a href="#bodyContents102"><em>disjoint</em> events</a></li>
            </ul>
          </li>
        </ul>
      </dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents21">Random Variables:</strong></dt>
      <dd>A <strong>Random Variable</strong> is a variable that can take on different values randomly.<br />
Formally, a random variable <script type="math/tex">X</script> is a <em>function</em> that maps outcomes to numerical quantities (labels), typically real numbers:</dd>
      <dd>
        <script type="math/tex; mode=display">{\displaystyle X\colon \Omega \to \mathbb{R}}</script>
      </dd>
      <dd>
        <ul>
          <li><strong>Types</strong>:
            <ul>
              <li><em><strong>Discrete</strong></em>: is a variable that has a finite or countably infinite number of states</li>
              <li><em><strong>Continuous</strong></em>: is a variable that is a real value</li>
            </ul>
          </li>
        </ul>
      </dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents22">Probability Distributions:</strong></dt>
      <dd>A <strong>Probability Distribution</strong> is a function that describes the likelihood that a random variable (or a set of r.v.) will take on each of its possible states.<br />
Probability Distributions are defined in terms of the <strong>Sample Space</strong>.</dd>
      <dd>
        <ul>
          <li><strong>Classes</strong>:
            <ul>
              <li><em><strong>Discrete Probability Distribution:</strong></em> is encoded by a discrete list of the probabilities of the outcomes, known as a <strong>Probability Mass Function (PMF)</strong>.</li>
              <li><em><strong>Continuous Probability Distribution:</strong></em> is described by a <strong>Probability Density Function (PDF)</strong>.</li>
            </ul>
          </li>
        </ul>
      </dd>
      <dd>
        <ul>
          <li><strong>Types</strong>:
            <ul>
              <li><em><strong>Univariate Distributions:</strong></em> are those whose sample space is <script type="math/tex">\mathbb{R}</script>.<br />
  They give the probabilities of a single random variable taking on various alternative values</li>
              <li><em><strong>Multivariate Distributions</strong></em> (also known as <em><strong>Joint Probability distributions</strong></em>):  are those whose sample space is a vector space. <br />
  They give the probabilities of a random vector taking on various combinations of values.</li>
            </ul>
          </li>
        </ul>
      </dd>
      <dd>A <strong>Cumulative Distribution Function (CDF)</strong>: is a general functional form to describe a probability distribution.
        <blockquote>
          <p>Because a probability distribution P on the real line is determined by the probability of a scalar random variable X being in a half-open interval (−∞, x], the probability distribution is completely characterized by its cumulative distribution function (i.e. one can calculate the probability of any event in the event space):</p>
        </blockquote>
      </dd>
      <dd>
        <script type="math/tex; mode=display">{\displaystyle F(x)=\operatorname {P} [X\leq x]\qquad {\text{ for all }}x\in \mathbb {R} .}</script>
      </dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents23">Probability Mass Function:</strong></dt>
      <dd>A <strong>Probability Mass Function (PMF)</strong> is a function (probability distribution) that gives the probability that a discrete random variable is exactly equal to some value.</dd>
      <dd><strong>Mathematical Definition</strong>:<br />
Suppose that <script type="math/tex">X: S \rightarrow A, \:\:\: (A {\displaystyle \subseteq }  R)</script> is a discrete random variable defined on a sample space <script type="math/tex">S</script>. Then the probability mass function <script type="math/tex">f_X: A \rightarrow [0, 1]</script> for <script type="math/tex">X</script> is defined as</dd>
      <dd>
        <script type="math/tex; mode=display">f_{X}(x)=\Pr(X=x)=\Pr(\{s\in S:X(s)=x\})</script>
      </dd>
      <dd>The total probability for all hypothetical outcomes <script type="math/tex">x</script> is always conserved:</dd>
      <dd>
        <script type="math/tex; mode=display">\sum _{x\in A}f_{X}(x)=1</script>
      </dd>
      <dd><strong>Joint Probability Distribution</strong> is a PMF over many variables, denoted <script type="math/tex">P(\mathrm{x} = x, \mathrm{y} = y)</script> or <script type="math/tex">P(x, y)</script>.</dd>
      <dd>A <strong>PMF</strong> must satisfy these properties:
        <ul>
          <li>The domain of <script type="math/tex">P</script> must be the set of all possible states of <script type="math/tex">\mathrm{x}</script>.</li>
          <li><script type="math/tex">\forall x \in \mathrm{x}, \: 0 \leq P(x) \leq 1</script>. Impossible events has probability <script type="math/tex">0</script>. Guaranteed events have probability <script type="math/tex">1</script>.</li>
          <li><script type="math/tex">\sum_{x \in \mathrm{x}} P(x) = 1</script>, i.e. the PMF must be normalized.</li>
        </ul>
      </dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents24">Probability Density Function:</strong></dt>
      <dd>A <strong>Probability Density Function (PDF)</strong> is a function (probability distribution) whose value at any given sample (or point) in the sample space can be interpreted as providing a relative likelihood that the value of the random variable would equal that sample.</dd>
      <dd>The <strong>PDF</strong> is defined as the <em>derivative</em> of the <strong>CDF</strong>:</dd>
      <dd>
        <script type="math/tex; mode=display">f_{X}(x) = \dfrac{dF_{X}(x)}{dx}</script>
      </dd>
      <dd>A Probability Density Function <script type="math/tex">p(x)</script> does not give the probability of a specific state directly; instead the probability of landing inside an infinitesimal region with volume <script type="math/tex">\delta x</script> is given by <script type="math/tex">p(x)\delta x</script>.<br />
     We can integrate the density function to find the actual probability mass of a set of points. Specifically, the probability that <script type="math/tex">x</script> lies in some set <script type="math/tex">S</script> is given by the integral of <script type="math/tex">p(x)</script> over that set.
        <blockquote>
          <p>In the <strong>Univariate</strong> example, the probability that <script type="math/tex">x</script> lies in the interval <script type="math/tex">[a, b]</script> is given by <script type="math/tex">\int_{[a, b]} p(x)dx</script></p>
        </blockquote>
      </dd>
      <dd>A <strong>PDF</strong> must satisfy these properties:
        <ul>
          <li>The domain of <script type="math/tex">P</script> must be the set of all possible states of <script type="math/tex">x</script>.</li>
          <li><script type="math/tex">\forall x \in \mathrm{x}, \: 0 \leq P(x) \leq 1</script>. Impossible events has probability <script type="math/tex">0</script>. Guaranteed events have probability <script type="math/tex">1</script>.</li>
          <li><script type="math/tex">\int p(x)dx = 1</script>, i.e. the integral of the PDF must be normalized.</li>
        </ul>
      </dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents244">Cumulative Distribution Function:</strong></dt>
      <dd>A <strong>Cumulative Distribution Function (CDF)</strong> is a function (probability distribution) of a real-valued random variable <script type="math/tex">X</script>, or just distribution function of <script type="math/tex">X</script>, evaluated at <script type="math/tex">x</script>, is the probability that <script type="math/tex">X</script> will take a value less than or equal to <script type="math/tex">x</script>.</dd>
      <dd>
        <script type="math/tex; mode=display">F_{X}(x)=\operatorname {P} (X\leq x)</script>
      </dd>
      <dd>The probability that <script type="math/tex">X</script> lies in the semi-closed interval <script type="math/tex">(a, b]</script>, where <script type="math/tex">% <![CDATA[
a  <  b %]]></script>, is therefore</dd>
      <dd>
        <script type="math/tex; mode=display">% <![CDATA[
{\displaystyle \operatorname {P} (a<X\leq b)=F_{X}(b)-F_{X}(a).} %]]></script>
      </dd>
      <dd><em><strong>Properties</strong></em>:
        <ul>
          <li><script type="math/tex">0 \leq F(x) \leq 1</script>,</li>
          <li><script type="math/tex">\lim_{x \rightarrow -\infty} F(x) = 0</script>,</li>
          <li><script type="math/tex">\lim_{x \rightarrow \infty} F(x) = 1</script>,</li>
          <li><script type="math/tex">x \leq y \implies F(x) \leq F(y)</script>.</li>
        </ul>
      </dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents25">Marginal Probability:</strong></dt>
      <dd>The <strong>Marginal Distribution</strong> of a subset of a collection of random variables is the probability distribution of the variables contained in the subset.</dd>
      <dd><strong>Two-variable Case</strong>:<br />
Given two random variables <script type="math/tex">X</script> and <script type="math/tex">Y</script> whose joint distribution is known, the marginal distribution of <script type="math/tex">X</script> is simply the probability distribution of <script type="math/tex">X</script> averaging over information about <script type="math/tex">Y</script>.</dd>
      <dd>
        <ul>
          <li><strong>Discrete</strong>:</li>
        </ul>
      </dd>
      <dd>
        <script type="math/tex; mode=display">{\displaystyle \Pr(X=x)=\sum _{y}\Pr(X=x,Y=y)=\sum _{y}\Pr(X=x\mid Y=y)\Pr(Y=y)}</script>
      </dd>
      <dd>
        <ul>
          <li><strong>Continuous</strong>:</li>
        </ul>
      </dd>
      <dd>
        <script type="math/tex; mode=display">{\displaystyle p_{X}(x)=\int _{y}p_{X,Y}(x,y)\,\mathrm {d} y=\int _{y}p_{X\mid Y}(x\mid y)\,p_{Y}(y)\,\mathrm {d} y}</script>
      </dd>
      <dd>
        <ul>
          <li><em><strong>Marginal Probability as Expectation</strong></em>:</li>
        </ul>
      </dd>
      <dd>
        <script type="math/tex; mode=display">{\displaystyle p_{X}(x)=\int _{y}p_{X\mid Y}(x\mid y)\,p_{Y}(y)\,\mathrm {d} y=\mathbb {E} _{Y}[p_{X\mid Y}(x\mid y)]}</script>
      </dd>
      <dd><button class="showText" value="show" onclick="showTextPopHide(event);">Intuitive Explanation</button>
 <img src="/main_files/math/prob/1.png" alt="img" width="100%" hidden="" /></dd>
      <dd>
        <blockquote>
          <p><strong>Marginalization:</strong> the process of forming the marginal distribution with respect to one variable by summing out the other variable</p>
        </blockquote>
      </dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents26">Conditional Probability:</strong></dt>
      <dd><strong>Conditional Probability</strong> is a measure of the probability of an event given that another event has occurred.<br />
Conditional Probability is only defined when <script type="math/tex">P(x) > 0</script> - We cannot compute the conditional probability conditioned on an event that never happens.</dd>
      <dd><strong>Definition</strong>:</dd>
      <dd>
        <script type="math/tex; mode=display">P(A|B)={\frac {P(A\cap B)}{P(B)}} = {\frac {P(A, B)}{P(B)}}</script>
      </dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents27">The Chain Rule of Conditional Probability:</strong></dt>
      <dd>Any joint probability distribution over many random variables may be decomposed into conditional distributions over only one variable.<br />
The chain rule permits the calculation of any member of the joint distribution of a set of random variables using only conditional probabilities:</dd>
      <dd>
        <script type="math/tex; mode=display">\mathrm {P} \left(\bigcap _{k=1}^{n}A_{k}\right)=\prod _{k=1}^{n}\mathrm {P} \left(A_{k}\,{\Bigg |}\,\bigcap _{j=1}^{k-1}A_{j}\right)</script>
      </dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents28">Independence and Conditional Independence:</strong></dt>
      <dd>Two random variables <script type="math/tex">x</script> and <script type="math/tex">y</script> are <strong>independent</strong> if their probability distribution can be expressed as a product of two factors, one involving only <script type="math/tex">x</script> and one involving only <script type="math/tex">y</script>:</dd>
      <dd>
        <script type="math/tex; mode=display">\mathrm{P}(A \cap B) = \mathrm{P}(A)\mathrm{P}(B)</script>
      </dd>
      <dd>Two random variables <script type="math/tex">A</script> and <script type="math/tex">B</script> are conditionally independent given a random variable <script type="math/tex">Y</script> if the conditional probability distribution over <script type="math/tex">A</script> and <script type="math/tex">B</script> factorizes in this way for every value of <script type="math/tex">Y</script>:</dd>
      <dd>
        <script type="math/tex; mode=display">\Pr(A\cap B\mid Y)=\Pr(A\mid Y)\Pr(B\mid Y)</script>
      </dd>
      <dd>or equivalently,</dd>
      <dd>
        <script type="math/tex; mode=display">\Pr(A\mid B\cap Y)=\Pr(A\mid Y)</script>
      </dd>
      <dd>
        <blockquote>
          <p>In other words, <script type="math/tex">A</script> and <script type="math/tex">B</script> are conditionally independent given <script type="math/tex">Y</script> if and only if, given knowledge that <script type="math/tex">Y</script> occurs, knowledge of whether <script type="math/tex">A</script> occurs provides no information on the likelihood of <script type="math/tex">B</script> occurring, and knowledge of whether <script type="math/tex">B</script> occurs provides no information on the likelihood of <script type="math/tex">A</script> occurring.</p>
        </blockquote>
      </dd>
      <dd><strong>Notation:</strong>
        <ul>
          <li><em><strong><script type="math/tex">A</script> is Independent from <script type="math/tex">B</script></strong></em>:  <script type="math/tex">A{\perp}B</script></li>
          <li><em><strong><script type="math/tex">A</script> and <script type="math/tex">B</script> are conditionally Independent given <script type="math/tex">Y</script></strong></em>:  <script type="math/tex">A{\perp}B \:\vert Y</script></li>
        </ul>
      </dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents29">Expectation:</strong></dt>
      <dd>The <strong>expectation</strong>, or <strong>expected value</strong>, of some function <script type="math/tex">f(x)</script> with respect to a probability distribution <script type="math/tex">P(x)</script> is the <em>“theoretical”</em> average, or mean value, that <script type="math/tex">f</script> takes on when <script type="math/tex">x</script> is drawn from <script type="math/tex">P</script>.
        <blockquote>
          <p>The Expectation of a R.V. is a weighted average of the values <script type="math/tex">x</script> that the R.V. can take – <script type="math/tex">\operatorname {E}[X] = \sum_{x \in X} x \cdot p(x)</script></p>
        </blockquote>
      </dd>
      <dd>
        <ul>
          <li><strong>Discrete case</strong>:</li>
        </ul>
      </dd>
      <dd>
        <script type="math/tex; mode=display">{\displaystyle \operatorname {E}_{x \sim P} [f(X)]=f(x_{1})p(x_{1})+f(x_{2})p(x_{2})+\cdots +f(x_{k})p(x_{k})} = \sum_x P(x)f(x)</script>
      </dd>
      <dd>
        <ul>
          <li><strong>Continuous case</strong>:</li>
        </ul>
      </dd>
      <dd>
        <script type="math/tex; mode=display">{\displaystyle \operatorname {E}_{x \sim P} [f(X)] = \int p(x)f(x)dx}</script>
      </dd>
      <dd><strong>Linearity of Expectation:</strong></dd>
      <dd>
        <script type="math/tex; mode=display">% <![CDATA[
{\displaystyle {\begin{aligned}\operatorname {E} [X+Y]&=\operatorname {E} [X]+\operatorname {E} [Y],\\[6pt]\operatorname {E} [aX]&=a\operatorname {E} [X],\end{aligned}}} %]]></script>
      </dd>
      <dd><strong>Independence:</strong> <br />
If <script type="math/tex">X</script> and <script type="math/tex">Y</script> are independent <script type="math/tex">\implies \operatorname {E} [X+Y] = \operatorname {E} [X] \operatorname {E} [X]</script></dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents210">Variance:</strong></dt>
      <dd><strong>Variance</strong> is the expectation of the squared deviation of a random variable from its mean.<br />
It gives a measure of how much the values of a function of a random variable <script type="math/tex">x</script> vary as we sample different values of <script type="math/tex">x</script> from its probability distribution:</dd>
      <dd>
        <script type="math/tex; mode=display">\operatorname {Var} (f(x))=\operatorname {E} \left[(f(x)-\mu )^{2}\right] = \sum_{x \in X} (x - \mu)^2 \cdot p(x)</script>
      </dd>
      <dd><strong>Variance expanded</strong>:</dd>
      <dd>
        <script type="math/tex; mode=display">% <![CDATA[
{\displaystyle {\begin{aligned}\operatorname {Var} (X)&=\operatorname {E} \left[(X-\operatorname {E} [X])^{2}\right]\\&=\operatorname {E} \left[X^{2}-2X\operatorname {E} [X]+\operatorname {E} [X]^{2}\right]\\&=\operatorname {E} \left[X^{2}\right]-2\operatorname {E} [X]\operatorname {E} [X]+\operatorname {E} [X]^{2}\\&=\operatorname {E} \left[X^{2}\right]-\operatorname {E} [X]^{2}\end{aligned}}} %]]></script>
      </dd>
      <dd><strong>Variance as Covariance</strong>: 
    Variance can be expressed as the covariance of a random variable with itself:</dd>
      <dd>
        <script type="math/tex; mode=display">\operatorname {Var} (X)=\operatorname {Cov} (X,X)</script>
      </dd>
      <dd><strong>Properties:</strong>
        <ul>
          <li><script type="math/tex">\operatorname {Var} [a] = 0, \forall a \in \mathbb{R}</script> (constant <script type="math/tex">a</script>)</li>
          <li><script type="math/tex">\operatorname {Var} [af(X)] = a^2 \operatorname {Var} [f(X)]</script> (constant <script type="math/tex">a</script>)</li>
          <li>
            <script type="math/tex; mode=display">\operatorname {Var} [X + Y] = a^2 \operatorname {Var} [X] + \operatorname {Var} [Y] + 2 \operatorname {Cov} [X, Y]</script>
          </li>
        </ul>
      </dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents211">Standard Deviation:</strong></dt>
      <dd>The <strong>Standard Deviation</strong> is a measure that is used to quantify the amount of variation or dispersion of a set of data values.<br />
It is defined as the square root of the variance:</dd>
      <dd>
        <script type="math/tex; mode=display">% <![CDATA[
{\displaystyle {\begin{aligned}\sigma &={\sqrt {\operatorname {E} [(X-\mu )^{2}]}}\\&={\sqrt {\operatorname {E} [X^{2}]+\operatorname {E} [-2\mu X]+\operatorname {E} [\mu ^{2}]}}\\&={\sqrt {\operatorname {E} [X^{2}]-2\mu \operatorname {E} [X]+\mu ^{2}}}\\&={\sqrt {\operatorname {E} [X^{2}]-2\mu ^{2}+\mu ^{2}}}\\&={\sqrt {\operatorname {E} [X^{2}]-\mu ^{2}}}\\&={\sqrt {\operatorname {E} [X^{2}]-(\operatorname {E} [X])^{2}}}\end{aligned}}} %]]></script>
      </dd>
      <dd><strong>Properties:</strong>
        <ul>
          <li>68% of the data-points lie within <script type="math/tex">1 \cdot \sigma</script>s from the mean</li>
          <li>95% of the data-points lie within <script type="math/tex">2 \cdot \sigma</script>s from the mean</li>
          <li>99% of the data-points lie within <script type="math/tex">3 \cdot \sigma</script>s from the mean</li>
        </ul>
      </dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents212">Covariance:</strong></dt>
      <dd><strong>Covariance</strong> is a measure of the joint variability of two random variables.<br />
It gives some sense of how much two values are linearly related to each other, as well as the scale of these variables:</dd>
      <dd>
        <script type="math/tex; mode=display">\operatorname {cov} (X,Y)=\operatorname {E} { {\big[ }(X-\operatorname {E} [X])(Y-\operatorname {E} [Y]){ \big] } }</script>
      </dd>
      <dd><strong>Covariance expanded:</strong></dd>
      <dd>
        <script type="math/tex; mode=display">% <![CDATA[
{\displaystyle {\begin{aligned}\operatorname {cov} (X,Y)&=\operatorname {E} \left[\left(X-\operatorname {E} \left[X\right]\right)\left(Y-\operatorname {E} \left[Y\right]\right)\right]\\&=\operatorname {E} \left[XY-X\operatorname {E} \left[Y\right]-\operatorname {E} \left[X\right]Y+\operatorname {E} \left[X\right]\operatorname {E} \left[Y\right]\right]\\&=\operatorname {E} \left[XY\right]-\operatorname {E} \left[X\right]\operatorname {E} \left[Y\right]-\operatorname {E} \left[X\right]\operatorname {E} \left[Y\right]+\operatorname {E} \left[X\right]\operatorname {E} \left[Y\right]\\&=\operatorname {E} \left[XY\right]-\operatorname {E} \left[X\right]\operatorname {E} \left[Y\right].\end{aligned}}} %]]></script>
      </dd>
      <dd>
        <blockquote>
          <p>when <script type="math/tex">{\displaystyle \operatorname {E} [XY]\approx \operatorname {E} [X]\operatorname {E} [Y]}</script>, this last equation is prone to catastrophic cancellation when computed with floating point arithmetic and thus should be avoided in computer programs when the data has not been centered before.</p>
        </blockquote>
      </dd>
      <dd><strong>Covariance of Random Vectors</strong>:</dd>
      <dd>
        <script type="math/tex; mode=display">% <![CDATA[
{\begin{aligned}\operatorname {cov} (\mathbf {X} ,\mathbf {Y} )&=\operatorname {E} \left[(\mathbf {X} -\operatorname {E} [\mathbf {X} ])(\mathbf {Y} -\operatorname {E} [\mathbf {Y} ])^{\mathrm {T} }\right]\\&=\operatorname {E} \left[\mathbf {X} \mathbf {Y} ^{\mathrm {T} }\right]-\operatorname {E} [\mathbf {X} ]\operatorname {E} [\mathbf {Y} ]^{\mathrm {T} },\end{aligned}} %]]></script>
      </dd>
      <dd><strong>The Covariance Matrix</strong> of a random vector <script type="math/tex">x \in \mathbb{R}^n</script> is an <script type="math/tex">n \times n</script> matrix, such that:</dd>
      <dd>
        <script type="math/tex; mode=display">\operatorname {cov} (X)_{i,j} = \operatorname {cov}(x_i, x_j) \\
\operatorname {cov}(x_i, x_j) = \operatorname {Var} (x_i)</script>
      </dd>
      <dd><strong>Interpretations</strong>:
        <ul>
          <li>High absolute values of the covariance mean that the values change very much and are both far from their respective means at the same time.</li>
          <li><strong>The sign of the covariance</strong>: <br />
  The sign of the covariance shows the tendency in the linear relationship between the variables:
            <ul>
              <li><em><strong>Positive</strong></em>:<br />
  the variables tend to show similar behavior</li>
              <li><em><strong>Negative</strong></em>:<br />
  the variables tend to show opposite behavior</li>
              <li><strong>Reason</strong>:<br />
  If the greater values of one variable mainly correspond with the greater values of the other variable, and the same holds for the lesser values, (i.e., the variables tend to show similar behavior), the covariance is positive. In the opposite case, when the greater values of one variable mainly correspond to the lesser values of the other, (i.e., the variables tend to show opposite behavior), the covariance is negative.</li>
            </ul>
          </li>
        </ul>
      </dd>
      <dd><strong>Covariance and Independence:</strong>
        <ul>
          <li>Independence <script type="math/tex">\Rightarrow</script> Zero Covariance</li>
          <li>Zero Covariance <script type="math/tex">\nRightarrow</script> Independence</li>
        </ul>
      </dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents213">Mixtures of Distributions:</strong></dt>
      <dd>It is also common to define probability distributions by combining other simpler probability distributions. One common way of combining distributions is to construct a <strong>mixture distribution</strong>.</dd>
      <dd>A <strong>Mixture Distribution</strong> is the probability distribution of a random variable that is derived from a collection of other random variables as follows: first, a random variable is selected by chance from the collection according to given probabilities of selection, and then the value of the selected random variable is realized.<br />
On each trial, the choice of which component distribution should generate the sample is determined by sampling a component identity from a multinoulli distribution:</dd>
      <dd>
        <script type="math/tex; mode=display">P(x) = \sum_i P(x=i)P(x \vert c=i)</script>
      </dd>
      <dd>where <script type="math/tex">P(c)</script> is the multinoulli distribution over component identities.</dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents214">Bayes’ Rule:</strong></dt>
      <dd><strong>Bayes’ Rule</strong> describes the probability of an event, based on prior knowledge of conditions that might be related to the event.</dd>
      <dd>
        <script type="math/tex; mode=display">{\displaystyle P(A\mid B)={\frac {P(B\mid A)\,P(A)}{P(B)}}}</script>
      </dd>
      <dd>where,</dd>
      <dd>
        <script type="math/tex; mode=display">P(B) =\sum_A P(B \vert A) P(A)</script>
      </dd>
    </dl>
  </li>
</ol>

<hr />

<h2 id="content9">Discrete Distributions</h2>

<ol>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents9" id="bodyContents91">Uniform Distribution:</strong></dt>
      <dd></dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents9" id="bodyContents92">Bernoulli Distribution:</strong></dt>
      <dd>A distribution over a single binary random variable.<br />
It is controlled by a single parameter <script type="math/tex">\phi \in [0, 1]</script>, which fives the probability of the r.v. being equal to <script type="math/tex">1</script>.
        <blockquote>
          <p>It models the probability of a single experiment with a boolean outcome (e.g. coin flip <script type="math/tex">\rightarrow</script> {heads: 1, tails: 0})</p>
        </blockquote>
      </dd>
      <dd><strong>PMF:</strong></dd>
      <dd>
        <script type="math/tex; mode=display">% <![CDATA[
{\displaystyle P(x)={\begin{cases}p&{\text{if }}p=1,\\q=1-p&{\text{if }}p=0.\end{cases}}} %]]></script>
      </dd>
      <dd><strong>Properties:</strong>
        <ul>
          <li>
            <script type="math/tex; mode=display">P(X=1) = \phi</script>
          </li>
          <li>
            <script type="math/tex; mode=display">P(X=0) = 1 - \phi</script>
          </li>
          <li>
            <script type="math/tex; mode=display">P(X=x) = \phi^x (1 - \phi)^{1-x}</script>
          </li>
          <li>
            <script type="math/tex; mode=display">\operatorname {E}[X] = \phi</script>
          </li>
          <li>
            <script type="math/tex; mode=display">\operatorname {Var}(X) = \phi (1 - \phi)</script>
          </li>
        </ul>
      </dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents9" id="bodyContents93">Binomial Distribution:</strong></dt>
      <dd></dd>
      <dd>
        <blockquote>
          <p><script type="math/tex">{\binom {n}{k}}={\frac {n!}{k!(n-k)!}}</script> is the number of possible ways of getting <script type="math/tex">x</script> successes and <script type="math/tex">n-x</script> failures</p>
        </blockquote>
      </dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents9" id="bodyContents94">Asynchronous:</strong></dt>
      <dd></dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents9" id="bodyContents95">Asynchronous:</strong></dt>
      <dd></dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents9" id="bodyContents96">Asynchronous:</strong></dt>
      <dd></dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents9" id="bodyContents97">Asynchronous:</strong></dt>
      <dd></dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents9" id="bodyContents98">Asynchronous:</strong></dt>
      <dd></dd>
    </dl>
  </li>
</ol>

<hr />

<h2 id="content99">Continuous Distributions</h2>

<ol>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents99" id="bodyContents991">Asynchronous:</strong></dt>
      <dd></dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents99" id="bodyContents992">Asynchronous:</strong></dt>
      <dd></dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents99" id="bodyContents993">Asynchronous:</strong></dt>
      <dd></dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents99" id="bodyContents994">Asynchronous:</strong></dt>
      <dd></dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents99" id="bodyContents995">Asynchronous:</strong></dt>
      <dd></dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents99" id="bodyContents996">Asynchronous:</strong></dt>
      <dd></dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents99" id="bodyContents997">Asynchronous:</strong></dt>
      <dd></dd>
    </dl>
  </li>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents99" id="bodyContents998">Asynchronous:</strong></dt>
      <dd>
        <hr />
      </dd>
    </dl>
  </li>
</ol>

<h2 id="content10">Notes, Tips and Tricks</h2>

<ul>
  <li>
    <p>It is more practical to use a simple but uncertain rule rather than a complex but certain one, even if the true rule is deterministic and our modeling system has the fidelity to accommodate a complex rule.<br />
  For example, the simple rule “Most birds ﬂy” is cheap to develop and is broadly useful, while a rule of the form, “Birds ﬂy, except for very young birds that have not yet learned to ﬂy, sick or injured birds that have lost the ability to ﬂy, ﬂightless species of birds including the cassowary, ostrich and kiwi. . .” is expensive to develop, maintain and communicate and, after all this effort, is still brittle and prone to failure.</p>
  </li>
  <li><strong class="bodyContents10" id="bodyContents102">Disjoint Events (Mutually Exclusive):</strong> are events that cannot occur together at the same time
  Mathematically:
    <ul>
      <li><script type="math/tex">A_i \cap A_j = \varnothing</script> whenever <script type="math/tex">i \neq j</script></li>
      <li><script type="math/tex">p(A_i, A_j) = 0</script>,</li>
    </ul>
  </li>
  <li><strong>Describing a Probability Distribution</strong>:<br />
  A description of a probability distribution is <em>exponential</em> in the number of variables it models</li>
</ul>


      <footer class="site-footer">
    <!--   <span class="site-footer-owner"><a href="http://localhost:8889">Ahmad Badary</a> is maintained by <a href="http://ahmedbadary.ml">Ahmad Badary</a>.</span> -->
    
<!--  -->
    <div class="wrapper">
        <div class="footer-col-wrapper">
            <div class="footer-col footer-col-1">
            <span class="site-footer-owner"><a href="http://localhost:8889">Site</a> maintained by <a href="http://ahmedbadary.ml">Ahmad Badary</a>.</span>
    <span class="site-footer-credits">
        <p>
            &copy; 2017. All rights reserved.
        </p> 
    </span>
            </div>
            <div class="footer-col footer-col-2">
            <div><p>         </p></div>
            </div>
            <div class="footer-col footer-col-3">
                <ul class="social-media-list">
                    
                      <li>
                        <a href="https://github.com/AhmedBadary">
                          <i class="fa fa-github"></i> GitHub
                        </a>
                      </li>
                    
                    
                      <li>
                        <a href="https://linkedin.com/in/ahmad-badary-656098121/">
                          <i class="fa fa-linkedin"></i> LinkedIn
                        </a>
                      </li>
                    
                    
                      <li>
                        <a href="https://www.facebook.com/ahmed.thabet.94">
                          <i class="fa fa-facebook"></i> Facebook
                        </a>
                      </li>
                    
                </ul>
            </div>
        </div>
    </div>
<!--  -->
</footer>


    </section>

  </body>

<!-- Table of Content Script -->
<script type="text/javascript">
var bodyContents = $(".bodyContents1");
$("<ol>").addClass("TOC1ul").appendTo(".TOC1");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC1ul");
     });
// 
var bodyContents = $(".bodyContents2");
$("<ol>").addClass("TOC2ul").appendTo(".TOC2");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC2ul");
     });
// 
var bodyContents = $(".bodyContents3");
$("<ol>").addClass("TOC3ul").appendTo(".TOC3");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC3ul");
     });
//
var bodyContents = $(".bodyContents4");
$("<ol>").addClass("TOC4ul").appendTo(".TOC4");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC4ul");
     });
//
var bodyContents = $(".bodyContents5");
$("<ol>").addClass("TOC5ul").appendTo(".TOC5");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC5ul");
     });
//
var bodyContents = $(".bodyContents6");
$("<ol>").addClass("TOC6ul").appendTo(".TOC6");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC6ul");
     });
//
var bodyContents = $(".bodyContents7");
$("<ol>").addClass("TOC7ul").appendTo(".TOC7");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC7ul");
     });
//
var bodyContents = $(".bodyContents8");
$("<ol>").addClass("TOC8ul").appendTo(".TOC8");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC8ul");
     });
//
var bodyContents = $(".bodyContents9");
$("<ol>").addClass("TOC9ul").appendTo(".TOC9");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC9ul");
     });

</script>

<!-- VIDEO BUTTONS SCRIPT -->
<script type="text/javascript">
  function iframePopInject(event) {
    var $button = $(event.target);
    // console.log($button.parent().next());
    if ($button.attr('value') == 'show') {
        $button.attr('value', 'hide');
        $figure = $("<div>").addClass("video_container");
        $iframe = $("<iframe>").appendTo($figure);
        $iframe.attr("src", $button.attr("src"));
        // $iframe.attr("frameborder", "0");
        $iframe.attr("allowfullscreen", "true");
        $iframe.css("padding", "4px 6px");
        $button.next().css("display", "block");
        $figure.appendTo($button.next());
        $button.text("Hide Video")
    } else {
        $button.attr('value', 'show');
        $button.next().html("");
        $button.text("Show Video")
    }
}
</script>

<!-- BUTTON TRY -->
<script type="text/javascript">
  function iframePopA(event) {
    event.preventDefault();
    var $a = $(event.target).parent();
    console.log($a);
    if ($a.attr('value') == 'show') {
        $a.attr('value', 'hide');
        $figure = $("<div>");
        $iframe = $("<iframe>").addClass("popup_website_container").appendTo($figure);
        $iframe.attr("src", $a.attr("href"));
        $iframe.attr("frameborder", "1");
        $iframe.attr("allowfullscreen", "true");
        $iframe.css("padding", "4px 6px");
        $a.next().css("display", "block");
        $figure.appendTo($a.next().next());
        // $a.text("Hide Content")
        $('html, body').animate({
            scrollTop: $a.offset().top
        }, 1000);
    } else {
        $a.attr('value', 'show');
        $a.next().next().html("");
        // $a.text("Show Content")
    }

    $a.next().css("display", "inline");
}
</script>


<!-- TEXT BUTTON SCRIPT - INJECT -->
<script type="text/javascript">
  function showTextPopInject(event) {
    var $button = $(event.target);
    var txt = $button.attr("input");
    console.log(txt);
    if ($button.attr('value') == 'show') {
        $button.attr('value', 'hide');
        $p = $("<p>");
        $p.html(txt);
        $button.next().css("display", "block");
        $p.appendTo($button.next());
        $button.text("Hide Content")
    } else {
        $button.attr('value', 'show');
        $button.next().html("");
        $button.text("Show Content")
    }

}
</script>

<!-- TEXT BUTTON SCRIPT - HIDDEN / HIDE / SHOW / HIDE/SHOW -->
<script type="text/javascript">
  function showTextPopHide(event) {
    var $button = $(event.target);
    var txt = $button.attr("input");
    if ($button.attr('value') == 'show') {
        $button.attr('value', 'hide');
        $button.next().removeAttr("hidden");
        $button.text("Hide Content");
    } else {
        $button.attr('value', 'show');
        $button.next().attr("hidden", "");
        $button.text("Show Content");
    }
}
</script>

<!-- TEXT BUTTON SCRIPT - HIDDEN / HIDE / SHOW / HIDE/SHOW -->
<script type="text/javascript">
  function showText_withParent_PopHide(event) {
    var $button = $(event.target);
    var $parent = $button.parent();
    var txt = $button.attr("input");
    if ($button.attr('value') == 'show') {
        $button.attr('value', 'hide');
        $parent.next().removeAttr("hidden");
        $button.text("Hide Content");
    } else {
        $button.attr('value', 'show');
        $parent.next().attr("hidden", "");
        $button.text("Show Content");
    }
}
</script>

<!-- Print / Printing / printme -->
<!-- <script type="text/javascript">
i = 0

for (var i = 1; i < 6; i++) {
    var bodyContents = $(".bodyContents" + i);
    $("<p>").addClass("TOC1ul")  .appendTo(".TOC1");
    bodyContents.each(function(index, element) {
        var paragraph = $(element);
        $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC1ul");
         });
} 
</script>
 -->
 
</html>

