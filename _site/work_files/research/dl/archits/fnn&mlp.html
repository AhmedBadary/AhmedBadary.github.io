<!DOCTYPE html>
<html lang="en-us">
  <head>
  <meta charset="UTF-8">
  <title>Ahmad Badary</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <link rel="stylesheet" href="/css/normalize.css">
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="/css/cayman.css">
  <link rel="stylesheet" href="/css/style.css">
  <link rel="shortcut icon" href="/main_files/favicon.ico" />
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="/css/customStyle.css">
  <title> » Ahmad Badary</title>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
</head>

  <body>
    <nav class="main-nav">
    <a href="https://ahmedbadary.github.io/" class="main-nav-logo">
        <img src="/main_files/logo.png">
    </a>
    <ul id="menu-main" class="main-nav-items">
        <li id="menu-item-1859" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-home menu-item-1859">
            <a href="/">Home</a>
        </li>
        <li id="menu-item-2869" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-2869">
            <a href="/work">Work</a>
        </li>
        <li id="menu-item-1892" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1892">
            <a href="/projects">Projects</a>
        </li>
        <li id="menu-item-1858" class="menu-item menu-item-type-post_type menu-item-object-page current_page_parent menu-item-1858">
            <a href="/blog">Blog</a>
        </li>
        <li id="menu-item-1862" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1862">
            <a href="/about">About</a>
        </li>
    </ul>
</nav>


<section class="page-header">
  <h1 class="project-name">FeedForward Neural Networks and Multilayer Perceptron</h1>
  <h2 class="project-tagline"></h2>
  <a href="/#" class="btn">Home</a>
  <a href="/work" class="btn">Work-Space</a>
  <a href= /work_files/research/dl/archits.html class="btn">Previous</a>
</section>

<!-- <div>
  <ul class="posts">
    
      <li><span>02 Jan 2014</span> &raquo; <a href="/2014/01/02/introducing-Ahmad/">Introducing Ahmad</a></li>
    
  </ul>
</div> -->


    <section class="main-content">
      
      <div class="TOC">
  <h1 id="table-of-contents">Table of Contents</h1>

  <ul class="TOC1">
    <li><a href="#content1">FeedForward Neural Network</a></li>
  </ul>
  <ul class="TOC2">
    <li><a href="#content2">Multilayer Perceptron</a></li>
  </ul>
  <ul class="TOC3">
    <li><a href="#content3">Deep FeedForward Neural Network</a></li>
  </ul>
  <ul class="TOC4">
    <li><a href="#content4">(Gradient-Based) Learning for FNNs</a></li>
  </ul>
</div>

<hr />
<hr />

<p><img src="https://cdn.mathpix.com/snip/images/ijocrRQow82xG79k_kuSaZuJgOPfpPW4v8SYvbHSXXU.original.fullsize.png" alt="img" width="80%" /></p>

<h2 id="content1">FeedForward Neural Network</h2>

<ol>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents11">FeedForward Neural Network:</strong><br />
 The <strong>FeedForward Neural Network (FNN)</strong> is an <em>artificial neural network</em> wherein the connections between the nodes do <em>not</em> form a <em>cycle</em>, allowing the information to move only in one direction, forward, from the input layer to the subsequent layers.<br />
 <br /></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents12">Architecture:</strong>  <br />
 An FNN consists of one or more layers, each consisting of nodes (simulating biological neurons) that hold a certain <em>wight value \(w_{ij}\).</em> Those weights are usually multiplied by the input values (in the input layer) in each node and, then, summed; finally, one can apply some sort of activation function on the multiplied values to simulate a response (e.g. 1-0 classification).<br />
 <br /></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents13">Classes of FNNs:</strong>  <br />
 There are many variations of FNNs. As long as they utilize FeedForward control signals and have a layered structure (described above) they are a type of FNN:</p>
    <ul>
      <li><a href="http://localhost:8889/work_files/research/ml/1/2"><strong>Single-Layer Perceptron</strong></a>:<br />
  A <span style="color: purple">linear binary classifier</span>, the <strong>single-layer perceptron</strong> is the simplest feedforward neural network. It consists of a single layer of output nodes; the inputs are multiplied by a series of weights, effectively, being fed directly to the outputs where they values are summed in each node, and if the value is above some threshold (typically 0) the neuron fires and takes the activated value (typically 1); otherwise it takes the deactivated value (typically 0).
        <p>$$f(\mathbf{x})=\left\{\begin{array}{ll}{1} &amp; {\text { if } \mathbf{w} \cdot \mathbf{x}+b&gt;0} \\ {0} &amp; {\text { otherwise }}\end{array}\right.$$</p>
        <p>In the context of neural networks, a perceptron is an artificial neuron using the <a href="https://en.wikipedia.org/wiki/Heaviside_step_function"><strong>Heaviside step function</strong></a> as the activation function.</p>
      </li>
      <li><a href="#content2"><strong>Multi-Layer Perceptron</strong></a>:<br />
  This class of networks consists of multiple layers of computational units, usually interconnected in a feed-forward way. Each neuron in one layer has directed connections to the neurons of the subsequent layer. In many applications the units of these networks apply a sigmoid function as an activation function.</li>
    </ul>
  </li>
</ol>

<!-- 4. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents1 #bodyContents14}  
5. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents1 #bodyContents15}  
6. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents1 #bodyContents16}  
7. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents1 #bodyContents17}  
8. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents1 #bodyContents18} -->

<hr />

<h2 id="content2">Multilayer Perceptron</h2>

<ol>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents21">Multilayer Perceptron:</strong><br />
 The <strong>Multilayer Perceptron (MLP)</strong> is a class of <em>FeedForward Neural Networks</em> that is used for learning from data.<br />
 <br /></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents22">Architecture:</strong>  <br />
 The MLP consists of at least three layers of nodes: <em><strong>input layer</strong></em>, <em><strong>hidden layer</strong></em>, and an <em><strong>output layer</strong></em>.</p>

    <p>The layers in a neural network are connected by certain weights and the MLP is known as a <strong>fully-connected network</strong> where each neuron in one layer is connected with a weight \(w_{ij}\) to every node in the following layer.</p>

    <p>Each node (except for the input nodes) uses a <strong>non-linear activation function</strong> that were developed to <em>model the frequency of <strong>action potential</strong> (firing) of biological neurons</em>.<br />
 <br /></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents23">Learning:</strong>  <br />
 The MLP employs a <strong>supervised learning</strong> technique called <strong>backpropagation</strong>.<br />
 Learning occurs by changing the weights, connecting the layers, based on the amount of error in the output compared to the expected result. Those weights are changed by using <em>gradient-methods</em> to optimize a, given, objective function (called the <strong>loss function</strong>).<br />
 <br /></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents24">Properties:</strong></p>
    <ul>
      <li>Due to their <em>non-linearity</em>, MLPs can distinguish and model non-linearly-separable data</li>
      <li>According to <a href="https://pdfs.semanticscholar.org/05ce/b32839c26c8d2cb38d5529cf7720a68c3fab.pdf"><strong>Cybenko’s Theorem</strong></a>, MLPs are <em><strong>universal function approximators</strong></em>; thus, they can be used for <em>regression analysis</em> and, by extension, <em>classification</em></li>
      <li>Without the <em>non-linear activation functions</em>, MLPs will be identical to <strong>Perceptrons</strong>, since Linear Algebra shows that the linear transformations in many hidden layers can be collapsed into one linear-transformation<br />
 <br /></li>
    </ul>
  </li>
</ol>

<!-- 5. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents2 #bodyContents25}  

6. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents2 #bodyContents26}  

7. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents2 #bodyContents27}  

8. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents2 #bodyContents28} -->

<hr />

<h2 id="content3"><a href="/work_files/research/dl/theory/dl_book_pt2#content1">Deep FeedForward Neural Network</a></h2>

<hr />

<h2 id="content4"><a href="/work_files/research/dl/theory/dl_book_pt2#content2">(Gradient-Based) Learning for FNNs</a></h2>

<hr />

<!-- ## [Activation Functions for FNNs](/work_files/research/dl/theory/dl_book_pt2#content2)
{: #content4} -->


      <footer class="site-footer">
    <!--   <span class="site-footer-owner"><a href="http://localhost:8880">Ahmad Badary</a> is maintained by <a href="http://ahmedbadary.ml">Ahmad Badary</a>.</span> -->
    
<!--  -->
    <div class="wrapper">
        <div class="footer-col-wrapper">
            <div class="footer-col footer-col-1">
            <span class="site-footer-owner"><a href="http://localhost:8880">Site</a> maintained by <a href="http://ahmedbadary.ml">Ahmad Badary</a>.</span>
    <span class="site-footer-credits">
        <p>
            &copy; 2017. All rights reserved.
        </p> 
    </span>
            </div>
            <div class="footer-col footer-col-2">
            <div><p>         </p></div>
            </div>
            <div class="footer-col footer-col-3">
                <ul class="social-media-list">
                    
                      <li>
                        <a href="https://github.com/AhmedBadary">
                          <i class="fa fa-github"></i> GitHub
                        </a>
                      </li>
                    
                    
                      <li>
                        <a href="https://linkedin.com/in/ahmad-badary-656098121/">
                          <i class="fa fa-linkedin"></i> LinkedIn
                        </a>
                      </li>
                    
                    
                      <li>
                        <a href="https://www.facebook.com/ahmed.thabet.94">
                          <i class="fa fa-facebook"></i> Facebook
                        </a>
                      </li>
                    
                </ul>
            </div>
        </div>
    </div>
<!--  -->
</footer>


    </section>

  </body>

<!-- Table of Content Script -->
<script type="text/javascript">
var bodyContents = $(".bodyContents1");
$("<ol>").addClass("TOC1ul").appendTo(".TOC1");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC1ul");
     });
// 
var bodyContents = $(".bodyContents2");
$("<ol>").addClass("TOC2ul").appendTo(".TOC2");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC2ul");
     });
// 
var bodyContents = $(".bodyContents3");
$("<ol>").addClass("TOC3ul").appendTo(".TOC3");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC3ul");
     });
//
var bodyContents = $(".bodyContents4");
$("<ol>").addClass("TOC4ul").appendTo(".TOC4");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC4ul");
     });
//
var bodyContents = $(".bodyContents5");
$("<ol>").addClass("TOC5ul").appendTo(".TOC5");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC5ul");
     });
//
var bodyContents = $(".bodyContents6");
$("<ol>").addClass("TOC6ul").appendTo(".TOC6");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC6ul");
     });
//
var bodyContents = $(".bodyContents7");
$("<ol>").addClass("TOC7ul").appendTo(".TOC7");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC7ul");
     });
//
var bodyContents = $(".bodyContents8");
$("<ol>").addClass("TOC8ul").appendTo(".TOC8");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC8ul");
     });
//
var bodyContents = $(".bodyContents9");
$("<ol>").addClass("TOC9ul").appendTo(".TOC9");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC9ul");
     });

</script>

<!-- VIDEO BUTTONS SCRIPT -->
<script type="text/javascript">
  function iframePopInject(event) {
    var $button = $(event.target);
    // console.log($button.parent().next());
    if ($button.attr('value') == 'show') {
        $button.attr('value', 'hide');
        $figure = $("<div>").addClass("video_container");
        $iframe = $("<iframe>").appendTo($figure);
        $iframe.attr("src", $button.attr("src"));
        // $iframe.attr("frameborder", "0");
        $iframe.attr("allowfullscreen", "true");
        $iframe.css("padding", "4px 6px");
        $button.next().css("display", "block");
        $figure.appendTo($button.next());
        $button.text("Hide Video")
    } else {
        $button.attr('value', 'show');
        $button.next().html("");
        $button.text("Show Video")
    }
}
</script>

<!-- BUTTON TRY -->
<script type="text/javascript">
  function iframePopA(event) {
    event.preventDefault();
    var $a = $(event.target).parent();
    console.log($a);
    if ($a.attr('value') == 'show') {
        $a.attr('value', 'hide');
        $figure = $("<div>");
        $iframe = $("<iframe>").addClass("popup_website_container").appendTo($figure);
        $iframe.attr("src", $a.attr("href"));
        $iframe.attr("frameborder", "1");
        $iframe.attr("allowfullscreen", "true");
        $iframe.css("padding", "4px 6px");
        $a.next().css("display", "block");
        $figure.appendTo($a.next().next());
        // $a.text("Hide Content")
        $('html, body').animate({
            scrollTop: $a.offset().top
        }, 1000);
    } else {
        $a.attr('value', 'show');
        $a.next().next().html("");
        // $a.text("Show Content")
    }

    $a.next().css("display", "inline");
}
</script>


<!-- TEXT BUTTON SCRIPT - INJECT -->
<script type="text/javascript">
  function showTextPopInject(event) {
    var $button = $(event.target);
    var txt = $button.attr("input");
    console.log(txt);
    if ($button.attr('value') == 'show') {
        $button.attr('value', 'hide');
        $p = $("<p>");
        $p.html(txt);
        $button.next().css("display", "block");
        $p.appendTo($button.next());
        $button.text("Hide Content")
    } else {
        $button.attr('value', 'show');
        $button.next().html("");
        $button.text("Show Content")
    }

}
</script>

<!-- TEXT BUTTON SCRIPT - HIDDEN / HIDE / SHOW / HIDE/SHOW -->
<script type="text/javascript">
  function showTextPopHide(event) {
    var $button = $(event.target);
    // var txt = $button.attr("input");
    var txt = $button.text();
    if ($button.attr('value') == 'show') {
        $button.attr('value', 'hide');
        $button.next().removeAttr("hidden");
        $button.text(txt + " - Hide Content");
    } else {
        $button.attr('value', 'show');
        $button.next().attr("hidden", "");
        $button.text(txt.replace(" - Hide Content",""));
    }
}
</script>

<!-- TEXT BUTTON SCRIPT - HIDDEN / HIDE / SHOW / HIDE/SHOW -->
<script type="text/javascript">
  function showText_withParent_PopHide(event) {
    var $button = $(event.target);
    var $parent = $button.parent();
    var txt = $button.text();
    if ($button.attr('value') == 'show') {
        $button.attr('value', 'hide');
        $parent.next().removeAttr("hidden");
        $button.text(txt + " - Hide Content");
    } else {
        $button.attr('value', 'show');
        $parent.next().attr("hidden", "");
        $button.text(txt.replace(" - Hide Content",""));
    }
}
</script>

<!-- Print / Printing / printme -->
<!-- <script type="text/javascript">
i = 0

for (var i = 1; i < 6; i++) {
    var bodyContents = $(".bodyContents" + i);
    $("<p>").addClass("TOC1ul")  .appendTo(".TOC1");
    bodyContents.each(function(index, element) {
        var paragraph = $(element);
        $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC1ul");
         });
} 
</script>
 -->
 
</html>

