<!DOCTYPE html>
<html lang="en-us">
  <head>
  <meta charset="UTF-8">
  <title>Ahmad Badary</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <link rel="stylesheet" href="/css/normalize.css">
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="/css/cayman.css">
  <link rel="stylesheet" href="/css/style.css">
  <link rel="shortcut icon" href="/main_files/favicon.ico" />
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="/css/customStyle.css">
  <title> » Ahmad Badary</title>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
</head>

  <body>
    <nav class="main-nav">
    <a href="https://ahmedbadary.github.io/" class="main-nav-logo">
        <img src="/main_files/logo.png">
    </a>
    <ul id="menu-main" class="main-nav-items">
        <li id="menu-item-1859" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-home menu-item-1859">
            <a href="/">Home</a>
        </li>
        <li id="menu-item-2869" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-2869">
            <a href="/work">Work</a>
        </li>
        <li id="menu-item-1892" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1892">
            <a href="/projects">Projects</a>
        </li>
        <li id="menu-item-1858" class="menu-item menu-item-type-post_type menu-item-object-page current_page_parent menu-item-1858">
            <a href="/blog">Blog</a>
        </li>
        <li id="menu-item-1862" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1862">
            <a href="/about">About</a>
        </li>
    </ul>
</nav>


<section class="page-header">
  <h1 class="project-name">Regularization</h1>
  <h2 class="project-tagline"></h2>
  <a href="/#" class="btn">Home</a>
  <a href="/work" class="btn">Work-Space</a>
  <a href= /work_files/research/dl/theory.html class="btn">Previous</a>
</section>

<!-- <div>
  <ul class="posts">
    
      <li><span>02 Jan 2014</span> &raquo; <a href="/2014/01/02/introducing-Ahmad/">Introducing Ahmad</a></li>
    
  </ul>
</div> -->


    <section class="main-content">
      
      <div class="TOC">
  <h1 id="table-of-contents">Table of Contents</h1>

  <ul class="TOC1">
    <li><a href="#content1">Regularization Basics and Definitions</a></li>
  </ul>
  <ul class="TOC2">
    <li><a href="#content2">Parameter Norm Penalties</a></li>
  </ul>
  <ul class="TOC3">
    <li><a href="#content3">Advanced Regularization Techniques</a></li>
  </ul>
</div>

<hr />
<hr />

<p><a href="/work_files/research/dl/nlp/dl_book_pt1#bodyContents133">Regularization in FFN</a><br />
<a href="/concepts_#bodyContents616">Regularization Concept</a><br />
<a href="https://medium.com/inveterate-learner/deep-learning-book-chapter-7-regularization-for-deep-learning-937ff261875c">Regularization Ch.7 Summary</a><br />
<a href="http://cs229.stanford.edu/notes-spring2019/addendum_bias_variance.pdf">How Regularization Reduces Variance from bias-var-decomp</a><br />
<a href="http://bjlkeng.github.io/posts/probabilistic-interpretation-of-regularization">Probabilistic Interpretation of Regularization (MAP)</a><br />
<a href="https://www.wikiwand.com/en/Regularization_(mathematics)">The Math of Regularization</a></p>

<h2 id="content1">Regularization Basics and Definitions</h2>

<ol>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents11">Regularization:</strong>  <br />
 <strong>Regularization</strong> can be, loosely, defined as: any modification we make to a learning algorithm that is intended to <em>reduce</em> its <em>generalization error</em> but not its <em>training error</em>.</p>

    <p>Formally, it is a set of techniques that impose certain restrictions on the hypothesis space (by adding information) in order to solve an <strong>ill-posed</strong> problem or to prevent <strong>overfitting</strong>.<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents12">Theoretical Justification for Regularization:</strong>  <br />
 A theoretical justification for regularization is that it attempts to impose Occam’s razor on the solution.<br />
 From a Bayesian point of view, many regularization techniques correspond to imposing certain prior distributions on model parameters.
 <br /></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents13">Regularization in Deep Learning:</strong><br />
 In the context of DL, most regularization strategies are based on <strong>regularizing estimators</strong>, which usually works by <em>trading increased bias for reduced variance</em>.</p>

    <p>An effective regularizer is one that makes a profitable trade, reducing variance significantly while not overly increasing the bias.
 <br /></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents14">Regularization and Data Domains in DL - A Practical Motivation:</strong><br />
 Most applications of DL are to domains where the true data-generating process is almost certainly outside the model family (hypothesis space). Deep learning algorithms are typically applied to extremely complicated domains such as images, audio sequences and text, for which the true generation process essentially involves simulating the entire universe.</p>

    <p>Thus, controlling the complexity of the mdoel is not a simple matter of finding the model of the right size, with the right number of parameters; instead, the best fitting model (wrt. generalization error) is a large model that has been regularized appropriately.</p>
  </li>
</ol>

<hr />

<h2 id="content2">Parameter Norm Penalties</h2>

<ol>
  <li><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents21">Parameter Norms:</strong><br />
 Many regularization approaches are based on limiting the capacity of models by adding a parameter norm penalty <script type="math/tex">\Omega(\boldsymbol{\theta})</script> to the objective function <script type="math/tex">J</script>. We denote the regularized objective function by <script type="math/tex">\tilde{J}</script>:
    <p>$$\tilde{J}(\boldsymbol{\theta} ; \boldsymbol{X}, \boldsymbol{y})=J(\boldsymbol{\theta} ; \boldsymbol{X}, \boldsymbol{y})+\alpha \Omega(\boldsymbol{\theta}) \tag{7.1}$$</p>
    <p>where <script type="math/tex">\alpha \in[0, \infty)</script> is a HP that weights the relative contribution of the norml penalty term, <script type="math/tex">\Omega</script>, relative to the standard objective function <script type="math/tex">J</script>.</p>
    <ul>
      <li><strong>Effects of <script type="math/tex">\alpha</script></strong>:
        <ul>
          <li><script type="math/tex">\alpha = 0</script> results in NO regularization</li>
          <li>Larger values of <script type="math/tex">\alpha</script> correspond to MORE regularization</li>
        </ul>
      </li>
    </ul>

    <p>The <strong>effect of minimizing the regularized objective function</strong> is that it will <em><strong>decrease</strong></em>, both, <em>the original objective <script type="math/tex">J</script></em> on the training data and some <em>measure of the size of the parameters <script type="math/tex">\boldsymbol{\theta}</script></em>.</p>

    <p>Different choices for the parameter norm <script type="math/tex">\Omega</script> can result in different solutions being preferred.</p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents22">Parameter Penalties and the Bias parameter:</strong><br />
 In NN, we usually penalize <strong>only the weights</strong> of the affine transformation at each layer and we leave the <strong>biases unregularized</strong>.<br />
 Biases typically require less data than the weights to fit accurately. The reason is that <em>each weight specifies how TWO variables interact</em> so fitting the weights well, requires observing both variable sin a variety of conditions. However, <em>each bias controls only a single variable</em>, thus, we dont induce too much <em>variance</em> by leaving the biases unregularized. If anything, regularizing the bias can introduce a significant amount of <em>underfitting</em>.</p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents23">Note on the <script type="math/tex">\alpha</script> parameter for different hidden layers:</strong><br />
 In the context of neural networks, it is sometimes desirable to use a separate penalty with a different <script type="math/tex">\alpha</script> coefficient for each layer of the network. Because it can be expensive to search for the correct value of multiple hyperparameters, it is still reasonable to use the same weight decay at all layers just to reduce the size of search space.</p>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents24"><script type="math/tex">L^2</script> Parameter Regularization (Weight Decay):</strong><br />
 It is a regularization strategy that <em>drives the weights closer to the origin</em><sup id="fnref:2"><a href="#fn:2" class="footnote">2</a></sup> by adding a regularization term:
    <p>$$\Omega(\mathbf{\theta}) = \frac{1}{2}\|\boldsymbol{w}\|_ {2}^{2}$$</p>
    <p>to the objective function.</p>

    <p>In statistics, <script type="math/tex">L^2</script> regularization is also known as <strong>Ridge Regression</strong> or <strong>Tikhonov Regularization</strong>.</p>

    <p><strong style="color: red">Analyzing Weight Decay:</strong><br />
 <button class="showText" value="show" onclick="showText_withParent_PopHide(event);">Show Analysis</button></p>
    <ul hidden="">
      <li><strong>What happens in a Single Step</strong>:<br />
  We can gain some insight into the behavior of weight decay regularization by studying the gradient of the regularized objective function.<br />
  Take the models objective function:
        <p>$$\tilde{J}(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})=\frac{\alpha}{2} \boldsymbol{w}^{\top} \boldsymbol{w}+J(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y}) \tag{7.2}$$</p>
        <p>with the corresponding <em>parameter gradient</em>:</p>
        <p>$$\nabla_{\boldsymbol{w}} \tilde{J}(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})=\alpha \boldsymbol{w}+\nabla_{\boldsymbol{w}} J(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y}) \tag{7.3}$$</p>
        <p>The gradient descent update:</p>
        <p>$$\boldsymbol{w} \leftarrow \boldsymbol{w}-\epsilon\left(\alpha \boldsymbol{w}+\nabla_{\boldsymbol{w}} J(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})\right) \tag{7.4}$$</p>
        <p>Equivalently:</p>
        <p>$$\boldsymbol{w} \leftarrow(1-\epsilon \alpha) \boldsymbol{w}-\epsilon \nabla_{\boldsymbol{w}} J(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y}) \tag{7.5}$$</p>

        <p>Observe that the addition of the weight decay term has modified the learning rule to <strong>multiplicatively shrink the weight vector by  a constant factor on each step</strong>, just before performing the usual gradient update.</p>
      </li>
      <li><strong>What happens over the Entire course of training</strong>:<br />
  We simplify the analysis by making a quadratic (2nd-order Taylor) approximation to the objective function in the neighborhood of the optimal wight-parameter of the unregularized objective <script type="math/tex">\mathbf{w}^{\ast} = \arg \min_{\boldsymbol{w}} J(\boldsymbol{w})</script>.<sup id="fnref:3"><a href="#fn:3" class="footnote">3</a></sup><br />
  The approximation <script type="math/tex">\hat{J}</script>:
        <p>$$\hat{J}(\boldsymbol{\theta})=J\left(\boldsymbol{w}^{\ast}\right)+\frac{1}{2}\left(\boldsymbol{w}-\boldsymbol{w}^{\ast}\right)^{\top} \boldsymbol{H}(J(\boldsymbol{w}^{\ast}))\left(\boldsymbol{w}-\boldsymbol{w}^{\ast}\right)  \tag{7.6}$$</p>
        <p>where <script type="math/tex">\boldsymbol{H}</script> is the Hessian matrix of <script type="math/tex">J</script> with respect to <script type="math/tex">\mathbf{w}</script> evaluated at <script type="math/tex">\mathbf{w}^{\ast}</script>.</p>

        <p><strong>Notice:</strong></p>
        <ul>
          <li>There is no first-order term in this quadratic approximation, because <script type="math/tex">\boldsymbol{w}^{\ast}</script>  is defined to be a minimum, where the gradient vanishes.</li>
          <li>Because <script type="math/tex">\boldsymbol{w}^{\ast}</script> is the location of a minimum of <script type="math/tex">J</script>, we can conclude that <script type="math/tex">\boldsymbol{H}</script> is <strong>positive semidefinite</strong>.</li>
        </ul>

        <p>The <strong>gradient</strong> of <script type="math/tex">\hat{J} + \Omega(\mathbf{\theta})</script>:</p>
        <p>$$\nabla_{\boldsymbol{w}} \hat{J}(\boldsymbol{w})=\boldsymbol{H}(J(\boldsymbol{w}^{\ast}))\left(\tilde{\boldsymbol{w}}-\boldsymbol{w}^{\ast}\right) + \alpha \tilde{\boldsymbol{w}} \tag{7.7}$$</p>
        <p>And the <strong>minimum</strong> is achieved at <script type="math/tex">\nabla_{\boldsymbol{w}} \hat{J}(\boldsymbol{w}) = 0</script>:</p>
        <p>$$\tilde{\boldsymbol{w}}=(\boldsymbol{H}+\alpha \boldsymbol{I})^{-1} \boldsymbol{H} \boldsymbol{w}^{\ast} \tag{7.10}$$</p>

        <p><strong>Effects:</strong></p>
        <ul>
          <li>As <script type="math/tex">\alpha</script> approaches <script type="math/tex">0</script>: the regularized solution <script type="math/tex">\tilde{\boldsymbol{w}}</script> approaches <script type="math/tex">\boldsymbol{w}^{\ast}</script>.</li>
          <li>As <script type="math/tex">\alpha</script> grows: we apply <strong>spectral decomposition</strong> to the <strong>real and symmetric</strong> <script type="math/tex">\boldsymbol{H} = \boldsymbol{Q} \boldsymbol{\Lambda} \boldsymbol{Q}^{\top}</script>:
            <p>$$\begin{aligned} \tilde{\boldsymbol{w}} &amp;=\left(\boldsymbol{Q} \mathbf{\Lambda} \boldsymbol{Q}^{\top}+\alpha \boldsymbol{I}\right)^{-1} \boldsymbol{Q} \boldsymbol{\Lambda} \boldsymbol{Q}^{\top} \boldsymbol{w}^{\ast} \\ &amp;=\left[\boldsymbol{Q}(\boldsymbol{\Lambda}+\alpha \boldsymbol{I}) \boldsymbol{Q}^{\top}\right]^{-1} \boldsymbol{Q} \boldsymbol{\Lambda} \boldsymbol{Q}^{\top} \boldsymbol{w}^{\ast} \\ &amp;=\boldsymbol{Q}(\boldsymbol{\Lambda}+\alpha \boldsymbol{I})^{-1} \boldsymbol{\Lambda} \boldsymbol{Q}^{\top} \boldsymbol{w}^{\ast} \end{aligned} \tag{7.13}$$</p>
          </li>
        </ul>

        <p>Thus, we see that the effect of weight decay is to rescale <script type="math/tex">\boldsymbol{w}^{\ast}</script> along the axes defined by the eigenvector of <script type="math/tex">\boldsymbol{H}</script> . Specifically, the component of <script type="math/tex">\boldsymbol{w}^{\ast}</script> that is aligned with the <script type="math/tex">i</script>-th eigenvector of <script type="math/tex">\boldsymbol{H}</script>  is rescaled by a factor of <script type="math/tex">\frac{\lambda_{i}}{\lambda_{i}+\alpha}</script>.</p>

        <p><img src="/main_files/dl_book/regularization/1.png" alt="img" width="100%" /></p>

        <p><strong>Summary:</strong></p>

        <table>
          <tbody>
            <tr>
              <td><strong>Condition</strong></td>
              <td><strong>Effect of Regularization</strong></td>
            </tr>
            <tr>
              <td><script type="math/tex">\lambda_{i}>>\alpha</script></td>
              <td>Not much</td>
            </tr>
            <tr>
              <td><script type="math/tex">% <![CDATA[
\lambda_{i}<<\alpha %]]></script></td>
              <td>The weight value almost shrunk to <script type="math/tex">0</script></td>
            </tr>
          </tbody>
        </table>
      </li>
      <li><strong>Applying <script type="math/tex">L^2</script> regularization to <em>Linear Regression</em> :</strong>
        <ul>
          <li><button class="showText" value="show" onclick="showTextPopHide(event);">Application to Linear Regression</button>
  <img src="/main_files/dl_book/regularization/2.png" alt="img" width="100%" hidden="" /></li>
        </ul>
      </li>
    </ul>
    <p><br /></p>

    <p><strong style="color: red"><script type="math/tex">L^2</script> Regularization Derivation:</strong><br />
 <script type="math/tex">L^2</script> regularization is equivalent to <strong>MAP Bayesian inference with a Gaussian prior on the weights</strong>.</p>

    <p><strong>The MAP Estimate:</strong><br />
 <button class="showText" value="show" onclick="showText_withParent_PopHide(event);">Show MAP Estimate Derivation</button></p>
    <p hidden="">$$\begin{aligned} \hat{\theta}_ {\mathrm{MAP}} &amp;=\arg \max_{\theta} P(\theta | y) \\ &amp;=\arg \max_{\theta} \frac{P(y | \theta) P(\theta)}{P(y)} \\ &amp;=\arg \max_{\theta} P(y | \theta) P(\theta) \\ &amp;=\arg \max_{\theta} \log (P(y | \theta) P(\theta)) \\ &amp;=\arg \max_{\theta} \log P(y | \theta)+\log P(\theta) \end{aligned}$$</p>

    <p>We place a <strong>Gaussian Prior</strong> on the weights, with <strong>zero mean</strong> and <strong>equal variance <script type="math/tex">\tau^2</script></strong>:</p>
    <p>$$\begin{aligned} \hat{\theta}_ {\mathrm{MAP}} &amp;=\arg \max_{\theta} \log P(y | \theta)+\log P(\theta) \\ &amp;=\arg \max _{\boldsymbol{w}}\left[\log \prod_{i=1}^{n} \dfrac{1}{\sigma \sqrt{2 \pi}} e^{-\dfrac{\left(y_{i}-\boldsymbol{w}^T\boldsymbol{x}_i\right)^{2}}{2 \sigma^{2}}}+\log \prod_{j=0}^{p} \dfrac{1}{\tau \sqrt{2 \pi}} e^{-\dfrac{w_{j}^{2}}{2 \tau^{2}}} \right] \\ &amp;=\arg \max _{\boldsymbol{w}} \left[-\sum_{i=1}^{n} \dfrac{\left(y_{i}-\boldsymbol{w}^T\boldsymbol{x}_i\right)^{2}}{2 \sigma^{2}}-\sum_{j=0}^{p} \dfrac{w_{j}^{2}}{2 \tau^{2}}\right] \\ &amp;=\arg \min_{\boldsymbol{w}} \dfrac{1}{2 \sigma^{2}}\left[\sum_{i=1}^{n}\left(y_{i}-\boldsymbol{w}^T\boldsymbol{x}_i\right)^{2}+\dfrac{\sigma^{2}}{\tau^{2}} \sum_{j=0}^{p} w_{j}^{2}\right] \\ &amp;=\arg \min_{\boldsymbol{w}} \left[\sum_{i=1}^{n}\left(y_{i}-\boldsymbol{w}^T\boldsymbol{x}_i\right)^{2}+\lambda \sum_{j=0}^{p} w_{j}^{2}\right] \\ &amp;= \arg \min_{\boldsymbol{w}} \left[ \|XW - \boldsymbol{y}\|^2 + \lambda {\|\boldsymbol{w}\|_ 2}^2\right]\end{aligned}$$</p>
    <p><button class="showText" value="show" onclick="showTextPopHide(event);">Different Notation</button>
 <img src="/main_files/dl_book/regularization/4.png" alt="img" width="100%" hidden="" /> <br />
 <br /></p>

    <p><strong style="color: red">Properties:</strong></p>
    <ul>
      <li>Notice that L2-regularization has a rotational invariance. This actually makes it more sensitive to irrelevant features.  <a href="https://www.cs.ubc.ca/~schmidtm/Courses/540-W18/L6.pdf">Ref</a></li>
      <li>Adding L2-regularization to a convex function gives a strongly-convex function. So L2-regularization can make gradient descent converge much faster.  (^ same ref)    <br />
 <br /></li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents25"><script type="math/tex">L^1</script> Regularization:</strong><br />
 <script type="math/tex">L^1</script> Regularization is another way to regulate the model by <em>penalizing the size of its parameters</em>; the technique adds a regularization term:
    <p>$$\Omega(\boldsymbol{\theta})=\|\boldsymbol{w}\|_{1}=\sum_{i}\left|w_{i}\right| \tag{7.18}$$</p>
    <p>which is a sum of absolute values of the individual parameters.</p>

    <p>The regularized objective function is given by:</p>
    <p>$$\tilde{J}(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})=\alpha\|\boldsymbol{w}\|_ {1}+J(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y}) \tag{7.19}$$</p>
    <p>with the corresponding (sub) gradient:</p>
    <p>$$\nabla_{\boldsymbol{w}} \tilde{J}(\boldsymbol{w} ; \boldsymbol{X}, \boldsymbol{y})=\alpha \operatorname{sign}(\boldsymbol{w})+\nabla_{\boldsymbol{w}} J(\boldsymbol{X}, \boldsymbol{y} ; \boldsymbol{w}) \tag{7.20}$$</p>

    <p>Notice that the regularization contribution to the gradient, <strong>no longer scales linearly with each <script type="math/tex">w_i</script></strong>; instead it is a <strong>constant factor with a sign = <script type="math/tex">\text{sign}(w_i)</script></strong>.</p>

    <p>[Analysis]</p>

    <p><strong>Sparsity of the <script type="math/tex">L^1</script> regularization:</strong><br />
 In comparison to <script type="math/tex">L^2</script>, <script type="math/tex">L^1</script> regularization results in a solution that is more <strong>sparse</strong>.<br />
 The <em>sparsity property</em> has been used extensively as a <strong>feature selection</strong> mechanism.</p>
    <ul>
      <li><strong>LASSO</strong>: The Least Absolute Shrinkage and Selection Operator integrates an <script type="math/tex">L^1</script> penalty with a <em>linear model</em> and a <em>least-squares cost function</em>.<br />
  The <script type="math/tex">L^1</script> penalty causes a subset of the weights to become <strong>zero</strong>, suggesting that the corresponding features may safely be discarded.</li>
    </ul>

    <p><strong style="color: red"><script type="math/tex">L^1</script> Regularization Derivation:</strong><br />
 <script type="math/tex">L^1</script> regularization is equivalent to (the log-prior term in) <strong>MAP Bayesian inference with an isotropic Laplace distribution prior on the weights</strong>:</p>
    <p>$$\log p(\boldsymbol{w})=\sum_{i} \log \operatorname{Laplace}\left(w_{i} ; 0, \frac{1}{\alpha}\right)=-\alpha\|\boldsymbol{w}\|_ {1}+n \log \alpha-n \log 2 \tag{7.24}$$</p>
    <p>note that we can ignore the terms <script type="math/tex">\log \alpha-\log 2</script> because they do not depend on <script type="math/tex">\boldsymbol{w}</script>.    <br />
 <button class="showText" value="show" onclick="showText_withParent_PopHide(event);">Derivation</button></p>
    <p hidden="">$$\begin{aligned} \hat{\theta}_ {\mathrm{MAP}} &amp;=\arg \max_{\theta} \log P(y | \theta)+\log P(\theta) \\  &amp;=\arg \max _{\boldsymbol{w}}\left[\log \prod_{i=1}^{n} \dfrac{1}{\sigma \sqrt{2 \pi}} e^{-\dfrac{\left(y_{i}-\boldsymbol{w}^T\boldsymbol{x}_i\right)^{2}}{2 \sigma^{2}}}+\log \prod_{j=0}^{p} \dfrac{1}{2 b} e^{-\dfrac{\left|\theta_{j}\right|}{2 b}} \right] \\    &amp;=\arg \max _{\boldsymbol{w}} \left[-\sum_{i=1}^{n} \dfrac{\left(y_{i}-\boldsymbol{w}^T\boldsymbol{x}_i\right)^{2}}{2 \sigma^{2}}-\sum_{j=0}^{p} \dfrac{\left|w_{j}\right|}{2 b}\right] \\    &amp;=\arg \min_{\boldsymbol{w}} \dfrac{1}{2 \sigma^{2}}\left[\sum_{i=1}^{n}\left(y_{i}-\boldsymbol{w}^T\boldsymbol{x}_i\right)^{2}+\dfrac{\sigma^{2}}{b} \sum_{j=0}^{p}\left|w_{j}\right|\right] \\    &amp;=\arg \min_{\boldsymbol{w}} \left[\sum_{i=1}^{n}\left(y_{i}-\boldsymbol{w}^T\boldsymbol{x}_i\right)^{2}+\lambda \sum_{j=0}^{p}\left|w_{j}\right|\right] \\    &amp;= \arg \min_{\boldsymbol{w}} \left[ \|XW - \boldsymbol{y}\|^2 + \lambda \|\boldsymbol{w}\|_ 1\right]\end{aligned}$$</p>
    <p><br /></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents26"><script type="math/tex">L^1</script> VS <script type="math/tex">L^2</script> Regularization:</strong></p>

    <ul>
      <li><strong>Feature Correlation and Sparsity</strong>:
        <ul>
          <li><strong>Identical features</strong>:
            <ul>
              <li><script type="math/tex">L^1</script> regularization spreads weight arbitrarily (all weights same sign)</li>
              <li><script type="math/tex">L^2</script> regularization spreads weight evenly</li>
            </ul>
          </li>
          <li><strong>Linearly related features</strong>:
            <ul>
              <li><script type="math/tex">L^1</script> regularization chooses variable with larger scale, <script type="math/tex">0</script> weight to others</li>
              <li><script type="math/tex">L^2</script> prefers variables with larger scale — spreads weight proportional to scale
                <blockquote>
                  <p><a href="https://www.youtube.com/watch?v=KIoz_aa1ed4&amp;list=PLnZuxOufsXnvftwTB1HL6mel1V32w0ThI&amp;index=7">Reference</a></p>
                </blockquote>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>

    <p><strong style="color: red">Interpreting Sparsity with an Example:</strong><br />
 Let’s imagine we are estimating two coefficients in a regression. In <script type="math/tex">L^2</script> regularization, the solution <script type="math/tex">\boldsymbol{w} =(0,1)</script> has the same weight as <script type="math/tex">\boldsymbol{w}=(\frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}})</script>  so they are both treated equally. In <script type="math/tex">L^1</script> regularization, the same two solutions favor the sparse one:</p>
    <p>$$\|(1,0)\|_{1}=1&lt;\left\|\left(\frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}}\right)\right\|_{1}=\sqrt{2}$$</p>
    <p>So <script type="math/tex">L^2</script> regularization doesn’t have any specific built in mechanisms to favor zeroed out coefficients, while <script type="math/tex">L^1</script> regularization actually favors these sparser solutions.</p>
    <blockquote>
      <p><a href="https://www.quora.com/What-is-the-difference-between-L1-and-L2-regularization-How-does-it-solve-the-problem-of-overfitting-Which-regularizer-to-use-and-when">Extensive Discussions on Sparsity (Quora)</a></p>
    </blockquote>

    <p><br /></p>
  </li>
</ol>

<p><strong style="color: red">Notes:</strong></p>
<ul>
  <li><strong>Elastic Net Regularization:</strong>
    <p>$$\Omega = \lambda\left(\alpha\|w\|_{1}+(1-\alpha)\|w\|_{2}^{2}\right), \alpha \in[0,1]$$</p>
    <ul>
      <li>Combines both <script type="math/tex">L^1</script> and <script type="math/tex">L^2</script></li>
      <li>Used to <strong>produce sparse solutions</strong>, but to avoid the problem of <script type="math/tex">L^1</script> solutions being sometimes <strong>Non-Unique</strong>
        <ul>
          <li>The problem mainly arises with <strong>correlated features</strong></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<hr />

<h2 id="content3">Advanced Regularization Techniques</h2>

<ol>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents3" id="bodyContents31">Regularization and Under-Constrained Problems:</strong><br />
 In some cases, regularization is necessary for machine learning problems to be properly define.</p>

    <p>Many linear models (e.g. Linear Regression, PCA) depend on <strong>inverting <script type="math/tex">\boldsymbol{X}^T\boldsymbol{X}</script></strong>. This is not possible if <script type="math/tex">\boldsymbol{X}^T\boldsymbol{X}</script> is singular. In this case, many forms of regularization correspond to solving inverting <script type="math/tex">\boldsymbol{X}^{\top} \boldsymbol{X}+\alpha \boldsymbol{I}</script> instead. This regularized matrix is <strong>guaranteed to be invertible</strong>.</p>
    <ul>
      <li><script type="math/tex">\boldsymbol{X}^T\boldsymbol{X}</script> can be singular if:
        <ul>
          <li>The data-generating function truly has no variance in some direction.</li>
          <li>No Variance is <em>observed</em> in some direction because there are fewer examples (rows of <script type="math/tex">\boldsymbol{X}</script>) than input features (columns).</li>
        </ul>
      </li>
    </ul>

    <p>Models with no closed-form solution can, also, be <em>underdetermined</em>:<br />
 Take <strong>logistic regression on a linearly separable dataset</strong>, if a weight vector <script type="math/tex">\boldsymbol{w}</script> is able to achieve perfect classification, then so does <script type="math/tex">2\boldsymbol{w}</script> but with even <strong>higher likelihood</strong>. Thus, an iterative optimization procedure (sgd) will continually increase the magnitude of <script type="math/tex">\boldsymbol{w}</script> and, in theory, will <strong>never halt</strong>.<br />
 We can use regularization to guarantee the convergence of iterative methods applied to underdetermined problems: e.g. <strong>weight decay</strong> will cause gradient descent to <em>quit increasing the magnitude of the weights when the <strong>slope of the likelihood is equal to the weight decay coefficient</strong></em>.</p>

    <p><strong>Linear Algebra Perspective:</strong><br />
 Given that the <strong>Moore-Penrose pseudoinverse</strong> <script type="math/tex">\boldsymbol{X}^{+}</script> of a matrix <script type="math/tex">\boldsymbol{X}</script> can solve underdetermined linear equations:</p>
    <p>$$\boldsymbol{X}^{+}=\lim_{\alpha \searrow 0}\left(\boldsymbol{X}^{\top} \boldsymbol{X}+\alpha \boldsymbol{I}\right)^{-1} \boldsymbol{X}^{\top} \tag{7.29}$$</p>
    <p>we can now recognize the equation as <strong>performing linear regression with weight-decay</strong>.<br />
 Specifically, <script type="math/tex">7.29</script> is the limit of eq <script type="math/tex">7.17</script> as the <em>regularization coefficient shrinks to zero</em>.<br />
 We can thus interpret the pseudoinverse as <strong>stabilizing underdetermined problems using regularization</strong>.</p>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents3" id="bodyContents32">Dataset Augmentation:</strong><br />
 Having more data is the most desirable thing to improving a machine learning model’s performance. In many cases, it is relatively easy to artificially generate data.
    <ul>
      <li><strong>Applications</strong>: for certain problems like <strong>classification</strong> this approach is readily usable. E.g. for a classification task, we require the model to be <em>invariant to certain types of transformations</em>, of which we can generate data by applying them on our current dataset.<br />
  The most successful application of data-augmentation has been in <strong>object recognition</strong>.</li>
      <li><strong>Non-Applicable</strong>: this approach is not applicable to many problems, especially those that require us to learn the true data-distribution first E.g. Density Estimation.</li>
    </ul>

    <p><strong style="color: red">Noise Injection as Data-Augmentation:</strong><br />
 Injecting noise in the <em>input</em> to a NN <em>(Siestma and Dow, 1991)</em> can also be seen as a form of data augmentation.</p>
    <ul>
      <li><strong>Motivation:</strong>
        <ul>
          <li>For many classification and (some) regression tasks: the task should be possible to solve even if small random noise is added to the input <a href="/work_files/research/dl/theory/dl_book_pt1#bodyContents32">(Local Constancy)</a></li>
          <li>Moreover, NNs prove not to be very robust to noise.</li>
        </ul>
      </li>
    </ul>

    <p><strong>Injecting Noise in the Hidden Units:</strong><br />
 It can be seen as doing data-augmentation at <em><strong>multiple levels of abstraction</strong></em>. This approach can be highly effective provided that the magnitude of the noise is carefully tuned <em>(Poole et al. 2014)</em>.</p>
    <blockquote>
      <p><strong>Dropout</strong> can be seen as a process of constructing new inputs by <em>multiplying</em> by noise.</p>
    </blockquote>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents3" id="bodyContents33">Noise Robustness:</strong><br />
 We can apply <strong>Noise Injection</strong> to different components of the model as a way to regularize the model:<br />
 <strong style="color: red">Injecting Noise in the Input Layer:</strong>
    <ul>
      <li><strong>Motivation</strong>:<br />
  We have motivated the injection of noise, to the inputs, as a dataset augmentation strategy.</li>
      <li><strong>Interpretation</strong>:<br />
  For some models, the addition of noise with infinitesimal variance at the input of the model is equivalent to <strong>imposing a penalty on the norm of the weights</strong> <em>(Bishop, 1995a,b)</em>.</li>
    </ul>

    <p><strong style="color: red">Injecting Noise in the Hidden Layers:</strong></p>
    <ul>
      <li><strong>Interpretation</strong>:<br />
  It can be seen as doing <strong>data-augmentation</strong> at <em><strong>multiple levels of abstraction</strong></em>.</li>
      <li><strong>Applications</strong>:<br />
  The most successful application of this type of noise injection is <strong>Dropout</strong>.<br />
  It can be seen as a process of constructing new inputs by <em>multiplying</em> by noise.</li>
    </ul>

    <p><strong style="color: red">Injecting Noise in the Weight Matrices:</strong></p>
    <ul>
      <li><strong>Interpretation</strong>:
        <ol>
          <li>It can be interpreted as a stochastic implementation of Bayesian inference over the weights.
            <ul>
              <li><strong>The Bayesian View</strong>:<br />
  The Bayesian treatment of learning would consider the model weights to be <em>uncertain and representable via a probability distribution that reflects this uncertainty</em>. Adding noise to the weights is a practical, stochastic way to reflect this uncertainty.</li>
            </ul>
          </li>
          <li>It can, also, be interpreted as equivalent a more traditional form of regularization, <em>encouraging stability of the function to be learned</em>.
            <ul>
              <li><button class="showText" value="show" onclick="showTextPopHide(event);">Analysis</button>
  <img src="/main_files/dl_book/regularization/3.png" alt="img" width="100%" hidden="" /></li>
            </ul>
          </li>
        </ol>
      </li>
      <li><strong>Applications</strong>:<br />
  This technique has been used primarily in the context of <strong>recurrent neural networks</strong> <em>(Jim et al., 1996; Graves, 2011)</em>.</li>
    </ul>

    <p><strong style="color: red">Injecting Noise in the Output Layer:</strong></p>
    <ul>
      <li><strong>Motivation</strong>:
        <ul>
          <li>Most datasets have some number of mistakes in the <script type="math/tex">y</script> labels. It can be harmful to maximize <script type="math/tex">\log p(y | \boldsymbol{x})</script> when <script type="math/tex">y</script> is a mistake. One way to prevent this is to explicitly model the noise on the labels.<br />
  One can assume that for some small constant <script type="math/tex">\epsilon</script>, the training set label <script type="math/tex">y</script> is correct with probability <script type="math/tex">1-\epsilon</script>.<br />
  This assumption is easy to incorporate into the cost function analytically, rather than by explicitly drawing noise samples (e.g. <strong>label smoothing</strong>).</li>
          <li>MLE with a softmax classifier and hard targets may never converge - the softmax can never predict a probability of exactly <script type="math/tex">0</script> or <script type="math/tex">1</script>, so it will continue to learn larger and larger weights, making more extreme predictions forever.{: #bodyContents33mle}</li>
        </ul>
      </li>
      <li><strong>Interpretation</strong>:<br />
  For some models, the addition of noise with infinitesimal variance at the input of the</li>
      <li><strong>Applications</strong>:<br />
  <strong>Label Smoothing</strong> regularizes a model based on a softmax with <script type="math/tex">k</script> output values by replacing the hard <script type="math/tex">0</script> and <script type="math/tex">1</script> classification targets with targets of <script type="math/tex">\dfrac{\epsilon}{k-1}</script> and <script type="math/tex">1-\epsilon</script>, respectively.
        <ul>
          <li><a href="#bodyContents33mle"><strong>Applied to MLE problem:</strong></a> Label smoothing, compared to weight-decay, has the advantage of preventing the pursuit of hard probabilities without discouraging correct classification.</li>
          <li>Application in modern NN: <em>(Szegedy et al. 2015)</em></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents3" id="bodyContents34">Semi-Supervised Learning:</strong><br />
 <strong>Semi-Supervised Learning</strong> is a class of ML tasks and techniques that makes use of both unlabeled examples from <script type="math/tex">P(\mathbf{x})</script> and labeled examples from <script type="math/tex">P(\mathbf{x}, \mathbf{y})</script> to estimate <script type="math/tex">P(\mathbf{y} | \mathbf{x})</script> or predict <script type="math/tex">\mathbf{y}</script> from <script type="math/tex">\mathbf{x}</script>.</p>

    <p>In the context of Deep Learning, Semi-Supervised Learning usually refers to <em>learning a representation <script type="math/tex">\boldsymbol{h}=f(\boldsymbol{x})</script></em>; the goal being to learn a representation such that <strong>examples from the same class have similar representations</strong>. <br />
 Usually, <strong>Unsupervised Learning</strong> provides us clues (e.g. clustering) that influence the representation of the data.</p>
    <blockquote>
      <p><strong>PCA</strong>, as a preprocessing step before applying a classifier, is a long-standing variant of this approach.</p>
    </blockquote>

    <p><strong>Approach:</strong><br />
 Instead of separating the supervised and unsupervised criteria, we can instead have a generative model of <script type="math/tex">P(\mathbf{x})</script> (or <script type="math/tex">P(\mathbf{x}, \mathbf{y})</script>) which shares parameters with a discriminative model <script type="math/tex">P(\mathbf{y} \vert \mathbf{x})</script>.<br />
 The idea is to share the unsupervised/generative criterion with the supervised criterion to <em>express a prior belief that the structure of <script type="math/tex">P(\mathbf{x})</script> (or <script type="math/tex">P(\mathbf{x}, \mathbf{y})</script>) is connected to the structure of <script type="math/tex">P(\mathbf{y} \vert \mathbf{x})</script></em>, which is captured by the <em>shared parameters</em>.<br />
 By controlling how much of the generative criterion is included in the total criterion, one can find a better trade-off than with a purely generative or a purely discriminative training criterion <em>(Lasserre et al., 2006; Larochelle and Bengio, 2008)</em>.</p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents3" id="bodyContents35">Asynchronous:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents3" id="bodyContents36">Asynchronous:</strong></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents3" id="bodyContents37">Asynchronous:</strong></p>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents3" id="bodyContents38">Asynchronous:</strong></li>
</ol>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>Where we (Hadamard) define <strong>Well-Posed Problems</strong> as having the properties (1) A Solution Exists (2) It is Unique (3) It’s behavior changes continuously with the initial conditions. <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>More generally, we could regularize the parameters to be near any specific point in space and, surprisingly, still get a regularization effect, but better results will be obtained for a value closer to the true one, with zero being a default value that makes sense when we do not know if the correct value should be positive or negative. <a href="#fnref:2" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:3">
      <p>The approximation is perfect if the objective function is truly quadratic, as in the case of <strong>linear regression w/ MSE</strong>. <a href="#fnref:3" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>


      <footer class="site-footer">
    <!--   <span class="site-footer-owner"><a href="http://localhost:8889">Ahmad Badary</a> is maintained by <a href="http://ahmedbadary.ml">Ahmad Badary</a>.</span> -->
    
<!--  -->
    <div class="wrapper">
        <div class="footer-col-wrapper">
            <div class="footer-col footer-col-1">
            <span class="site-footer-owner"><a href="http://localhost:8889">Site</a> maintained by <a href="http://ahmedbadary.ml">Ahmad Badary</a>.</span>
    <span class="site-footer-credits">
        <p>
            &copy; 2017. All rights reserved.
        </p> 
    </span>
            </div>
            <div class="footer-col footer-col-2">
            <div><p>         </p></div>
            </div>
            <div class="footer-col footer-col-3">
                <ul class="social-media-list">
                    
                      <li>
                        <a href="https://github.com/AhmedBadary">
                          <i class="fa fa-github"></i> GitHub
                        </a>
                      </li>
                    
                    
                      <li>
                        <a href="https://linkedin.com/in/ahmad-badary-656098121/">
                          <i class="fa fa-linkedin"></i> LinkedIn
                        </a>
                      </li>
                    
                    
                      <li>
                        <a href="https://www.facebook.com/ahmed.thabet.94">
                          <i class="fa fa-facebook"></i> Facebook
                        </a>
                      </li>
                    
                </ul>
            </div>
        </div>
    </div>
<!--  -->
</footer>


    </section>

  </body>

<!-- Table of Content Script -->
<script type="text/javascript">
var bodyContents = $(".bodyContents1");
$("<ol>").addClass("TOC1ul").appendTo(".TOC1");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC1ul");
     });
// 
var bodyContents = $(".bodyContents2");
$("<ol>").addClass("TOC2ul").appendTo(".TOC2");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC2ul");
     });
// 
var bodyContents = $(".bodyContents3");
$("<ol>").addClass("TOC3ul").appendTo(".TOC3");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC3ul");
     });
//
var bodyContents = $(".bodyContents4");
$("<ol>").addClass("TOC4ul").appendTo(".TOC4");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC4ul");
     });
//
var bodyContents = $(".bodyContents5");
$("<ol>").addClass("TOC5ul").appendTo(".TOC5");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC5ul");
     });
//
var bodyContents = $(".bodyContents6");
$("<ol>").addClass("TOC6ul").appendTo(".TOC6");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC6ul");
     });
//
var bodyContents = $(".bodyContents7");
$("<ol>").addClass("TOC7ul").appendTo(".TOC7");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC7ul");
     });
//
var bodyContents = $(".bodyContents8");
$("<ol>").addClass("TOC8ul").appendTo(".TOC8");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC8ul");
     });
//
var bodyContents = $(".bodyContents9");
$("<ol>").addClass("TOC9ul").appendTo(".TOC9");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC9ul");
     });

</script>

<!-- VIDEO BUTTONS SCRIPT -->
<script type="text/javascript">
  function iframePopInject(event) {
    var $button = $(event.target);
    // console.log($button.parent().next());
    if ($button.attr('value') == 'show') {
        $button.attr('value', 'hide');
        $figure = $("<div>").addClass("video_container");
        $iframe = $("<iframe>").appendTo($figure);
        $iframe.attr("src", $button.attr("src"));
        // $iframe.attr("frameborder", "0");
        $iframe.attr("allowfullscreen", "true");
        $iframe.css("padding", "4px 6px");
        $button.next().css("display", "block");
        $figure.appendTo($button.next());
        $button.text("Hide Video")
    } else {
        $button.attr('value', 'show');
        $button.next().html("");
        $button.text("Show Video")
    }
}
</script>

<!-- BUTTON TRY -->
<script type="text/javascript">
  function iframePopA(event) {
    event.preventDefault();
    var $a = $(event.target).parent();
    console.log($a);
    if ($a.attr('value') == 'show') {
        $a.attr('value', 'hide');
        $figure = $("<div>");
        $iframe = $("<iframe>").addClass("popup_website_container").appendTo($figure);
        $iframe.attr("src", $a.attr("href"));
        $iframe.attr("frameborder", "1");
        $iframe.attr("allowfullscreen", "true");
        $iframe.css("padding", "4px 6px");
        $a.next().css("display", "block");
        $figure.appendTo($a.next().next());
        // $a.text("Hide Content")
        $('html, body').animate({
            scrollTop: $a.offset().top
        }, 1000);
    } else {
        $a.attr('value', 'show');
        $a.next().next().html("");
        // $a.text("Show Content")
    }

    $a.next().css("display", "inline");
}
</script>


<!-- TEXT BUTTON SCRIPT - INJECT -->
<script type="text/javascript">
  function showTextPopInject(event) {
    var $button = $(event.target);
    var txt = $button.attr("input");
    console.log(txt);
    if ($button.attr('value') == 'show') {
        $button.attr('value', 'hide');
        $p = $("<p>");
        $p.html(txt);
        $button.next().css("display", "block");
        $p.appendTo($button.next());
        $button.text("Hide Content")
    } else {
        $button.attr('value', 'show');
        $button.next().html("");
        $button.text("Show Content")
    }

}
</script>

<!-- TEXT BUTTON SCRIPT - HIDDEN / HIDE / SHOW / HIDE/SHOW -->
<script type="text/javascript">
  function showTextPopHide(event) {
    var $button = $(event.target);
    // var txt = $button.attr("input");
    var txt = $button.text();
    if ($button.attr('value') == 'show') {
        $button.attr('value', 'hide');
        $button.next().removeAttr("hidden");
        $button.text(txt + " - Hide Content");
    } else {
        $button.attr('value', 'show');
        $button.next().attr("hidden", "");
        $button.text(txt.replace(" - Hide Content",""));
    }
}
</script>

<!-- TEXT BUTTON SCRIPT - HIDDEN / HIDE / SHOW / HIDE/SHOW -->
<script type="text/javascript">
  function showText_withParent_PopHide(event) {
    var $button = $(event.target);
    var $parent = $button.parent();
    var txt = $button.text();
    if ($button.attr('value') == 'show') {
        $button.attr('value', 'hide');
        $parent.next().removeAttr("hidden");
        $button.text(txt + " - Hide Content");
    } else {
        $button.attr('value', 'show');
        $parent.next().attr("hidden", "");
        $button.text(txt.replace(" - Hide Content",""));
    }
}
</script>

<!-- Print / Printing / printme -->
<!-- <script type="text/javascript">
i = 0

for (var i = 1; i < 6; i++) {
    var bodyContents = $(".bodyContents" + i);
    $("<p>").addClass("TOC1ul")  .appendTo(".TOC1");
    bodyContents.each(function(index, element) {
        var paragraph = $(element);
        $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC1ul");
         });
} 
</script>
 -->
 
</html>

