<!DOCTYPE html>
<html lang="en-us">
  <head>
  <meta charset="UTF-8">
  <title>Ahmad Badary</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <link rel="stylesheet" href="/css/normalize.css">
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="/css/cayman.css">
  <link rel="stylesheet" href="/css/style.css">
  <link rel="shortcut icon" href="/main_files/favicon.ico" />
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="/css/customStyle.css">
  <title> » Ahmad Badary</title>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
</head>

  <body>
    <nav class="main-nav">
    <a href="https://ahmedbadary.github.io/" class="main-nav-logo">
        <img src="/main_files/logo.png">
    </a>
    <ul id="menu-main" class="main-nav-items">
        <li id="menu-item-1859" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-home menu-item-1859">
            <a href="/">Home</a>
        </li>
        <li id="menu-item-2869" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-2869">
            <a href="/work">Work</a>
        </li>
        <li id="menu-item-1892" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1892">
            <a href="/projects">Projects</a>
        </li>
        <li id="menu-item-1858" class="menu-item menu-item-type-post_type menu-item-object-page current_page_parent menu-item-1858">
            <a href="/blog">Blog</a>
        </li>
        <li id="menu-item-1862" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1862">
            <a href="/about">About</a>
        </li>
    </ul>
</nav>


<section class="page-header">
  <h1 class="project-name">Probability Theory <br /> Mathematics of Deep Learning</h1>
  <h2 class="project-tagline"></h2>
  <a href="/#" class="btn">Home</a>
  <a href="/work" class="btn">Work-Space</a>
  <a href= /work_files/research/dl/theory.html class="btn">Previous</a>
</section>

<!-- <div>
  <ul class="posts">
    
      <li><span>02 Jan 2014</span> &raquo; <a href="/2014/01/02/introducing-Ahmad/">Introducing Ahmad</a></li>
    
  </ul>
</div> -->


    <section class="main-content">
      
      <div class="TOC">
  <h1 id="table-of-contents">Table of Contents</h1>

  <ul class="TOC1">
    <li><a href="#content1">Motivation</a></li>
  </ul>
  <ul class="TOC2">
    <li><a href="#content2">Basics</a></li>
  </ul>
  <!--   * [THIRD](#content3)
  {: .TOC3} -->
  <ul class="TOC9">
    <li><a href="#content9">Discrete Distributions</a></li>
  </ul>
  <ul class="TOC10">
    <li><a href="#content10">Notes, Tips, and Tricks</a></li>
  </ul>
</div>

<hr />
<hr />

<p><a href="https://www.countbayesie.com">COUNT BAYESIE: PROBABLY A PROBABILITY BLOG</a><br />
<a href="http://cs229.stanford.edu/section/cs229-prob.pdf">Review of Probability Theory (Stanford)</a><br />
<a href="http://julio.staff.ipb.ac.id/files/2015/02/Ross_8th_ed_English.pdf">A First Course in Probability (Book: <em>Sheldon Ross</em>)</a><br />
<a href="https://www.youtube.com/playlist?list=PL2SOU6wwxB0uwwH80KTQ6ht66KWxbzTIo">Statistics 110: Harvard</a><br />
<a href="https://www.youtube.com/playlist?list=PLR6O_WZHBlOELxOrXlzB1LCXd2cUIXkkm">Lecture Series on Probability (following DL-book)</a><br />
<a href="https://www.quora.com/What-is-the-probability-statistics-topic-FAQ">Probability Quora FAQs</a><br />
<a href="https://projects.iq.harvard.edu/files/stat110/files/math_review_handout.pdf">Math review for Stat 110</a><br />
<a href="https://jhui.github.io/2017/01/05/Deep-learning-probability-and-distribution/">Deep Learning Probability</a><br />
<a href="http://bjlkeng.github.io/posts/probability-the-logic-of-science/">Probability as Extended Logic</a><br />
<a href="https://www.youtube.com/watch?v=sMNbLXsvRig&amp;list=PL7k0r4t5c108AZRwfW-FhnkZ0sCKBChLH&amp;index=13&amp;t=0s">CS188 Probability Lecture (very intuitive)</a><br />
<a href="https://www.dartmouth.edu/~chance/teaching_aids/books_articles/probability_book/Chapter3.pdf">Combinatorics (Notes)</a><br />
<a href="https://www.statlect.com/">Digital textbook on probability and statistics (!)</a></p>

<h2 id="content1">Motivation</h2>

<ol>
  <li><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents11">Uncertainty in General Systems and the need for a Probabilistic Framework:</strong>
    <ol>
      <li><strong>Inherent stochasticity in the system being modeled:</strong><br />
 Take Quantum Mechanics, most interpretations of quantum mechanics describe the dynamics of sub-atomic particles as being probabilistic.</li>
      <li><strong>Incomplete observability</strong>:<br />
 Deterministic systems can appear stochastic when we cannot observe all the variables that drive the behavior of the system.
        <blockquote>
          <p>i.e. Point-of-View determinism (Monty-Hall)</p>
        </blockquote>
      </li>
      <li><strong>Incomplete modeling</strong>:<br />
 Building a system that makes strong assumptions about the problem and discards (observed) information result in uncertainty in the predictions.  <br />
 <br /></li>
    </ol>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents12">Bayesian Probabilities and Frequentist Probabilities:</strong><br />
 <strong>Frequentist Probabilities</strong> describe the predicted number of times that a <strong>repeatable</strong> process will result in a given output in an absolute scale.</p>

    <p><strong>Bayesian Probabilities</strong> describe the <em>degree of belief</em> that a certain <strong>non-repeatable</strong> event is going to result in a given output, in an absolute scale.</p>

    <p>We assume that <strong>Bayesian Probabilities</strong> behaves in exactly the same way as <strong>Frequentist Probabilities</strong>.<br />
 This assumption is derived from a set of <em>“common sense”</em> arguments that end in the logical conclusion that both approaches to probabilities must behave the same way - <a href="https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/ramseyfp/ramsess.pdf">Truth and probability (Ramsey 1926)</a>.</p>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents1" id="bodyContents13">Probability as an extension of Logic:</strong><br />
 “Probability can be seen as the extension of logic to deal with uncertainty. Logic provides a set of formal rules for determining what propositions are implied to be true or false given the assumption that some other set of propositions is true or false. Probability theory provides a set of formal rules for determining the likelihood of a proposition being true given the likelihood of other propositions.” - deeplearningbook p.54</li>
</ol>

<hr />

<h2 id="content2">Basics</h2>

<ol>
  <li><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents20">Elements of Probability:</strong>
    <ul>
      <li><strong>Sample Space \(\Omega\)</strong>: The set of all the outcomes of a stochastic experiment; where each <em>outcome</em> is a complete description of the state of the real world at the end of the experiment.</li>
      <li><strong>Event Space \({\mathcal {F}}\)</strong>: A set of <em>events</em>; where each event \(A \in \mathcal{F}\) is a subset of the sample space \(\Omega\) - it is a collection of possible outcomes of an experiment.</li>
      <li><strong>Probability Measure \(\operatorname {P}\)</strong>: A function \(\operatorname {P}: \mathcal{F} \rightarrow \mathbb{R}\) that satisfies the following properties:
        <ul>
          <li>\(\operatorname {P}(A) \geq 0, \: \forall A \in \mathcal{f}\),</li>
          <li>\(\operatorname {P}(\Omega) = 1\), \(\operatorname {P}(\emptyset) = 0\)<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup></li>
          <li>\({\displaystyle \operatorname {P}(\bigcup_i A_i) = \sum_i \operatorname {P}(A_i) }\), where \(A_1, A_2, ...\) are <a href="#bodyContents102"><em>disjoint</em> events</a></li>
        </ul>
      </li>
    </ul>

    <p><strong style="color: red">Properties:</strong></p>
    <ul>
      <li>\({\text { If } A \subseteq B \Longrightarrow P(A) \leq P(B)}\),</li>
      <li>\({P(A \cap B) \leq \min (P(A), P(B))}\),</li>
      <li><strong>Union Bound:</strong> \({P(A \cup B) \leq P(A)+P(B)}\)</li>
      <li>\({P(\Omega \backslash A)=1-P(A)}\).</li>
      <li><strong>Law of Total Probability (LOTB):</strong> \(\text { If } A_{1}, \ldots, A_{k} \text { are a set of disjoint events such that } \cup_{i=1}^{k} A_{i}=\Omega, \text { then } \sum_{i=1}^{k} P\left(A_{k}\right)=1\)</li>
      <li><strong>Inclusion-Exclusion Principle</strong>:
        <p>$$\mathbb{P}\left(\bigcup_{i=1}^{n} A_{i}\right)=\sum_{i=1}^{n} \mathbb{P}\left(A_{i}\right)-\sum_{i&lt; j} \mathbb{P}\left(A_{i} \cap A_{j}\right)+\sum_{i&lt; j &lt; k} \mathbb{P}\left(A_{i} \cap A_{j} \cap A_{k}\right)-\cdots+(-1)^{n-1} \sum_{i&lt; \ldots&lt; n} \mathbb{P}\left(\bigcap_{i=1}^{n} A_{i}\right)$$</p>
        <ul>
          <li><a href="https://www.youtube.com/embed/LZ5Wergp_PA?start=2057" value="show" onclick="iframePopA(event)"><strong>Example 110</strong></a>
  <a href="https://www.youtube.com/embed/LZ5Wergp_PA?start=2057"></a>
            <div></div>
          </li>
        </ul>
      </li>
      <li><a href="https://www.youtube.com/embed/LZ5Wergp_PA?start=1359" value="show" onclick="iframePopA(event)"><strong>Properties and Proofs 110</strong></a>
 <a href="https://www.youtube.com/embed/LZ5Wergp_PA?start=1359"></a>
        <div></div>
      </li>
    </ul>
  </li>
</ol>

<ol>
  <li><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents21">Random Variables:</strong><br />
 A <strong>Random Variable</strong> is a variable that can take on different values randomly.<br />
 Formally, a random variable \(X\) is a <em>function</em> that maps outcomes to numerical quantities (labels), typically real numbers:
    <p>$${\displaystyle X\colon \Omega \to \mathbb{R}}$$</p>

    <p>Think of a R.V.: as a numerical “summary” of an aspect of the experiment.</p>

    <p><strong>Types</strong>:</p>
    <ul>
      <li><em><strong>Discrete</strong></em>: is a variable that has a finite or countably infinite number of states</li>
      <li><em><strong>Continuous</strong></em>: is a variable that is a real value</li>
    </ul>

    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>Bernoulli:</strong> A r.v. \(X\) is said to have a <strong>Bernoulli</strong> distribution if \(X\) has only \(2\) possible values, \(0\) and \(1\), and \(P(X=1) = p, P(X=0) = 1-p\); denoted \(\text{Bern}(p)\).</li>
      <li><strong>Binomial</strong>: The distr. of #successes in \(n\) independent <strong>\(\text{Bern}(p)\)</strong> trials and its distribution is \(P(X=k) = \left(\begin{array}{l}{n} \\ {k}\end{array}\right) p^k (1-p)^{n-k}\); denoted \(\text{Bin}(n, p)\).        <br />
 <br /></li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents22">Probability Distributions:</strong><br />
 A <strong>Probability Distribution</strong> is a function that describes the likelihood that a random variable (or a set of r.v.) will take on each of its possible states.<br />
 Probability Distributions are defined in terms of the <strong>Sample Space</strong>.
    <ul>
      <li><strong>Classes</strong>:
        <ul>
          <li><em><strong>Discrete Probability Distribution:</strong></em> is encoded by a discrete list of the probabilities of the outcomes, known as a <strong>Probability Mass Function (PMF)</strong>.</li>
          <li><em><strong>Continuous Probability Distribution:</strong></em> is described by a <strong>Probability Density Function (PDF)</strong>.</li>
        </ul>
      </li>
      <li><strong>Types</strong>:
        <ul>
          <li><em><strong>Univariate Distributions:</strong></em> are those whose sample space is \(\mathbb{R}\).<br />
  They give the probabilities of a single random variable taking on various alternative values</li>
          <li><em><strong>Multivariate Distributions</strong></em> (also known as <em><strong>Joint Probability distributions</strong></em>):  are those whose sample space is a vector space. <br />
  They give the probabilities of a random vector taking on various combinations of values.</li>
        </ul>
      </li>
    </ul>

    <p>A <strong>Cumulative Distribution Function (CDF)</strong>: is a general functional form to describe a probability distribution:</p>
    <p>$${\displaystyle F(x)=\operatorname {P} [X\leq x]\qquad {\text{ for all }}x\in \mathbb {R} .}$$</p>
    <blockquote>
      <p>Because a probability distribution P on the real line is determined by the probability of a scalar random variable X being in a half-open interval \((−\infty, x]\), the probability distribution is completely characterized by its cumulative distribution function (i.e. one can calculate the probability of any event in the event space)</p>
    </blockquote>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents23">Probability Mass Function:</strong><br />
 A <strong>Probability Mass Function (PMF)</strong> is a function (probability distribution) that gives the probability that a discrete random variable is exactly equal to some value.<br />
 <strong>Mathematical Definition</strong>:<br />
 Suppose that \(X: S \rightarrow A, \:\:\: (A {\displaystyle \subseteq }  \mathbb{R})\) is a discrete random variable defined on a sample space \(S\). Then the probability mass function \(f_X: A \rightarrow [0, 1]\) for \(X\) is defined as:
    <p>$$p_{X}(x)=P(X=x)=P(\{s\in S:X(s)=x\})$$</p>
    <p>The <strong>total probability for all hypothetical outcomes \(x\) is always conserved</strong>:</p>
    <p>$$\sum _{x\in A}p_{X}(x)=1$$</p>
    <p><strong>Joint Probability Distribution</strong> is a PMF over many variables, denoted \(P(\mathrm{x} = x, \mathrm{y} = y)\) or \(P(x, y)\).</p>

    <p>A <strong>PMF</strong> must satisfy these properties:</p>
    <ul>
      <li>The domain of \(P\) must be the set of all possible states of \(\mathrm{x}\).</li>
      <li>\(\forall x \in \mathrm{x}, \: 0 \leq P(x) \leq 1\). Impossible events has probability \(0\). Guaranteed events have probability \(1\).</li>
      <li>\({\displaystyle \sum_{x \in \mathrm{x}} P(x) = 1}\), i.e. the PMF must be normalized.<br />
 <br /></li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents24">Probability Density Function:</strong><br />
 A <strong>Probability Density Function (PDF)</strong> is a function (probability distribution) whose value at any given sample (or point) in the sample space can be interpreted as providing a relative likelihood that the value of the random variable would equal that sample.<br />
 The <strong>PDF</strong> is defined as the <em>derivative</em> of the <strong>CDF</strong>:
    <p>$$f_{X}(x) = \dfrac{dF_{X}(x)}{dx}$$</p>
    <p>A Probability Density Function \(p(x)\) does not give the probability of a specific state directly; instead the probability of landing inside an infinitesimal region with volume \(\delta x\) is given by \(p(x)\delta x\).<br />
 We can integrate the density function to find the actual probability mass of a set of points. Specifically, the probability that \(x\) lies in some set \(S\) is given by the integral of \(p(x)\) over that set.</p>
    <blockquote>
      <p>In the <strong>Univariate</strong> example, the probability that \(x\) lies in the interval \([a, b]\) is given by \(\int_{[a, b]} p(x)dx\)</p>
    </blockquote>

    <p>A <strong>PDF</strong> must satisfy these properties:</p>
    <ul>
      <li>The domain of \(P\) must be the set of all possible states of \(x\).</li>
      <li>\(\forall x \in \mathrm{x}, \: 0 \leq P(x) \leq 1\). Impossible events has probability \(0\). Guaranteed events have probability \(1\).</li>
      <li>\(\int p(x)dx = 1\), i.e. the integral of the PDF must be normalized.<br />
 <br /></li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents244">Cumulative Distribution Function:</strong><br />
A <strong>Cumulative Distribution Function (CDF)</strong> is a function (probability distribution) of a real-valued random variable \(X\), or just distribution function of \(X\), evaluated at \(x\), is the probability that \(X\) will take a value less than or equal to \(x\).
    <p>$$F_{X}(x)=\operatorname {P} (X\leq x)$$ </p>
    <p>The probability that \(X\) lies in the semi-closed interval \((a, b]\), where \(a  &lt;  b\), is therefore</p>
    <p>$${\displaystyle \operatorname {P} (a&lt;X\leq b)=F_{X}(b)-F_{X}(a).}$$</p>

    <p><strong>Properties</strong>:</p>
    <ul>
      <li>\(0 \leq F(x) \leq 1\),</li>
      <li>\(\lim_{x \rightarrow -\infty} F(x) = 0\),</li>
      <li>\(\lim_{x \rightarrow \infty} F(x) = 1\),</li>
      <li>\(x \leq y \implies F(x) \leq F(y)\).<br />
<br /></li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents25">Marginal Probability:</strong><br />
 The <strong>Marginal Distribution</strong> of a subset of a collection of random variables is the probability distribution of the variables contained in the subset.<br />
 <strong>Two-variable Case</strong>:<br />
 Given two random variables \(X\) and \(Y\) whose joint distribution is known, the marginal distribution of \(X\) is simply the probability distribution of \(X\) averaging over information about \(Y\).
    <ul>
      <li><strong>Discrete</strong>:
        <p>$${\displaystyle \Pr(X=x)=\sum_ {y}\Pr(X=x,Y=y)=\sum_ {y}\Pr(X=x\mid Y=y)\Pr(Y=y)}$$</p>
      </li>
      <li><strong>Continuous</strong>:
        <p>$${\displaystyle p_{X}(x)=\int _{y}p_{X,Y}(x,y)\,\mathrm {d} y=\int _{y}p_{X\mid Y}(x\mid y)\,p_{Y}(y)\,\mathrm {d} y}$$</p>
      </li>
      <li><em><strong>Marginal Probability as Expectation</strong></em>:</li>
    </ul>
    <p>$${\displaystyle p_{X}(x)=\int _{y}p_{X\mid Y}(x\mid y)\,p_{Y}(y)\,\mathrm {d} y=\mathbb {E} _{Y}[p_{X\mid Y}(x\mid y)]}$$</p>
    <p><button class="showText" value="show" onclick="showTextPopHide(event);">Intuitive Explanation</button>
 <img src="/main_files/math/prob/1.png" alt="img" width="100%" hidden="" /></p>

    <p><strong style="color: red">Marginalization:</strong> the process of forming the marginal distribution with respect to one variable by summing out the other variable</p>

    <p id="lst-p"><strong style="color: red">Notes:</strong></p>
    <ul>
      <li><strong>Marginal Distribution of a variable</strong>: is just the prior distr of the variable</li>
      <li><strong>Marginal Likelihood</strong>: also known as the evidence, or model evidence, is the denominator of the Bayes equation. Its only role is to guarantee that the posterior is a valid probability by making its area sum to 1.<br />
  <img src="https://cdn.mathpix.com/snip/images/UPUhBUhhUivvvIHO3nt5S52UcqPkSMS_eZEg3mhDXhk.original.fullsize.png" alt="Example" /></li>
      <li><strong>both terms above are the same</strong></li>
      <li><strong>Marginal Distr VS Prior</strong>:
        <ul>
          <li><a href="https://stats.stackexchange.com/questions/249275/whats-the-difference-between-prior-and-marginal-probabilities?rq=1">Discussion</a></li>
          <li><strong>Summary</strong>:<br />
  Basically, it’s a conceptual difference.<br />
  The prior, denoted \(p(\theta)\), denotes the probability of some event 𝜔 even before any data has been taken.<br />
  A marginal distribution is rather different. You hold a variable value and integrate over the unknown values.<br />
  But, in some contexts they are the same.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents26">Conditional Probability:</strong><br />
 <strong>Conditional Probability</strong> is a measure of the probability of an event given that another event has occurred.<br />
 Conditional Probability is only defined when \(P(x) &gt; 0\) - We cannot compute the conditional probability conditioned on an event that never happens. <br />
 <strong>Definition</strong>:
    <p>$$P(A|B)={\frac {P(A\cap B)}{P(B)}} = {\frac {P(A, B)}{P(B)}}$$</p>

    <blockquote>
      <p>Intuitively, it is a way of updating your beliefs/probabilities given new evidence. It’s inherently a sequential process.</p>
    </blockquote>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents27">The Chain Rule of Conditional Probability:</strong><br />
 Any joint probability distribution over many random variables may be decomposed into conditional distributions over only one variable.<br />
 The chain rule permits the calculation of any member of the joint distribution of a set of random variables using only conditional probabilities:
    <p>$$\mathrm {P} \left(\bigcap _{k=1}^{n}A_{k}\right)=\prod _{k=1}^{n}\mathrm {P} \left(A_{k}\,{\Bigg |}\,\bigcap _{j=1}^{k-1}A_{j}\right)$$</p>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents28">Independence and Conditional Independence:</strong><br />
 Two random variables \(x\) and \(y\) (or events ) are <strong>independent</strong> if their probability distribution can be expressed as a product of two factors, one involving only \(x\) and one involving only \(y\):
    <p>$$\mathrm{P}(A \cap B) = \mathrm{P}(A)\mathrm{P}(B)$$</p>

    <p>Two random variables \(A\) and \(B\) are <strong>conditionally independent</strong> <em>given a random variable \(Y\)</em> if the conditional probability distribution over \(A\) and \(B\) factorizes in this way for every value of \(Y\):</p>
    <p>$$\Pr(A\cap B\mid Y)=\Pr(A\mid Y)\Pr(B\mid Y)$$</p>
    <p>or equivalently,</p>
    <p>$$\Pr(A\mid B\cap Y)=\Pr(A\mid Y)$$</p>
    <blockquote>
      <p>In other words, \(A\) and \(B\) are conditionally independent given \(Y\) if and only if, given knowledge that \(Y\) occurs, knowledge of whether \(A\) occurs provides no information on the likelihood of \(B\) occurring, and knowledge of whether \(B\) occurs provides no information on the likelihood of \(A\) occurring.</p>
    </blockquote>

    <p><strong style="color: red">Pairwise VS Mutual Independence:</strong></p>
    <ul>
      <li><strong>Pairwise</strong>:
        <p>$$\mathrm{P}\left(A_{m} \cap A_{k}\right)=\mathrm{P}\left(A_{m}\right) \mathrm{P}\left(A_{k}\right)$$</p>
      </li>
      <li><strong>Mutual Independence:</strong>
        <p>$$\mathrm{P}\left(\bigcap_{i=1}^{k} B_{i}\right)=\prod_{i=1}^{k} \mathrm{P}\left(B_{i}\right)$$</p>
        <p>for <em><strong>all subsets</strong></em> of size \(k \leq n\)</p>
      </li>
    </ul>

    <p><strong>Pairwise</strong> independence does <strong>not</strong> imply <strong>mutual</strong> independence, but the other way around is TRUE (by definition).</p>

    <p><strong>Notation:</strong></p>
    <ul>
      <li><em><strong>\(A\) is Independent from \(B\)</strong></em>:  \(A{\perp}B\)</li>
      <li><em><strong>\(A\) and \(B\) are conditionally Independent given \(Y\)</strong></em>:  \(A{\perp}B \:\vert Y\)</li>
    </ul>

    <p id="lst-p"><strong style="color: red">Notes:</strong></p>
    <ul>
      <li>Unconditional Independence is very rare (there is usually some hidden factor influencing the interaction between the two events/variables)</li>
      <li><em>Conditional Independence</em> is the most basic and robust form of knowledge about uncertain environments</li>
    </ul>

    <p><br /></p>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents29">Expectation:</strong><br />
 The <strong>expectation</strong>, or <strong>expected value</strong>, of some function \(f(x)\) with respect to a probability distribution \(P(x)\) is the <em>“theoretical”</em> average, or mean value, that \(f\) takes on when \(x\) is drawn from \(P\).
    <blockquote>
      <p>The Expectation of a R.V. is a weighted average of the values \(x\) that the R.V. can take – \(\operatorname {E}[X] = \sum_{x \in X} x \cdot p(x)\)</p>
    </blockquote>
    <ul>
      <li><strong>Discrete case</strong>:
        <p>$${\displaystyle \operatorname {E}_{x \sim P} [f(X)]=f(x_{1})p(x_{1})+f(x_{2})p(x_{2})+\cdots +f(x_{k})p(x_{k})} = \sum_x P(x)f(x)$$</p>
      </li>
      <li><strong>Continuous case</strong>:</li>
    </ul>
    <p>$${\displaystyle \operatorname {E}_ {x \sim P} [f(X)] = \int p(x)f(x)dx}$$</p>
    <p><strong>Linearity of Expectation:</strong></p>
    <p>$${\displaystyle {\begin{aligned}\operatorname {E} [X+Y]&amp;=\operatorname {E} [X]+\operatorname {E} [Y],\\[6pt]\operatorname {E} [aX]&amp;=a\operatorname {E} [X],\end{aligned}}}$$</p>
    <p><strong>Independence:</strong> <br />
 If \(X\) and \(Y\) are independent \(\implies \operatorname {E} [XY] = \operatorname {E} [X] \operatorname {E} [Y]\)<br />
 <br /></p>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents210">Variance:</strong><br />
<strong>Variance</strong> is the expectation of the squared deviation of a random variable from its mean.<br />
It gives a measure of how much the values of a function of a random variable \(x\) vary as we sample different values of \(x\) from its probability distribution:
    <p>$$\operatorname {Var} (f(x))=\operatorname {E} \left[(f(x)-\mu )^{2}\right] = \sum_{x \in X} (x - \mu)^2 \cdot p(x)$$</p>
    <p><strong>Variance expanded</strong>:</p>
    <p>$${\displaystyle {\begin{aligned}\operatorname {Var} (X)&amp;=\operatorname {E} \left[(X-\operatorname {E} [X])^{2}\right]\\
    &amp;=\operatorname {E} \left[X^{2}-2X\operatorname {E} [X]+\operatorname {E} [X]^{2}\right]\\
    &amp;=\operatorname {E} \left[X^{2}\right]-2\operatorname {E} [X]\operatorname {E} [X]+\operatorname {E} [X]^{2}\\
    &amp;=\operatorname {E} \left[X^{2}\right]-\operatorname {E} [X]^{2}\end{aligned}}}$$  </p>
    <p><strong>Variance as Covariance</strong>: 
Variance can be expressed as the covariance of a random variable with itself:</p>
    <p>$$\operatorname {Var} (X)=\operatorname {Cov} (X,X)$$</p>

    <p id="lst-p"><strong>Properties:</strong></p>
    <ul>
      <li>\(\operatorname {Var} [a] = 0, \forall a \in \mathbb{R}\) (constant \(a\))</li>
      <li>\(\operatorname {Var} [af(X)] = a^2 \operatorname {Var} [f(X)]\) (constant \(a\))</li>
      <li>\(\operatorname {Var} [X + Y] = a^2 \operatorname {Var} [X] + \operatorname {Var} [Y] + 2 \operatorname {Cov} [X, Y]\).</li>
    </ul>

    <p id="lst-p"><strong style="color: red">Notes:</strong></p>
    <ul>
      <li>When comparing Variances, <em><strong>ALWAYS NORMALIZE FIRST</strong></em>: Variance depends on Scale<br />
<br /></li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents211">Standard Deviation:</strong><br />
The <strong>Standard Deviation</strong> is a measure that is used to quantify the amount of variation or dispersion of a set of data values.<br />
It is defined as the square root of the variance:
    <p>$${\displaystyle {\begin{aligned}\sigma &amp;={\sqrt {\operatorname {E} [(X-\mu )^{2}]}}\\&amp;={\sqrt {\operatorname {E} [X^{2}]+\operatorname {E} [-2\mu X]+\operatorname {E} [\mu ^{2}]}}\\&amp;={\sqrt {\operatorname {E} [X^{2}]-2\mu \operatorname {E} [X]+\mu ^{2}}}\\&amp;={\sqrt {\operatorname {E} [X^{2}]-2\mu ^{2}+\mu ^{2}}}\\&amp;={\sqrt {\operatorname {E} [X^{2}]-\mu ^{2}}}\\&amp;={\sqrt {\operatorname {E} [X^{2}]-(\operatorname {E} [X])^{2}}}\end{aligned}}}$$</p>

    <p><strong>Properties:</strong></p>
    <ul>
      <li>68% of the data-points lie within \(1 \cdot \sigma\)s from the mean</li>
      <li>95% of the data-points lie within \(2 \cdot \sigma\)s from the mean</li>
      <li>99% of the data-points lie within \(3 \cdot \sigma\)s from the mean
<br /></li>
    </ul>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents212">Covariance:</strong><br />
<strong>Covariance</strong> is a measure of the joint variability of two random variables.<br />
It gives some sense of how much two values are linearly related to each other, as well as the scale of these variables:
    <p>$$\operatorname {cov} (X,Y)=\operatorname {E} { {\big[ }(X-\operatorname {E} [X])(Y-\operatorname {E} [Y]){ \big] } }$$ </p>
    <p><strong>Covariance expanded:</strong></p>
    <p>$${\displaystyle {\begin{aligned}\operatorname {cov} (X,Y)&amp;=\operatorname {E} \left[\left(X-\operatorname {E} \left[X\right]\right)\left(Y-\operatorname {E} \left[Y\right]\right)\right]\\&amp;=\operatorname {E} \left[XY-X\operatorname {E} \left[Y\right]-\operatorname {E} \left[X\right]Y+\operatorname {E} \left[X\right]\operatorname {E} \left[Y\right]\right]\\&amp;=\operatorname {E} \left[XY\right]-\operatorname {E} \left[X\right]\operatorname {E} \left[Y\right]-\operatorname {E} \left[X\right]\operatorname {E} \left[Y\right]+\operatorname {E} \left[X\right]\operatorname {E} \left[Y\right]\\&amp;=\operatorname {E} \left[XY\right]-\operatorname {E} \left[X\right]\operatorname {E} \left[Y\right].\end{aligned}}}$$ </p>
    <blockquote>
      <p>when \({\displaystyle \operatorname {E} [XY]\approx \operatorname {E} [X]\operatorname {E} [Y]}\), this last equation is prone to catastrophic cancellation when computed with floating point arithmetic and thus should be avoided in computer programs when the data has not been centered before.</p>
    </blockquote>

    <p><strong>Covariance of Random Vectors</strong>:</p>
    <p>$${\begin{aligned}\operatorname {cov} (\mathbf {X} ,\mathbf {Y} )&amp;=\operatorname {E} \left[(\mathbf {X} -\operatorname {E} [\mathbf {X} ])(\mathbf {Y} -\operatorname {E} [\mathbf {Y} ])^{\mathrm {T} }\right]\\&amp;=\operatorname {E} \left[\mathbf {X} \mathbf {Y} ^{\mathrm {T} }\right]-\operatorname {E} [\mathbf {X} ]\operatorname {E} [\mathbf {Y} ]^{\mathrm {T} },\end{aligned}}$$ </p>

    <p><strong>The Covariance Matrix</strong> of a random vector \(x \in \mathbb{R}^n\) is an \(n \times n\) matrix, such that:</p>
    <p>$$ \operatorname {cov} (X)_ {i,j} = \operatorname {cov}(x_i, x_j) \\
    \operatorname {cov}(x_i, x_j) = \operatorname {Var} (x_i)$$</p>
    <p><strong>Interpretations</strong>:</p>
    <ul>
      <li>High absolute values of the covariance mean that the values change very much and are both far from their respective means at the same time.</li>
      <li><strong>The sign of the covariance</strong>: <br />
  The sign of the covariance shows the tendency in the linear relationship between the variables:
        <ul>
          <li><em><strong>Positive</strong></em>:<br />
  the variables tend to show similar behavior</li>
          <li><em><strong>Negative</strong></em>:<br />
  the variables tend to show opposite behavior</li>
          <li><strong>Reason</strong>:<br />
  If the greater values of one variable mainly correspond with the greater values of the other variable, and the same holds for the lesser values, (i.e., the variables tend to show similar behavior), the covariance is positive. In the opposite case, when the greater values of one variable mainly correspond to the lesser values of the other, (i.e., the variables tend to show opposite behavior), the covariance is negative.</li>
        </ul>
      </li>
    </ul>

    <p><strong>Covariance and Variance:</strong></p>
    <p>$$\operatorname{Var}[X+Y]=\operatorname{Var}[X]+\operatorname{Var}[Y]+2 \operatorname{Cov}[X, Y]$$</p>

    <p><strong>Covariance and Independence:</strong><br />
If \(X\) and \(Y\) are independent \(\implies \operatorname{cov}[X, Y]=\mathrm{E}[X Y]-\mathrm{E}[X] \mathrm{E}[Y] = 0\).</p>
    <ul>
      <li>Independence \(\Rightarrow\) Zero Covariance</li>
      <li>Zero Covariance \(\nRightarrow\) Independence</li>
    </ul>

    <p><strong>Covariance and Correlation:</strong><br />
If \(\operatorname{Cov}[X, Y]=0 \implies\) \(X\) and \(Y\) are <strong>Uncorrelated</strong>.</p>

    <ul>
      <li><a href="https://www.youtube.com/embed/KDw3hC2YNFc" value="show" onclick="iframePopA(event)"><strong>Covariance/Correlation Intuition</strong></a>
<a href="https://www.youtube.com/embed/KDw3hC2YNFc"></a>
        <div></div>
      </li>
      <li><a href="https://www.youtube.com/embed/IujCYxtpszU" value="show" onclick="iframePopA(event)"><strong>Covariance and Correlation (Harvard Lecture)</strong></a>
<a href="https://www.youtube.com/embed/IujCYxtpszU"></a>
        <div></div>
      </li>
      <li><a href="https://www.youtube.com/embed/ualmyZiPs9w" value="show" onclick="iframePopA(event)"><strong>Covariance as slope of the Regression Line</strong></a>
<a href="https://www.youtube.com/embed/ualmyZiPs9w"></a>
        <div></div>
      </li>
    </ul>

    <p><br /></p>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents213">Mixtures of Distributions:</strong><br />
It is also common to define probability distributions by combining other simpler probability distributions. One common way of combining distributions is to construct a <strong>mixture distribution</strong>.  <br />
A <strong>Mixture Distribution</strong> is the probability distribution of a random variable that is derived from a collection of other random variables as follows: first, a random variable is selected by chance from the collection according to given probabilities of selection, and then the value of the selected random variable is realized.  <br />
On each trial, the choice of which component distribution should generate the sample is determined by sampling a component identity from a multinoulli distribution:
    <p>$$P(x) = \sum_i P(x=i)P(x \vert c=i)$$</p>
    <p>where \(P(c)\) is the multinoulli distribution over component identities.</p>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents214">Bayes’ Rule:</strong><br />
<strong>Bayes’ Rule</strong> describes the probability of an event, based on prior knowledge of conditions that might be related to the event.
    <p>$${\displaystyle P(A\mid B)={\frac {P(B\mid A)\,P(A)}{P(B)}}}$$</p>
    <p>where,</p>
    <p>$$P(B) =\sum_A P(B \vert A) P(A)$$</p>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents215">Common Random Variables:</strong><br />
<strong style="color: red">Discrete RVs:</strong>
    <ul>
      <li><strong>Bernoulli</strong>:<br />
<img src="/main_files/math/prob/2.png" alt="img" width="90%" /></li>
      <li><strong>Binomial</strong>:<br />
<img src="/main_files/math/prob/3.png" alt="img" width="90%" /></li>
      <li><strong>Geometric</strong>:<br />
<img src="/main_files/math/prob/4.png" alt="img" width="90%" /></li>
      <li><strong>Poisson</strong>:<br />
<img src="/main_files/math/prob/5.png" alt="img" width="90%" /></li>
    </ul>

    <p id="lst-p"><strong style="color: red">Continuous RVs:</strong></p>
    <ul>
      <li><strong>Uniform</strong>:<br />
<img src="/main_files/math/prob/6.png" alt="img" width="90%" /></li>
      <li><strong>Exponential</strong>:<br />
<img src="/main_files/math/prob/7.png" alt="img" width="90%" /></li>
      <li><strong>Normal/Gaussian</strong>:<br />
<img src="/main_files/math/prob/8.png" alt="img" width="90%" /></li>
    </ul>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents216">Summary of Distributions:</strong><br />
<img src="/main_files/math/prob/9.png" alt="img" width="80%" /></p>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents217">Formulas:</strong>
    <ul>
      <li>\(\overline{X} = \hat{\mu}\),</li>
      <li>\(\operatorname {E}[\overline{X}]=\operatorname {E}\left[\frac{X_{1}+\cdots+X_{n}}{n}\right] = \mu\),</li>
      <li>\(\operatorname{Var}[\overline{X}]=\operatorname{Var}\left[\frac{X_{1}+\cdots+X_{n}}{n}\right] = \dfrac{\sigma^2}{n}\),</li>
      <li>\(\operatorname {E}\left[X_{i}^{2}\right]=\operatorname {Var} [X]+\operatorname {E} [X]^{2} = \sigma^{2}+\mu^{2}\),</li>
      <li>\(\operatorname {E}\left[\overline{X}^{2}\right]=\operatorname {E}\left[\hat{\mu}^{2}\right]=\frac{\sigma^{2}}{n}+\mu^{2}\:\), <sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup><br />
<br /></li>
    </ul>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents218">Correlation:</strong><br />
In the broadest sense <strong>correlation</strong> is any statistical association, though it commonly refers to the degree to which a pair of variables are linearly related.</p>

    <p>There are several correlation coefficients, often denoted \({\displaystyle \rho }\) or \(r\), measuring the degree of correlation:</p>

    <p><strong style="color: red">Pearson Correlation Coefficient <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">[wiki]</a>:</strong><br />
It is a measure of the <strong>linear correlation</strong> between two variables \(X\) and \(Y\).</p>
    <p>$$\rho_{X, Y}=\frac{\operatorname{cov}(X, Y)}{\sigma_{X} \sigma_{Y}}$$</p>
    <p>where, \({\displaystyle \sigma_{X}}\) is the standard deviation of \({\displaystyle X}\) and \({\displaystyle \sigma_{Y}}\)  is the standard deviation of \({\displaystyle Y}\), and \(\rho \in [-1, 1]\).</p>

    <p><strong style="color: red">Correlation and Independence:</strong></p>
    <ol>
      <li>Uncorrelated \(\nRightarrow\) Independent</li>
      <li>Independent \(\implies\) Uncorrelated</li>
    </ol>

    <p>Zero correlation will indicate no linear dependency, however won’t capture non-linearity. Typical example is uniform random variable \(x\), and \(x^2\) over \([-1,1]\) with zero mean. Correlation is zero but clearly not independent.<br />
<br /></p>
  </li>
  <li>
    <p><strong style="color: SteelBlue" class="bodyContents2" id="bodyContents219">Probabilistic Inference:</strong><br />
<strong>Probabilistic Inference:</strong> compute a desired probability from other known probabilities (e.g. conditional from joint).</p>

    <p id="lst-p"><strong>We generally compute Conditional Probabilities:</strong></p>
    <ul>
      <li>
\[p(\text{sun} \vert T=\text{12 pm}) = 0.99\]
      </li>
      <li>These represent the agents beliefs given the evidence</li>
    </ul>

    <p id="lst-p"><strong>Probabilities change with new evidence:</strong></p>
    <ul>
      <li>\(p(\text{sun} \vert T=\text{12 pm}, C=\text{Stockholm}) = 0.85\)<br />
\(\longrightarrow\)</li>
      <li>
\[p(\text{sun} \vert T=\text{12 pm}, C=\text{Stockholm}, M=\text{Jan}) = 0.40\]
      </li>
      <li>Observing new evidence causes beliefs to be updated</li>
    </ul>

    <p id="lst-p"><strong style="color: red">Inference by Enumeration:</strong></p>
    <ul>
      <li><a href="https://www.youtube.com/embed/sMNbLXsvRig?start=3508" value="show" onclick="iframePopA(event)"><strong>CS188 Lec. 10-2</strong></a>
<a href="https://www.youtube.com/embed/sMNbLXsvRig?start=3508"></a>
        <div></div>
      </li>
    </ul>

    <p><strong>Problems:</strong></p>
    <ul>
      <li>Worst-case time complexity \(\mathrm{O}\left(\mathrm{d}^{n}\right)\)</li>
      <li>Space complexity \(\mathrm{O}\left(\mathrm{d}^{n}\right)\) to store the joint distribution</li>
    </ul>

    <p><strong style="color: red">Inference with Bayes Theorem:</strong></p>
    <ul>
      <li><strong>Diagnostic Probability from Causal Probability:</strong>
        <p>$$P(\text { cause } | \text { effect })=\frac{P(\text { effect } | \text { cause }) P(\text { cause })}{P(\text { effect })}$$</p>
      </li>
    </ul>
  </li>
</ol>

<hr />

<h2 id="content9">Discrete Distributions</h2>

<!-- 1. **Uniform Distribution:**{: style="color: SteelBlue"}{: .bodyContents9 #bodyContents91}   -->

<ol>
  <li>
    <dl>
      <dt><strong style="color: SteelBlue" class="bodyContents9" id="bodyContents92">Bernoulli Distribution:</strong></dt>
      <dd>A distribution over a single binary random variable.<br />
It is controlled by a single parameter \(\phi \in [0, 1]\), which fives the probability of the r.v. being equal to \(1\).
        <blockquote>
          <p>It models the probability of a single experiment with a boolean outcome (e.g. coin flip \(\rightarrow\) {heads: 1, tails: 0})</p>
        </blockquote>
      </dd>
      <dd><strong>PMF:</strong></dd>
      <dd>
\[{\displaystyle P(x)={\begin{cases}p&amp;{\text{if }}p=1,\\q=1-p&amp;{\text{if }}p=0.\end{cases}}}\]
      </dd>
      <dd><strong>Properties:</strong>
        <p>$$P(X=1) = \phi$$</p>
        <p>$$P(X=0) = 1 - \phi$$</p>
        <p>$$P(X=x) = \phi^x (1 - \phi)^{1-x}$$</p>
        <p>$$\operatorname {E}[X] = \phi$$</p>
        <p>$$\operatorname {Var}(X) = \phi (1 - \phi)$$</p>
      </dd>
    </dl>
  </li>
  <li><strong style="color: SteelBlue" class="bodyContents9" id="bodyContents93">Binomial Distribution:</strong>
    <blockquote>
      <p>\({\binom {n}{k}}={\frac {n!}{k!(n-k)!}}\) is the number of possible ways of getting \(x\) successes and \(n-x\) failures</p>
    </blockquote>
  </li>
</ol>

<!-- 4. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents9 #bodyContents94}  
5. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents9 #bodyContents95}  
6. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents9 #bodyContents96}  
7. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents9 #bodyContents97}  
8. **Asynchronous:**{: style="color: SteelBlue"}{: .bodyContents9 #bodyContents98}   -->

<hr />

<h2 id="content99">110</h2>

<ol>
  <li><strong style="color: SteelBlue" class="bodyContents99" id="bodyContents991">Problems:</strong>
    <ul>
      <li><a href="https://www.youtube.com/embed/LZ5Wergp_PA?start=2305" value="show" onclick="iframePopA(event)"><strong>deMortmonts/Matching problem</strong></a>
 <a href="https://www.youtube.com/embed/LZ5Wergp_PA?start=2305"></a>
        <div></div>
        <p>Sol: Inclusion-Exclusion</p>
      </li>
      <li><a href="https://www.youtube.com/embed/P7NE4WF8j-Q?start=1057" value="show" onclick="iframePopA(event)"><strong>Newton-Pepys: most likely event of rolling 6’s in dice</strong></a>
 <a href="https://www.youtube.com/embed/P7NE4WF8j-Q?start=1057"></a>
        <div></div>
      </li>
    </ul>
  </li>
</ol>

<hr />

<h2 id="content10">Notes, Tips and Tricks</h2>

<ul>
  <li>
    <p>It is more practical to use a simple but uncertain rule rather than a complex but certain one, even if the true rule is deterministic and our modeling system has the fidelity to accommodate a complex rule.<br />
  For example, the simple rule “Most birds fly” is cheap to develop and is broadly useful, while a rule of the form, “Birds fly, except for very young birds that have not yet learned to fly, sick or injured birds that have lost the ability to fly, flightless species of birds including the cassowary, ostrich and kiwi. . .” is expensive to develop, maintain and communicate and, after all this effort, is still brittle and prone to failure.</p>
  </li>
  <li><strong class="bodyContents10" id="bodyContents102">Disjoint Events (Mutually Exclusive):</strong> are events that cannot occur together at the same time
  Mathematically:
    <ul>
      <li>\(A_i \cap A_j = \varnothing\) whenever \(i \neq j\)</li>
      <li>\(p(A_i, A_j) = 0\),</li>
    </ul>
  </li>
  <li>
    <p><strong>Complexity of Describing a Probability Distribution</strong>:<br />
  A description of a probability distribution is <em>exponential</em> in the number of variables it models.<br />
  The number of possibilities is <strong>exponential</strong> in the number of variables.</p>
  </li>
  <li>
    <p><strong>Probability VS Likelihood</strong>:<br />
  <strong>Probabilities</strong> are the areas under a fixed distribution<br />
  \(pr(\)data\(|\)distribution\()\)<br />
  i.e. probability of some <em>data</em> (left hand side) given a distribution (described by the right hand side)<br />
  <strong>Likelihoods</strong> are the y-axis values for fixed data points with distributions that can be moved..<br />
  \(L(\)distribution\(|\)observation/data\()\)</p>

    <blockquote>
      <p>Likelihood is, basically, a specific probability that can only be calculated after the fact (of observing some outcomes). It is not normalized to \(1\) (it is <strong>not</strong> a probability). It is just a way to quantify how likely a set of observation is to occur given some distribution with some parameters; then you can manipulate the parameters to make the realization of the data more <em>“likely”</em> (it is precisely meant for that purpose of estimating the parameters); it is a <em>function</em> of the <strong>parameters</strong>.<br />
  Probability, on the other hand, is absolute for all possible outcomes. It is a function of the <strong>Data</strong>.</p>
    </blockquote>
  </li>
  <li>
    <p><strong>Maximum Likelihood Estimation</strong>:<br />
  A method that tries to find the <em>optimal value</em> for the <em>mean</em> and/or <em>stdev</em> for a distribution <em><strong>given</strong></em> some observed measurements/data-points.</p>
  </li>
  <li>
    <p><strong>Variance</strong>:<br />
  When \(\text{Var}(X) = 0 \implies X = E[X] = \mu\). (not interesting)</p>
  </li>
  <li><strong>Reason we sometimes prefer Biased Estimators</strong>:</li>
</ul>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Corresponds to “wanting” the probability of events that are <strong>certain</strong> to have p=1 and events that are <strong>impossible</strong> to have p=0 <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Comes from \(\operatorname{Var}[\overline{X}]=\operatorname {E}\left[\overline{X}^{2}\right]-\{\operatorname {E}[\overline{X}]\}^{2}\) <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>


      <footer class="site-footer">
    <!--   <span class="site-footer-owner"><a href="http://localhost:8889">Ahmad Badary</a> is maintained by <a href="http://ahmedbadary.ml">Ahmad Badary</a>.</span> -->
    
<!--  -->
    <div class="wrapper">
        <div class="footer-col-wrapper">
            <div class="footer-col footer-col-1">
            <span class="site-footer-owner"><a href="http://localhost:8889">Site</a> maintained by <a href="http://ahmedbadary.ml">Ahmad Badary</a>.</span>
    <span class="site-footer-credits">
        <p>
            &copy; 2017. All rights reserved.
        </p> 
    </span>
            </div>
            <div class="footer-col footer-col-2">
            <div><p>         </p></div>
            </div>
            <div class="footer-col footer-col-3">
                <ul class="social-media-list">
                    
                      <li>
                        <a href="https://github.com/AhmedBadary">
                          <i class="fa fa-github"></i> GitHub
                        </a>
                      </li>
                    
                    
                      <li>
                        <a href="https://linkedin.com/in/ahmad-badary-656098121/">
                          <i class="fa fa-linkedin"></i> LinkedIn
                        </a>
                      </li>
                    
                    
                      <li>
                        <a href="https://www.facebook.com/ahmed.thabet.94">
                          <i class="fa fa-facebook"></i> Facebook
                        </a>
                      </li>
                    
                </ul>
            </div>
        </div>
    </div>
<!--  -->
</footer>


    </section>

  </body>

<!-- Table of Content Script -->
<script type="text/javascript">
var bodyContents = $(".bodyContents1");
$("<ol>").addClass("TOC1ul").appendTo(".TOC1");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC1ul");
     });
// 
var bodyContents = $(".bodyContents2");
$("<ol>").addClass("TOC2ul").appendTo(".TOC2");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC2ul");
     });
// 
var bodyContents = $(".bodyContents3");
$("<ol>").addClass("TOC3ul").appendTo(".TOC3");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC3ul");
     });
//
var bodyContents = $(".bodyContents4");
$("<ol>").addClass("TOC4ul").appendTo(".TOC4");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC4ul");
     });
//
var bodyContents = $(".bodyContents5");
$("<ol>").addClass("TOC5ul").appendTo(".TOC5");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC5ul");
     });
//
var bodyContents = $(".bodyContents6");
$("<ol>").addClass("TOC6ul").appendTo(".TOC6");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC6ul");
     });
//
var bodyContents = $(".bodyContents7");
$("<ol>").addClass("TOC7ul").appendTo(".TOC7");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC7ul");
     });
//
var bodyContents = $(".bodyContents8");
$("<ol>").addClass("TOC8ul").appendTo(".TOC8");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC8ul");
     });
//
var bodyContents = $(".bodyContents9");
$("<ol>").addClass("TOC9ul").appendTo(".TOC9");
bodyContents.each(function(index, element) {
    var paragraph = $(element);
    $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC9ul");
     });

</script>

<!-- VIDEO BUTTONS SCRIPT -->
<script type="text/javascript">
  function iframePopInject(event) {
    var $button = $(event.target);
    // console.log($button.parent().next());
    if ($button.attr('value') == 'show') {
        $button.attr('value', 'hide');
        $figure = $("<div>").addClass("video_container");
        $iframe = $("<iframe>").appendTo($figure);
        $iframe.attr("src", $button.attr("src"));
        // $iframe.attr("frameborder", "0");
        $iframe.attr("allowfullscreen", "true");
        $iframe.css("padding", "4px 6px");
        $button.next().css("display", "block");
        $figure.appendTo($button.next());
        $button.text("Hide Video")
    } else {
        $button.attr('value', 'show');
        $button.next().html("");
        $button.text("Show Video")
    }
}
</script>

<!-- BUTTON TRY -->
<script type="text/javascript">
  function iframePopA(event) {
    event.preventDefault();
    var $a = $(event.target).parent();
    console.log($a);
    if ($a.attr('value') == 'show') {
        $a.attr('value', 'hide');
        $figure = $("<div>");
        $iframe = $("<iframe>").addClass("popup_website_container").appendTo($figure);
        $iframe.attr("src", $a.attr("href"));
        $iframe.attr("frameborder", "1");
        $iframe.attr("allowfullscreen", "true");
        $iframe.css("padding", "4px 6px");
        $a.next().css("display", "block");
        $figure.appendTo($a.next().next());
        // $a.text("Hide Content")
        $('html, body').animate({
            scrollTop: $a.offset().top
        }, 1000);
    } else {
        $a.attr('value', 'show');
        $a.next().next().html("");
        // $a.text("Show Content")
    }

    $a.next().css("display", "inline");
}
</script>


<!-- TEXT BUTTON SCRIPT - INJECT -->
<script type="text/javascript">
  function showTextPopInject(event) {
    var $button = $(event.target);
    var txt = $button.attr("input");
    console.log(txt);
    if ($button.attr('value') == 'show') {
        $button.attr('value', 'hide');
        $p = $("<p>");
        $p.html(txt);
        $button.next().css("display", "block");
        $p.appendTo($button.next());
        $button.text("Hide Content")
    } else {
        $button.attr('value', 'show');
        $button.next().html("");
        $button.text("Show Content")
    }

}
</script>

<!-- TEXT BUTTON SCRIPT - HIDDEN / HIDE / SHOW / HIDE/SHOW -->
<script type="text/javascript">
  function showTextPopHide(event) {
    var $button = $(event.target);
    // var txt = $button.attr("input");
    var txt = $button.text();
    if ($button.attr('value') == 'show') {
        $button.attr('value', 'hide');
        $button.next().removeAttr("hidden");
        $button.text(txt + " - Hide Content");
    } else {
        $button.attr('value', 'show');
        $button.next().attr("hidden", "");
        $button.text(txt.replace(" - Hide Content",""));
    }
}
</script>

<!-- TEXT BUTTON SCRIPT - HIDDEN / HIDE / SHOW / HIDE/SHOW -->
<script type="text/javascript">
  function showText_withParent_PopHide(event) {
    var $button = $(event.target);
    var $parent = $button.parent();
    var txt = $button.text();
    if ($button.attr('value') == 'show') {
        $button.attr('value', 'hide');
        $parent.next().removeAttr("hidden");
        $button.text(txt + " - Hide Content");
    } else {
        $button.attr('value', 'show');
        $parent.next().attr("hidden", "");
        $button.text(txt.replace(" - Hide Content",""));
    }
}
</script>

<!-- Print / Printing / printme -->
<!-- <script type="text/javascript">
i = 0

for (var i = 1; i < 6; i++) {
    var bodyContents = $(".bodyContents" + i);
    $("<p>").addClass("TOC1ul")  .appendTo(".TOC1");
    bodyContents.each(function(index, element) {
        var paragraph = $(element);
        $("<li>").html("<a href=#"+paragraph.attr('id')+">"+ paragraph.html().replace(':','')+" </a> ").appendTo(".TOC1ul");
         });
} 
</script>
 -->
 
</html>

