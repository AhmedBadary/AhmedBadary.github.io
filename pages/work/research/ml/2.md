---
layout: NotesPage
title: Decision Tree Learning <br /> and <br /> Random Forests
permalink: /work_files/research/ml/2
prevLink: /work_files/research/ml.html
---

## Decision Trees

### In Decision Analysis
**Decision Tree** is a decision support tool that uses a tree-like graph or model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It is one way to display an algorithm that only contains conditional control statements.  

Decision Trees are a **flowchart-like structure** in which each internal node represents a "test" on an attribute (e.g. whether a coin flip comes up heads or tails), each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes). The paths from root to leaf represent classification rules.

### In Machine Learning
**Decision Tree Learning** uses a decision tree (as a predictive model) to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). It is one of the predictive modelling vastly used.

#### Types
Decision Trees split into two types based on what they do:  
1. **Classification Trees:** Tree models where the target variable can take a discrete set of values.
2. **Regression Trees** Decision trees where the target variable can take continuous values (typically real numbers).

***

# Topics

* #### [(Classification) Decision Trees](/work_files/research/ml/2_1)

* #### [(Regression) Decision Trees](/work_files/research/ml/2_2)

* #### [Random Forests](/work_files/research/ml/2_3)

* #### [Bagging and Boosting](/work_files/research/ml/2_4)




Updated Soon!